{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 8: Node Policies - Building Resilient Workflows\n",
    "\n",
    "**Difficulty:** Intermediate | **Time:** 45 minutes\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Understand retry policies and failure handling\n",
    "- Configure rate limiting for resource protection\n",
    "- Implement circuit breakers for fault tolerance\n",
    "- Use timeout policies to prevent hangs\n",
    "- Apply idempotency policies for reliable operations\n",
    "- Combine policies for production-grade resilience\n",
    "\n",
    "## Real-World Use Cases\n",
    "\n",
    "Policies transform fragile workflows into resilient systems:\n",
    "\n",
    "- **API Integration**: Retry failed requests, rate limit calls, circuit break on service downtime\n",
    "- **Database Operations**: Timeout slow queries, retry on deadlocks, ensure idempotent writes\n",
    "- **External Services**: Handle network failures, prevent cascade failures, control resource usage\n",
    "- **File Processing**: Timeout I/O operations, retry on permission errors, limit concurrent access\n",
    "- **AI/ML Workflows**: Retry model inference, limit API calls, handle service unavailability\n",
    "- **Microservices**: Implement fault tolerance patterns, prevent overload, ensure graceful degradation\n",
    "\n",
    "In this tutorial, you'll learn how to make your Spark workflows bulletproof with built-in policy patterns!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Core Concepts\n",
    "\n",
    "### What Are Node Policies?\n",
    "\n",
    "**Policies** are cross-cutting concerns that wrap node execution to provide resilience, reliability, and resource management. They automatically handle common failure scenarios without polluting your business logic.\n",
    "\n",
    "**Key characteristics:**\n",
    "- Configured on `NodeConfig` and applied when the node is constructed\n",
    "- Composable - multiple policies can be stacked in a predictable order\n",
    "- Configurable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's import the necessary classes for building resilient nodes with policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import core Spark classes\n",
    "from spark.nodes.nodes import Node\n",
    "from spark.nodes.config import NodeConfig\n",
    "from spark.nodes.policies import (\n",
    "    RetryPolicy,\n",
    "    RateLimiterPolicy,\n",
    "    CircuitBreakerPolicy,\n",
    "    TimeoutPolicy,\n",
    "    IdempotencyPolicy,\n",
    "    Rate,\n",
    "    CircuitBreaker,\n",
    "    InMemoryIdempotencyStore,\n",
    "    IdempotencyConfig,\n",
    ")\n",
    "from spark.nodes.types import ExecutionContext, NodeMessage\n",
    "from spark.nodes.exceptions import NodeExecutionError, CircuitBreakerOpenError\n",
    "from spark.graphs.graph import Graph\n",
    "import asyncio\n",
    "import time\n",
    "import random\n",
    "from typing import Any, Optional\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Retry Policy - Handling Transient Failures\n",
    "\n",
    "Let's start by creating a node that sometimes fails and applying retry logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Example 1: Retry Policy ===\n",
      "\n",
      "ðŸ”§ Retry Policy Configuration:\n",
      "  Max attempts: 5\n",
      "  Initial delay: 0.2s\n",
      "  Backoff multiplier: 2.0\n",
      "  Max delay: 2.0s\n",
      "  Retry on errors: (<class 'spark.nodes.exceptions.NodeExecutionError'>,)\n",
      "\n",
      "ðŸš€ Testing Resilient Node:\n",
      "  âŒ Attempt 1: Service unavailable (503 error)\n",
      "  âŒ Attempt 2: Service unavailable (503 error)\n",
      "  âŒ Attempt 3: Service unavailable (503 error)\n",
      "  âŒ Attempt 4: Service unavailable (503 error)\n",
      "  âŒ Attempt 5: Service unavailable (503 error)\n",
      "\n",
      "âŒ Final failure after 3.51s: [retry_exhausted] node=None stage=_process: [service_error] node=None stage=_process: Service temporarily unavailable\n",
      "\n",
      "ðŸ“‹ Retry Policy Analysis:\n",
      "âœ“ Automatic retries with exponential backoff\n",
      "âœ“ Configurable maximum attempts\n",
      "âœ“ Selective retry based on error types\n",
      "âœ“ Jitter support for avoiding thundering herd\n",
      "âœ“ Full error context preservation\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Example 1: Retry Policy ===\")\n",
    "print()\n",
    "\n",
    "# Simulate a flaky service that fails 70% of the time\n",
    "failure_count = 0\n",
    "\n",
    "class FlakyServiceNode(Node):\n",
    "    \"\"\"A node that simulates an unreliable external service.\"\"\"\n",
    "    \n",
    "    async def process(self, context: ExecutionContext) -> Any:\n",
    "        global failure_count\n",
    "        failure_count += 1\n",
    "        \n",
    "        # Simulate network call\n",
    "        await asyncio.sleep(0.1)\n",
    "        \n",
    "        # Fail 70% of the time\n",
    "        if random.random() < 0.7:\n",
    "            print(f\"  âŒ Attempt {failure_count}: Service unavailable (503 error)\")\n",
    "            raise NodeExecutionError(\n",
    "                kind=\"service_error\",\n",
    "                node=self,\n",
    "                stage=\"_process\",\n",
    "                original=Exception(\"Service temporarily unavailable\"),\n",
    "                ctx_snapshot=context.snapshot()\n",
    "            )\n",
    "        \n",
    "        print(f\"  âœ… Attempt {failure_count}: Service responded successfully\")\n",
    "        return {\"status\": \"success\", \"attempts\": failure_count}\n",
    "\n",
    "# Apply retry policy to the flaky service\n",
    "retry_policy = RetryPolicy(\n",
    "    max_attempts=5,        # Try up to 5 times\n",
    "    delay=0.2,            # Start with 200ms delay\n",
    "    backoff_multiplier=2.0,  # Double delay each time\n",
    "    max_delay=2.0,         # Cap at 2 seconds\n",
    "    retry_on=(NodeExecutionError,),  # Only retry on specific errors\n",
    ")\n",
    "\n",
    "resilient_node = FlakyServiceNode(NodeConfig(retry=retry_policy))\n",
    "\n",
    "print(\"ðŸ”§ Retry Policy Configuration:\")\n",
    "print(f\"  Max attempts: {retry_policy.max_attempts}\")\n",
    "print(f\"  Initial delay: {retry_policy.delay}s\")\n",
    "print(f\"  Backoff multiplier: {retry_policy.backoff_multiplier}\")\n",
    "print(f\"  Max delay: {retry_policy.max_delay}s\")\n",
    "print(f\"  Retry on errors: {retry_policy.retry_on}\")\n",
    "print()\n",
    "\n",
    "# Test the resilient node\n",
    "print(\"ðŸš€ Testing Resilient Node:\")\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    context = ExecutionContext(\n",
    "        inputs=NodeMessage(content={\"request\": \"get_data\"}),\n",
    "        state={}\n",
    "    )\n",
    "    result = await resilient_node.do(context)\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Results:\")\n",
    "    print(f\"  Success: {result['status']}\")\n",
    "    print(f\"  Total attempts: {result['attempts']}\")\n",
    "    print(f\"  Total time: {elapsed:.2f}s\")\n",
    "    print(f\"  Final delay used: {retry_policy.get_delay(result['attempts']-1):.2f}s\")\n",
    "    \n",
    "except Exception as e:\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\nâŒ Final failure after {elapsed:.2f}s: {e}\")\n",
    "\n",
    "print()\n",
    "print(\"ðŸ“‹ Retry Policy Analysis:\")\n",
    "print(\"âœ“ Automatic retries with exponential backoff\")\n",
    "print(\"âœ“ Configurable maximum attempts\")\n",
    "print(\"âœ“ Selective retry based on error types\")\n",
    "print(\"âœ“ Jitter support for avoiding thundering herd\")\n",
    "print(\"âœ“ Full error context preservation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Retry Patterns\n",
    "\n",
    "**When to use retries:**\n",
    "\n",
    "âœ… **Network calls**: HTTP requests, database connections, API calls\n",
    "âœ… **Transient errors**: Timeouts, rate limits, temporary service issues\n",
    "âœ… **Resource contention**: Database deadlocks, file locks, temporary resource exhaustion\n",
    "\n",
    "âŒ **Don't retry:**\n",
    "\n",
    "- Authentication failures (401/403)\n",
    "- Not found errors (404)\n",
    "- Validation errors (400)\n",
    "- Configuration errors\n",
    "\n",
    "**Retry strategies:**\n",
    "\n",
    "```python\n",
    "# Fast retry for quick recovery\n",
    "RetryPolicy(max_attempts=3, delay=0.1, backoff_multiplier=1.5)\n",
    "\n",
    "# Slow retry for external services\n",
    "RetryPolicy(max_attempts=10, delay=1.0, backoff_multiplier=2.0, max_delay=30.0)\n",
    "\n",
    "# Limited retry for critical operations\n",
    "RetryPolicy(max_attempts=2, delay=0.5, retry_on=(TimeoutError, ConnectionError))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Rate Limiting - Preventing Resource Exhaustion\n",
    "\n",
    "Let's create nodes that make rapid API calls and protect them with rate limiting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Example 2: Rate Limiting ===\n",
      "\n",
      "ðŸš¦ Rate Limiting Configuration:\n",
      "  Resource key: external_api\n",
      "  Rate limit: 3.0 calls/second\n",
      "  Burst capacity: 5 calls\n",
      "  Shared across: weather, stocks, news APIs\n",
      "\n",
      "ðŸƒâ€â™‚ï¸ Testing Rate Limiting (parallel calls):\n",
      "\n",
      "\n",
      "ðŸ“Š Results after 1.72 seconds:\n",
      "  Successful calls: 0\n",
      "  Failed calls: 10\n",
      "  Actual rate: 0.00 calls/sec\n",
      "  Target rate: 3.0 calls/sec\n",
      "\n",
      "ðŸ“‹ Rate Limiting Analysis:\n",
      "âœ“ Token bucket algorithm for smooth rate limiting\n",
      "âœ“ Burst capacity allows short bursts above average rate\n",
      "âœ“ Shared rate limits across multiple nodes\n",
      "âœ“ Automatic backpressure when rate limit exceeded\n",
      "âœ“ No coordination required between nodes\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Example 2: Rate Limiting ===\")\n",
    "print()\n",
    "\n",
    "class APICallNode(Node):\n",
    "    \"\"\"Node that simulates making API calls.\"\"\"\n",
    "    call_count: int = 0\n",
    "    \n",
    "    async def process(self, context: ExecutionContext) -> Any:\n",
    "        self.call_count += 1\n",
    "        call_id = self.call_count\n",
    "        \n",
    "        # Simulate API call processing\n",
    "        await asyncio.sleep(0.05)\n",
    "        \n",
    "        print(f\"  ðŸ“¡ {self.api_name} call #{call_id}: Processing request\")\n",
    "        \n",
    "        return {\n",
    "            \"api\": self.api_name,\n",
    "            \"call_id\": call_id,\n",
    "            \"timestamp\": time.time(),\n",
    "            \"result\": f\"Data from {self.api_name}\"\n",
    "        }\n",
    "\n",
    "# Configure rate limiting: 3 calls per second with burst of 5\n",
    "rate_limit_policy = RateLimiterPolicy(\n",
    "    resource_key=\"external_api\",  # Share limit across all API calls\n",
    "    rate=Rate(limit=3.0, burst=5)   # 3 calls/sec, allow burst of 5\n",
    ")\n",
    "\n",
    "# Create multiple API nodes with rate limiting\n",
    "weather_node = APICallNode(NodeConfig(id=\"weather\", rate_limiter=rate_limit_policy))\n",
    "stocks_node = APICallNode(NodeConfig(id=\"stocks\", rate_limiter=rate_limit_policy))\n",
    "news_node = APICallNode(NodeConfig(id=\"news\", rate_limiter=rate_limit_policy))\n",
    "\n",
    "print(\"ðŸš¦ Rate Limiting Configuration:\")\n",
    "print(f\"  Resource key: {rate_limit_policy.resource_key}\")\n",
    "print(f\"  Rate limit: {rate_limit_policy.rate.limit} calls/second\")\n",
    "print(f\"  Burst capacity: {rate_limit_policy.rate.burst} calls\")\n",
    "print(f\"  Shared across: weather, stocks, news APIs\")\n",
    "print()\n",
    "\n",
    "print(\"ðŸƒâ€â™‚ï¸ Testing Rate Limiting (parallel calls):\")\n",
    "print()\n",
    "\n",
    "# Make multiple rapid calls\n",
    "async def make_rapid_calls():\n",
    "    \"\"\"Make multiple API calls rapidly to test rate limiting.\"\"\"\n",
    "    tasks = []\n",
    "    \n",
    "    # Schedule 10 calls rapidly\n",
    "    for i in range(10):\n",
    "        api_node = [weather_node, stocks_node, news_node][i % 3]\n",
    "        context = ExecutionContext(\n",
    "            inputs=NodeMessage(content={\"request_id\": i}),\n",
    "            state={}\n",
    "        )\n",
    "        \n",
    "        task = asyncio.create_task(api_node.do(context))\n",
    "        tasks.append(task)\n",
    "    \n",
    "    # Wait for all to complete\n",
    "    start_time = time.time()\n",
    "    results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Results after {elapsed:.2f} seconds:\")\n",
    "    \n",
    "    successful = [r for r in results if not isinstance(r, Exception)]\n",
    "    failed = [r for r in results if isinstance(r, Exception)]\n",
    "    \n",
    "    print(f\"  Successful calls: {len(successful)}\")\n",
    "    print(f\"  Failed calls: {len(failed)}\")\n",
    "    print(f\"  Actual rate: {len(successful)/elapsed:.2f} calls/sec\")\n",
    "    print(f\"  Target rate: {rate_limit_policy.rate.limit} calls/sec\")\n",
    "    \n",
    "    # Show timing of successful calls\n",
    "    if len(successful) > 1:\n",
    "        timestamps = [r['timestamp'] for r in successful]\n",
    "        timestamps.sort()\n",
    "        \n",
    "        print(f\"\\nðŸ“ˆ Call timing (first 5):\")\n",
    "        for i, ts in enumerate(timestamps[:5]):\n",
    "            if i == 0:\n",
    "                print(f\"  Call {i+1}: {ts:.3f} (start)\")\n",
    "            else:\n",
    "                delay = ts - timestamps[i-1]\n",
    "                print(f\"  Call {i+1}: {ts:.3f} (+{delay:.3f}s)\")\n",
    "\n",
    "await make_rapid_calls()\n",
    "\n",
    "print()\n",
    "print(\"ðŸ“‹ Rate Limiting Analysis:\")\n",
    "print(\"âœ“ Token bucket algorithm for smooth rate limiting\")\n",
    "print(\"âœ“ Burst capacity allows short bursts above average rate\")\n",
    "print(\"âœ“ Shared rate limits across multiple nodes\")\n",
    "print(\"âœ“ Automatic backpressure when rate limit exceeded\")\n",
    "print(\"âœ“ No coordination required between nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rate Limiting Patterns\n",
    "\n",
    "**Different rate limiting strategies:**\n",
    "\n",
    "```python\n",
    "# Strict rate limiting (no burst)\n",
    "Rate(limit=10.0, burst=1)  # Exactly 10 calls/sec\n",
    "\n",
    "# Bursty traffic allowance\n",
    "Rate(limit=5.0, burst=20)  # Average 5/sec, burst to 20\n",
    "\n",
    "# High throughput with large burst\n",
    "Rate(limit=100.0, burst=200)  # Average 100/sec, burst to 200\n",
    "\n",
    "# Slow drip (e.g., for expensive operations)\n",
    "Rate(limit=0.1, burst=1)  # 1 call every 10 seconds\n",
    "```\n",
    "\n",
    "**Resource key strategies:**\n",
    "\n",
    "```python\n",
    "# Global limit (all nodes share)\n",
    "RateLimiterPolicy(resource_key=\"global_limit\", rate=Rate(10, 10))\n",
    "\n",
    "# Per-service limit\n",
    "RateLimiterPolicy(resource_key=\"weather_api\", rate=Rate(5, 5))\n",
    "RateLimiterPolicy(resource_key=\"stocks_api\", rate=Rate(20, 20))\n",
    "\n",
    "# Per-user limit\n",
    "RateLimiterPolicy(resource_key=f\"user_{user_id}\", rate=Rate(2, 5))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Circuit Breaker - Preventing Cascade Failures\n",
    "\n",
    "Let's implement a circuit breaker that stops calling failing services after repeated failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Example 3: Circuit Breaker ===\n",
      "\n",
      "âš¡ Circuit Breaker Configuration:\n",
      "  Breaker key: payment_service\n",
      "  Failure threshold: 3\n",
      "  Failure window: 10.0s\n",
      "  Reset timeout: 5.0s\n",
      "\n",
      "ðŸ§ª Testing Circuit Breaker Behavior:\n",
      "\n",
      "  âœ… payment: Responding normally\n",
      "Call 1: ERROR - TypeError: 'NodeMessage' object is not subscriptable\n",
      "  âœ… payment: Responding normally\n",
      "Call 2: ERROR - TypeError: 'NodeMessage' object is not subscriptable\n",
      "  âœ… payment: Responding normally\n",
      "Call 3: ERROR - TypeError: 'NodeMessage' object is not subscriptable\n",
      "  âœ… payment: Responding normally\n",
      "Call 4: ERROR - TypeError: 'NodeMessage' object is not subscriptable\n",
      "  âœ… payment: Responding normally\n",
      "Call 5: ERROR - TypeError: 'NodeMessage' object is not subscriptable\n",
      "  âœ… payment: Responding normally\n",
      "Call 6: ERROR - TypeError: 'NodeMessage' object is not subscriptable\n",
      "  ðŸ”¥ payment: Service down! (503 error)\n",
      "Call 7: ERROR - NodeExecutionError: [service_unavailable] node=None stage=_process: payment service unavailable\n",
      "  ðŸ”¥ payment: Service down! (503 error)\n",
      "Call 8: ERROR - NodeExecutionError: [service_unavailable] node=None stage=_process: payment service unavailable\n",
      "  ðŸ”¥ payment: Service down! (503 error)\n",
      "Call 9: ERROR - NodeExecutionError: [service_unavailable] node=None stage=_process: payment service unavailable\n",
      "Call 10: ERROR - NodeExecutionError: [circuit_open] node=None stage=_process: circuit breaker 'payment_service' is open; retry after 4.50s\n",
      "Call 11: ERROR - NodeExecutionError: [circuit_open] node=None stage=_process: circuit breaker 'payment_service' is open; retry after 4.00s\n",
      "Call 12: ERROR - NodeExecutionError: [circuit_open] node=None stage=_process: circuit breaker 'payment_service' is open; retry after 3.50s\n",
      "Call 13: ERROR - NodeExecutionError: [circuit_open] node=None stage=_process: circuit breaker 'payment_service' is open; retry after 2.99s\n",
      "Call 14: ERROR - NodeExecutionError: [circuit_open] node=None stage=_process: circuit breaker 'payment_service' is open; retry after 2.49s\n",
      "Call 15: ERROR - NodeExecutionError: [circuit_open] node=None stage=_process: circuit breaker 'payment_service' is open; retry after 1.99s\n",
      "\n",
      "ðŸ“‹ Circuit Breaker Analysis:\n",
      "âœ“ Automatic detection of failure patterns\n",
      "âœ“ Fast failure when service is down (no wasted calls)\n",
      "âœ“ Automatic recovery attempt after timeout\n",
      "âœ“ Half-open state for testing recovery\n",
      "âœ“ Prevents cascade failures in distributed systems\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Example 3: Circuit Breaker ===\")\n",
    "print()\n",
    "\n",
    "# Simulate a downstream service that starts failing permanently\n",
    "service_failure_time = None\n",
    "call_count = 0\n",
    "\n",
    "class DownstreamServiceNode(Node):\n",
    "    \"\"\"Node that simulates a downstream service that can fail.\"\"\"\n",
    "    \n",
    "    def __init__(self, service_name: str, config: NodeConfig, fail_after_calls: int = 5):\n",
    "        super().__init__(config)\n",
    "        self.service_name = service_name\n",
    "        self.fail_after_calls = fail_after_calls\n",
    "    \n",
    "    async def process(self, context: ExecutionContext) -> Any:\n",
    "        global service_failure_time, call_count\n",
    "        call_count += 1\n",
    "        \n",
    "        await asyncio.sleep(0.1)  # Simulate network latency\n",
    "        \n",
    "        # Start failing after specified number of calls\n",
    "        if call_count > self.fail_after_calls:\n",
    "            if service_failure_time is None:\n",
    "                service_failure_time = time.time()\n",
    "            \n",
    "            print(f\"  ðŸ”¥ {self.service_name}: Service down! (503 error)\")\n",
    "            raise NodeExecutionError(\n",
    "                kind=\"service_unavailable\",\n",
    "                node=self,\n",
    "                stage=\"_process\",\n",
    "                original=Exception(f\"{self.service_name} service unavailable\"),\n",
    "                ctx_snapshot=context.snapshot()\n",
    "            )\n",
    "        \n",
    "        print(f\"  âœ… {self.service_name}: Responding normally\")\n",
    "        return {\n",
    "            \"service\": self.service_name,\n",
    "            \"status\": \"healthy\",\n",
    "            \"data\": f\"Response from {self.service_name}\"\n",
    "        }\n",
    "\n",
    "# Configure circuit breaker\n",
    "circuit_breaker_policy = CircuitBreakerPolicy(\n",
    "    breaker_key=\"payment_service\",  # Unique identifier\n",
    "    circuit_breaker=CircuitBreaker(\n",
    "        failure_threshold=3,    # Open after 3 failures\n",
    "        window=10.0,           # Consider failures in 10s window\n",
    "        reset_timeout=5.0       # Try again after 5s\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create service with circuit breaker protection\n",
    "payment_node = DownstreamServiceNode(\n",
    "    \"payment\", \n",
    "    NodeConfig(circuit_breaker=circuit_breaker_policy), \n",
    "    fail_after_calls=6\n",
    ")\n",
    "\n",
    "print(\"âš¡ Circuit Breaker Configuration:\")\n",
    "print(f\"  Breaker key: {circuit_breaker_policy.breaker_key}\")\n",
    "print(f\"  Failure threshold: {circuit_breaker_policy.circuit_breaker.failure_threshold}\")\n",
    "print(f\"  Failure window: {circuit_breaker_policy.circuit_breaker.window}s\")\n",
    "print(f\"  Reset timeout: {circuit_breaker_policy.circuit_breaker.reset_timeout}s\")\n",
    "print()\n",
    "\n",
    "print(\"ðŸ§ª Testing Circuit Breaker Behavior:\")\n",
    "print()\n",
    "\n",
    "async def test_circuit_breaker():\n",
    "    \"\"\"Test circuit breaker through different states.\"\"\"\n",
    "    for i in range(15):\n",
    "        try:\n",
    "            context = ExecutionContext(\n",
    "                inputs=NodeMessage(content={\"request_id\": i}),\n",
    "                state={}\n",
    "            )\n",
    "            \n",
    "            result = await payment_node.do(context)\n",
    "            print(f\"Call {i+1}: SUCCESS - {result['status']}\")\n",
    "            \n",
    "        except CircuitBreakerOpenError as e:\n",
    "            retry_after = getattr(e, 'retry_after', 0)\n",
    "            print(f\"Call {i+1}: CIRCUIT OPEN (retry in {retry_after:.1f}s)\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Call {i+1}: ERROR - {type(e).__name__}: {e}\")\n",
    "        \n",
    "        await asyncio.sleep(0.5)  # Small delay between calls\n",
    "\n",
    "await test_circuit_breaker()\n",
    "\n",
    "print()\n",
    "print(\"ðŸ“‹ Circuit Breaker Analysis:\")\n",
    "print(\"âœ“ Automatic detection of failure patterns\")\n",
    "print(\"âœ“ Fast failure when service is down (no wasted calls)\")\n",
    "print(\"âœ“ Automatic recovery attempt after timeout\")\n",
    "print(\"âœ“ Half-open state for testing recovery\")\n",
    "print(\"âœ“ Prevents cascade failures in distributed systems\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Circuit Breaker States\n",
    "\n",
    "**Three states of a circuit breaker:**\n",
    "\n",
    "1. **CLOSED** (Normal Operation):\n",
    "   - All calls pass through\n",
    "   - Success/failure is tracked\n",
    "   - Opens when threshold reached\n",
    "\n",
    "2. **OPEN** (Failing Fast):\n",
    "   - All calls immediately fail\n",
    "   - No calls to the failing service\n",
    "   - Saves resources and prevents overload\n",
    "   - Transitions to half-open after timeout\n",
    "\n",
    "3. **HALF-OPEN** (Testing Recovery):\n",
    "   - Limited calls allowed through\n",
    "   - First success closes circuit\n",
    "   - First failure re-opens circuit\n",
    "   - Determines if service has recovered\n",
    "\n",
    "**Configuration strategies:**\n",
    "\n",
    "```python\n",
    "# Sensitive circuit (opens quickly)\n",
    "CircuitBreaker(failure_threshold=2, window=5.0, reset_timeout=10.0)\n",
    "\n",
    "# Lenient circuit (tolerates more failures)\n",
    "CircuitBreaker(failure_threshold=10, window=60.0, reset_timeout=30.0)\n",
    "\n",
    "# Fast recovery\n",
    "CircuitBreaker(failure_threshold=5, window=10.0, reset_timeout=5.0)\n",
    "\n",
    "# Slow recovery (for stable services)\n",
    "CircuitBreaker(failure_threshold=5, window=30.0, reset_timeout=60.0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Timeout Policy - Preventing Hanging Operations\n",
    "\n",
    "Let's implement timeout protection for operations that might hang."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Example 4: Timeout Policy ===\n",
      "\n",
      "â±ï¸  Timeout Policy Configuration:\n",
      "  Timeout duration: 1.0s\n",
      "\n",
      "ðŸ§ª Testing Timeout Protection:\n",
      "\n",
      "ðŸ”“ Unprotected Node (may take long time):\n",
      "  â³ unprotected: Starting (will take 2.67s)\n",
      "  âœ… unprotected: Completed in 2.67s\n",
      "  Result: completed (took 2.67s)\n",
      "\n",
      "ðŸ”’ Protected Node (timeout after 1s):\n",
      "  â³ protected: Starting (will take 2.75s)\n",
      "  Attempt 1: TIMEOUT after 1.00s (NodeTimeoutError)\n",
      "  â³ protected: Starting (will take 0.80s)\n",
      "  âœ… protected: Completed in 0.80s\n",
      "  Attempt 2: SUCCESS in 0.81s\n",
      "  â³ protected: Starting (will take 2.67s)\n",
      "  Attempt 3: TIMEOUT after 1.00s (NodeTimeoutError)\n",
      "\n",
      "ðŸ“‹ Timeout Policy Analysis:\n",
      "âœ“ Guaranteed maximum execution time\n",
      "âœ“ Prevents resource exhaustion from hanging operations\n",
      "âœ“ Clean error handling with timeout context\n",
      "âœ“ Works with any asyncio-compatible operation\n",
      "âœ“ Preserves original operation semantics\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"=== Example 4: Timeout Policy ===\")\n",
    "print()\n",
    "\n",
    "class SlowOperationNode(Node):\n",
    "    \"\"\"Node that simulates operations with variable duration.\"\"\"\n",
    "\n",
    "    def __init__(self, operation_name: str, config: NodeConfig | None = None):\n",
    "        config = config or NodeConfig(name=f\"slow_{operation_name}\")\n",
    "        super().__init__(config=config)\n",
    "        self.operation_name = operation_name\n",
    "\n",
    "    async def process(self, context: ExecutionContext) -> Any:\n",
    "        # Simulate variable operation time\n",
    "        operation_time = random.uniform(0.5, 3.0)\n",
    "\n",
    "        print(f\"  â³ {self.operation_name}: Starting (will take {operation_time:.2f}s)\")\n",
    "        await asyncio.sleep(operation_time)\n",
    "        print(f\"  âœ… {self.operation_name}: Completed in {operation_time:.2f}s\")\n",
    "\n",
    "        return {\n",
    "            \"operation\": self.operation_name,\n",
    "            \"duration\": operation_time,\n",
    "            \"status\": \"completed\",\n",
    "        }\n",
    "\n",
    "# Configure nodes with and without timeout protection\n",
    "timeout_policy = TimeoutPolicy(seconds=1.0)  # 1 second timeout\n",
    "protected_config = NodeConfig(name=\"slow_protected\", timeout=timeout_policy)\n",
    "\n",
    "slow_unprotected = SlowOperationNode(\"unprotected\")\n",
    "slow_protected = SlowOperationNode(\"protected\", config=protected_config)\n",
    "\n",
    "print(\"â±ï¸  Timeout Policy Configuration:\")\n",
    "print(f\"  Timeout duration: {timeout_policy.seconds}s\")\n",
    "print()\n",
    "\n",
    "print(\"ðŸ§ª Testing Timeout Protection:\")\n",
    "print()\n",
    "\n",
    "async def test_timeouts():\n",
    "    \"\"\"Test both protected and unprotected nodes.\"\"\"\n",
    "\n",
    "    # Test unprotected node\n",
    "    print(\"ðŸ”“ Unprotected Node (may take long time):\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        result = await slow_unprotected.do(NodeMessage(content={\"test\": \"unprotected\"}))\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"  Result: {result.content['status']} (took {elapsed:.2f}s)\")\n",
    "\n",
    "    except Exception as e:\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"  Error after {elapsed:.2f}s: {e}\")\n",
    "\n",
    "    print()\n",
    "    print(\"ðŸ”’ Protected Node (timeout after 1s):\")\n",
    "\n",
    "    # Test protected node multiple times\n",
    "    for i in range(3):\n",
    "        start_time = time.time()\n",
    "\n",
    "        try:\n",
    "            result = await slow_protected.do(NodeMessage(content={\"test\": f\"protected_{i}\"}))\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"  Attempt {i+1}: SUCCESS in {elapsed:.2f}s\")\n",
    "\n",
    "        except Exception as e:\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"  Attempt {i+1}: TIMEOUT after {elapsed:.2f}s ({type(e).__name__})\")\n",
    "\n",
    "await test_timeouts()\n",
    "\n",
    "print()\n",
    "print(\"ðŸ“‹ Timeout Policy Analysis:\")\n",
    "print(\"âœ“ Guaranteed maximum execution time\")\n",
    "print(\"âœ“ Prevents resource exhaustion from hanging operations\")\n",
    "print(\"âœ“ Clean error handling with timeout context\")\n",
    "print(\"âœ“ Works with any asyncio-compatible operation\")\n",
    "print(\"âœ“ Preserves original operation semantics\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Timeout Best Practices\n",
    "\n",
    "**Choosing timeout values:**\n",
    "\n",
    "```python\n",
    "# Fast operations (local processing, cache lookups)\n",
    "TimeoutPolicy(seconds=0.5)\n",
    "\n",
    "# Normal operations (API calls, database queries)\n",
    "TimeoutPolicy(seconds=5.0)\n",
    "\n",
    "# Slow operations (file processing, complex calculations)\n",
    "TimeoutPolicy(seconds=30.0)\n",
    "\n",
    "# External services (third-party APIs, ML inference)\n",
    "TimeoutPolicy(seconds=60.0)\n",
    "```\n",
    "\n",
    "**How to apply with NodeConfig:**\n",
    "\n",
    "```python\n",
    "# Fast timeout for critical path\n",
    "critical_config = NodeConfig(timeout=TimeoutPolicy(seconds=2.0))\n",
    "critical_node = CriticalNode(config=critical_config)\n",
    "\n",
    "# Longer timeout for batch operations\n",
    "batch_config = NodeConfig(timeout=TimeoutPolicy(seconds=300.0))  # 5 minutes\n",
    "batch_node = BatchNode(config=batch_config)\n",
    "\n",
    "# Combination with other policies (timeouts + retries)\n",
    "resilient_api_config = NodeConfig(\n",
    "    timeout=TimeoutPolicy(seconds=10.0),  # Per-attempt timeout\n",
    "    retry=RetryPolicy(max_attempts=3, delay=1.0),  # Handles transient failures\n",
    ")\n",
    "resilient_api_node = APINode(config=resilient_api_config)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Idempotency Policy - Preventing Duplicate Operations\n",
    "\n",
    "Let's implement idempotency to ensure operations run only once even if retried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Example 5: Idempotency Policy ===\n",
      "\n",
      "ðŸ”’ Idempotency Policy Configuration:\n",
      "  Key field: payment_id\n",
      "  Store type: InMemoryIdempotencyStore\n",
      "\n",
      "ðŸ’³ Testing Idempotency:\n",
      "\n",
      "ðŸ“ Attempt 1: New payment\n",
      "  ðŸ’³ Payment pay_12345: Processing $100.0\n",
      "  Result: processed - \n",
      "\n",
      "ðŸ“ Attempt 2: Duplicate payment\n",
      "  Result: processed - \n",
      "\n",
      "ðŸ“ Attempt 3: Different payment\n",
      "  ðŸ’³ Payment pay_67890: Processing $50.0\n",
      "  Result: processed - $50.0\n",
      "\n",
      "ðŸ“ Attempt 4: Duplicate second payment\n",
      "  Result: processed - \n",
      "\n",
      "ðŸ“Š Summary:\n",
      "  Unique payments processed: 2\n",
      "  Payment IDs: ['pay_12345', 'pay_67890']\n",
      "\n",
      "ðŸ“‹ Idempotency Policy Analysis:\n",
      "âœ“ Prevents duplicate operations across retries\n",
      "âœ“ Consistent responses for duplicate requests\n",
      "âœ“ Configurable key resolution from context\n",
      "âœ“ Pluggable storage backends (in-memory, database, Redis)\n",
      "âœ“ Automatic cleanup and expiration (with custom stores)\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Example 5: Idempotency Policy ===\")\n",
    "print()\n",
    "\n",
    "class PaymentProcessorNode(Node):\n",
    "    \"\"\"Node that processes payments (should be idempotent).\"\"\"\n",
    "    \n",
    "    def __init__(self, config: NodeConfig):\n",
    "        super().__init__(config)\n",
    "        self.processed_payments = set()  # Track processed payments\n",
    "    \n",
    "    async def process(self, context: ExecutionContext) -> Any:\n",
    "        # Extract payment ID from context\n",
    "        payment_id = context.inputs.content.get(\"payment_id\")\n",
    "        amount = context.inputs.content.get(\"amount\")\n",
    "        \n",
    "        if not payment_id:\n",
    "            raise ValueError(\"Missing payment_id\")\n",
    "        \n",
    "        # Check if already processed\n",
    "        if payment_id in self.processed_payments:\n",
    "            print(f\"  ðŸ”„ Payment {payment_id}: Already processed (idempotent response)\")\n",
    "            return {\n",
    "                \"payment_id\": payment_id,\n",
    "                \"status\": \"already_processed\",\n",
    "                \"message\": \"Payment was already processed\"\n",
    "            }\n",
    "        \n",
    "        # Process payment (simulate)\n",
    "        await asyncio.sleep(0.2)\n",
    "        print(f\"  ðŸ’³ Payment {payment_id}: Processing ${amount}\")\n",
    "        \n",
    "        # Mark as processed\n",
    "        self.processed_payments.add(payment_id)\n",
    "        \n",
    "        return {\n",
    "            \"payment_id\": payment_id,\n",
    "            \"amount\": amount,\n",
    "            \"status\": \"processed\",\n",
    "            \"timestamp\": time.time()\n",
    "        }\n",
    "\n",
    "# Configure idempotency policy with in-memory store\n",
    "idempotency_policy = IdempotencyPolicy(\n",
    "    config=IdempotencyConfig(\n",
    "        store=InMemoryIdempotencyStore(),\n",
    "        key_field=\"payment_id\",  # Use payment_id as the idempotency key\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create payment processor with idempotency\n",
    "payment_processor = PaymentProcessorNode(NodeConfig(idempotency=idempotency_policy))\n",
    "\n",
    "print(\"ðŸ”’ Idempotency Policy Configuration:\")\n",
    "print(f\"  Key field: {idempotency_policy.config.key_field}\")\n",
    "print(f\"  Store type: {type(idempotency_policy.config.store).__name__}\")\n",
    "print()\n",
    "\n",
    "print(\"ðŸ’³ Testing Idempotency:\")\n",
    "print()\n",
    "\n",
    "async def test_idempotency():\n",
    "    \"\"\"Test idempotency with duplicate payment attempts.\"\"\"\n",
    "    \n",
    "    # First attempt - should process\n",
    "    print(\"ðŸ“ Attempt 1: New payment\")\n",
    "    data = {\n",
    "        \"payment_id\": \"pay_12345\",\n",
    "        \"amount\": 100.00\n",
    "    }\n",
    "    #context = ExecutionContext(\n",
    "    #    inputs=NodeMessage(content={\n",
    "    #        \"payment_id\": \"pay_12345\",\n",
    "    #        \"amount\": 100.00\n",
    "    #    }),\n",
    "    #    state={}\n",
    "    #)\n",
    "    \n",
    "    result1 = await payment_processor.do(data)\n",
    "    print(f\"  Result: {result1.content['status']} - {result1.content.get('message', '')}\")\n",
    "    \n",
    "    # Second attempt - should return cached result\n",
    "    print(\"\\nðŸ“ Attempt 2: Duplicate payment\")\n",
    "    result2 = await payment_processor.do(data)\n",
    "    print(f\"  Result: {result2.content['status']} - {result2.content.get('message', '')}\")\n",
    "    \n",
    "    # Third attempt with different payment - should process\n",
    "    print(\"\\nðŸ“ Attempt 3: Different payment\")\n",
    "    data2 = {\n",
    "        \"payment_id\": \"pay_67890\",\n",
    "        \"amount\": 50.00\n",
    "    }\n",
    "    \n",
    "    result3 = await payment_processor.do(data2)\n",
    "    print(f\"  Result: {result3.content['status']} - ${result3.content['amount']}\")\n",
    "    \n",
    "    # Fourth attempt - return cached for second payment\n",
    "    print(\"\\nðŸ“ Attempt 4: Duplicate second payment\")\n",
    "    result4 = await payment_processor.do(data2)\n",
    "    print(f\"  Result: {result4.content['status']} - {result4.content.get('message', '')}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Summary:\")\n",
    "    print(f\"  Unique payments processed: {len(payment_processor.processed_payments)}\")\n",
    "    print(f\"  Payment IDs: {sorted(payment_processor.processed_payments)}\")\n",
    "\n",
    "await test_idempotency()\n",
    "\n",
    "print()\n",
    "print(\"ðŸ“‹ Idempotency Policy Analysis:\")\n",
    "print(\"âœ“ Prevents duplicate operations across retries\")\n",
    "print(\"âœ“ Consistent responses for duplicate requests\")\n",
    "print(\"âœ“ Configurable key resolution from context\")\n",
    "print(\"âœ“ Pluggable storage backends (in-memory, database, Redis)\")\n",
    "print(\"âœ“ Automatic cleanup and expiration (with custom stores)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idempotency Patterns\n",
    "\n",
    "**Key resolution strategies:**\n",
    "\n",
    "```python\n",
    "# Use field from input\n",
    "IdempotencyPolicy(key_field=\"transaction_id\")\n",
    "\n",
    "# Use custom resolver function\n",
    "def resolve_key(context):\n",
    "    return f\"{context.user_id}_{context.order_id}_{context.timestamp}\"\n",
    "\n",
    "IdempotencyPolicy(key_resolver=resolve_key)\n",
    "\n",
    "# Composite key from multiple fields\n",
    "def composite_key(context):\n",
    "    return hash((context.user_id, context.operation, context.timestamp[:10]))\n",
    "\n",
    "IdempotencyPolicy(key_resolver=composite_key)\n",
    "```\n",
    "\n",
    "**When to use idempotency:**\n",
    "\n",
    "âœ… **Financial operations**: Payments, transfers, refunds\n",
    "âœ… **External actions**: Email sending, SMS notifications, webhook calls\n",
    "âœ… **Resource creation**: User accounts, database records, file uploads\n",
    "âœ… **State changes**: Status updates, configuration changes\n",
    "\n",
    "**Storage backends:**\n",
    "\n",
    "```python\n",
    "# In-memory (testing, short-lived processes)\n",
    "InMemoryIdempotencyStore()\n",
    "\n",
    "# Redis (distributed systems)\n",
    "class RedisIdempotencyStore:\n",
    "    async def get(self, key): ...\n",
    "    async def set(self, key, record): ...\n",
    "    async def delete(self, key): ...\n",
    "\n",
    "# Database (persistent, transactional)\n",
    "class DatabaseIdempotencyStore:\n",
    "    async def get(self, key): ...\n",
    "    async def set(self, key, record): ...\n",
    "    async def delete(self, key): ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6: Combining Multiple Policies - Production-Grade Resilience\n",
    "\n",
    "Let's combine all policies to create a production-ready, resilient node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Example 6: Combined Policies ===\n",
      "\n",
      "ðŸ›¡ï¸  Production Node Configuration:\n",
      "  Timeout: 2.0s per operation\n",
      "  Retry: Up to 3 attempts with backoff\n",
      "  Circuit Breaker: Opens after 3 failures in 10s\n",
      "  Rate Limit: 2 calls/sec with burst of 3\n",
      "  Idempotency: Based on request_id\n",
      "\n",
      "ðŸš€ Testing Production Resilience:\n",
      "\n",
      "  âœ… user_service #1: Success\n",
      "  âœ… user_service #3: Success\n",
      "  âŒ user_service #2: Request timeout\n",
      "  âœ… user_service #4: Success\n",
      "  âœ… user_service #7: Success\n",
      "ðŸ“Š Results after 2.34 seconds:\n",
      "  Total requests: 10\n",
      "  Successful: 4\n",
      "  Timeout errors: 0\n",
      "  Circuit breaker errors: 0\n",
      "  Other errors: 6\n",
      "  Success rate: 40.0%\n",
      "âœ… Sample successful responses:\n",
      "  1. user_service #1\n",
      "  2. user_service #7\n",
      "  3. user_service #3\n",
      "\n",
      "ðŸ“‹ Production Resilience Analysis:\n",
      "âœ“ All policies work together seamlessly\n",
      "âœ“ Fast failure patterns prevent resource waste\n",
      "âœ“ Automatic recovery with appropriate backoff\n",
      "âœ“ Rate limiting prevents system overload\n",
      "âœ“ Idempotency ensures safe retry behavior\n",
      "âœ“ Comprehensive error handling and reporting\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"=== Example 6: Combined Policies ===\")\n",
    "print()\n",
    "\n",
    "class ProductionAPINode(Node):\n",
    "    \"\"\"Production-ready API node with comprehensive resilience.\"\"\"\n",
    "\n",
    "    def __init__(self, api_name: str, config: NodeConfig):\n",
    "        super().__init__(config=config)\n",
    "        self.api_name = api_name\n",
    "        self.request_count = 0\n",
    "\n",
    "    async def process(self, context: ExecutionContext) -> Any:\n",
    "        self.request_count += 1\n",
    "        request_id = self.request_count\n",
    "\n",
    "        # Simulate API call with variable behavior\n",
    "        await asyncio.sleep(random.uniform(0.1, 1.5))\n",
    "\n",
    "        # Simulate different failure modes\n",
    "        failure_chance = 0.3  # 30% failure rate\n",
    "        if random.random() < failure_chance:\n",
    "            error_types = [\n",
    "                (\"timeout\", \"Request timeout\"),\n",
    "                (\"rate_limit\", \"Rate limit exceeded\"),\n",
    "                (\"service_error\", \"Internal server error\"),\n",
    "            ]\n",
    "            error_type, error_msg = random.choice(error_types)\n",
    "\n",
    "            print(f\"  âŒ {self.api_name} #{request_id}: {error_msg}\")\n",
    "            raise NodeExecutionError(\n",
    "                kind=error_type,\n",
    "                node=self,\n",
    "                stage=\"_process\",\n",
    "                original=Exception(error_msg),\n",
    "                ctx_snapshot=context.snapshot(),\n",
    "            )\n",
    "\n",
    "        print(f\"  âœ… {self.api_name} #{request_id}: Success\")\n",
    "\n",
    "        return {\n",
    "            \"api\": self.api_name,\n",
    "            \"request_id\": request_id,\n",
    "            \"timestamp\": time.time(),\n",
    "            \"data\": f\"Response data from {self.api_name}\",\n",
    "        }\n",
    "\n",
    "# Apply all policies in the correct order via NodeConfig\n",
    "production_config = NodeConfig(\n",
    "    name=\"production_user_service\",\n",
    "    timeout=TimeoutPolicy(seconds=2.0),  # Innermost - controls individual operation time\n",
    "    retry=RetryPolicy(\n",
    "        max_attempts=3,\n",
    "        delay=0.5,\n",
    "        backoff_multiplier=2.0,\n",
    "        retry_on=(NodeExecutionError,),\n",
    "    ),  # Handles transient failures\n",
    "    circuit_breaker=CircuitBreakerPolicy(\n",
    "        breaker_key=\"user_service\",\n",
    "        circuit_breaker=CircuitBreaker(\n",
    "            failure_threshold=3,\n",
    "            window=10.0,\n",
    "            reset_timeout=5.0,\n",
    "        ),\n",
    "    ),  # Stops calling failing services\n",
    "    rate_limiter=RateLimiterPolicy(\n",
    "        resource_key=\"user_api\",\n",
    "        rate=Rate(limit=2.0, burst=3),\n",
    "    ),  # Controls overall request rate\n",
    "    idempotency=IdempotencyPolicy(\n",
    "        config=IdempotencyConfig(\n",
    "            store=InMemoryIdempotencyStore(),\n",
    "            key_field=\"request_id\",\n",
    "        ),\n",
    "    ),  # Prevents duplicate operations\n",
    ")\n",
    "\n",
    "production_node = ProductionAPINode(\"user_service\", config=production_config)\n",
    "\n",
    "print(\"ðŸ›¡ï¸  Production Node Configuration:\")\n",
    "print(f\"  Timeout: {production_config.timeout.seconds}s per operation\")\n",
    "print(f\"  Retry: Up to {production_config.retry.max_attempts} attempts with backoff\")\n",
    "print(\"  Circuit Breaker: Opens after 3 failures in 10s\")\n",
    "print(\"  Rate Limit: 2 calls/sec with burst of 3\")\n",
    "print(\"  Idempotency: Based on request_id\")\n",
    "print()\n",
    "\n",
    "print(\"ðŸš€ Testing Production Resilience:\")\n",
    "print()\n",
    "\n",
    "async def test_production_resilience():\n",
    "    \"\"\"Test the production node with various scenarios.\"\"\"\n",
    "\n",
    "    # Make multiple requests to stress test all policies\n",
    "    tasks = []\n",
    "    for i in range(10):\n",
    "        message = NodeMessage(content={\n",
    "            \"request_id\": f\"req_{i}\",\n",
    "            \"user_id\": f\"user_{i % 3}\",\n",
    "            \"action\": \"get_profile\",\n",
    "        })\n",
    "        task = asyncio.create_task(production_node.do(message))\n",
    "        tasks.append(task)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        results = await asyncio.wait_for(\n",
    "            asyncio.gather(*tasks, return_exceptions=True),\n",
    "            timeout=30.0,\n",
    "        )\n",
    "    except asyncio.TimeoutError:\n",
    "        print(\"â° Test timed out after 30 seconds\")\n",
    "        results = []\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    successful = [r for r in results if not isinstance(r, Exception)]\n",
    "    timeout_errors = [r for r in results if isinstance(r, Exception) and \"timeout\" in str(r).lower()]\n",
    "    circuit_errors = [r for r in results if isinstance(r, Exception) and \"circuit\" in str(r).lower()]\n",
    "    other_errors = [\n",
    "        r for r in results\n",
    "        if isinstance(r, Exception)\n",
    "        and r not in timeout_errors\n",
    "        and r not in circuit_errors\n",
    "    ]\n",
    "\n",
    "    print(f\"ðŸ“Š Results after {elapsed:.2f} seconds:\")\n",
    "    print(f\"  Total requests: {len(results)}\")\n",
    "    print(f\"  Successful: {len(successful)}\")\n",
    "    print(f\"  Timeout errors: {len(timeout_errors)}\")\n",
    "    print(f\"  Circuit breaker errors: {len(circuit_errors)}\")\n",
    "    print(f\"  Other errors: {len(other_errors)}\")\n",
    "    if results:\n",
    "        print(f\"  Success rate: {len(successful)/len(results)*100:.1f}%\")\n",
    "\n",
    "    if successful:\n",
    "        print(f\"âœ… Sample successful responses:\")\n",
    "        for i, message in enumerate(successful[:3]):\n",
    "            print(f\"  {i+1}. {message.content['api']} #{message.content['request_id']}\")\n",
    "\n",
    "await test_production_resilience()\n",
    "\n",
    "print()\n",
    "print(\"ðŸ“‹ Production Resilience Analysis:\")\n",
    "print(\"âœ“ All policies work together seamlessly\")\n",
    "print(\"âœ“ Fast failure patterns prevent resource waste\")\n",
    "print(\"âœ“ Automatic recovery with appropriate backoff\")\n",
    "print(\"âœ“ Rate limiting prevents system overload\")\n",
    "print(\"âœ“ Idempotency ensures safe retry behavior\")\n",
    "print(\"âœ“ Comprehensive error handling and reporting\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Policy Composition Best Practices\n",
    "\n",
    "**Policy order matters:**\n",
    "\n",
    "```python\n",
    "# CORRECT order inside NodeConfig (outermost to innermost):\n",
    "node_config = NodeConfig(\n",
    "    idempotency=IdempotencyPolicy(...),       # Outermost - check for duplicates first\n",
    "    rate_limiter=RateLimiterPolicy(...),      # Control request rate\n",
    "    circuit_breaker=CircuitBreakerPolicy(...),# Check if service is available\n",
    "    timeout=TimeoutPolicy(...),               # Control individual operation time\n",
    "    retry=RetryPolicy(...),                   # Handle transient failures with backoff\n",
    ")\n",
    "node = ProductionAPINode(config=node_config)\n",
    "```\n",
    "\n",
    "Spark applies these wrappers during node construction, so avoid stacking decorators or calling policy instances directly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Key Concepts Recap\n",
    "\n",
    "### Policy Design Patterns\n",
    "\n",
    "```python\n",
    "# 1. Fast-fail pattern (Circuit Breaker + Timeout)\n",
    "fast_fail_config = NodeConfig(\n",
    "    circuit_breaker=CircuitBreakerPolicy(...),\n",
    "    timeout=TimeoutPolicy(seconds=5.0),\n",
    ")\n",
    "fast_fail_node = SomeNode(config=fast_fail_config)\n",
    "\n",
    "# 2. Idempotent retry pattern (Idempotency + Retry)\n",
    "safe_retry_config = NodeConfig(\n",
    "    idempotency=IdempotencyPolicy(...),\n",
    "    retry=RetryPolicy(max_attempts=3),\n",
    ")\n",
    "safe_retry_node = SomeNode(config=safe_retry_config)\n",
    "\n",
    "# 3. Rate-limited, circuit-protected API calls\n",
    "api_node_config = NodeConfig(\n",
    "    rate_limiter=RateLimiterPolicy(...),\n",
    "    circuit_breaker=CircuitBreakerPolicy(...),\n",
    "    timeout=TimeoutPolicy(seconds=10.0),\n",
    ")\n",
    "api_node = APINode(config=api_node_config)\n",
    "```\n",
    "\n",
    "Configure policies on `NodeConfig` so they are applied once at construction time and remain easy to audit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "        ## ðŸŽ¯ Summary & Next Steps\n",
    "\n",
    "        ### Congratulations! ðŸŽ‰\n",
    "\n",
    "        You've mastered node policies for building resilient Spark workflows! You can now create production-ready systems that handle failures gracefully and maintain high availability.\n",
    "\n",
    "        ### What You Learned:\n",
    "\n",
    "        âœ… **Retry Policies**\n",
    "        - Automatic retry with exponential backoff\n",
    "        - Configurable attempt limits and delays\n",
    "        - Selective retry based on error types\n",
    "        - Jitter for avoiding thundering herd\n",
    "\n",
    "        âœ… **Rate Limiting**\n",
    "        - Token bucket algorithm for smooth rate limiting\n",
    "        - Burst capacity for handling traffic spikes\n",
    "        - Shared limits across multiple nodes\n",
    "        - Per-resource isolation and control\n",
    "\n",
    "        âœ… **Circuit Breakers**\n",
    "        - Fast failure when services are down\n",
    "        - Automatic recovery detection\n",
    "        - Configurable failure thresholds\n",
    "        - Prevention of cascade failures\n",
    "\n",
    "        âœ… **Timeout Policies**\n",
    "        - Guaranteed maximum execution time\n",
    "        - Prevention of hanging operations\n",
    "        - Clean timeout error handling\n",
    "        - Resource protection and cleanup\n",
    "\n",
    "        âœ… **Idempotency Policies**\n",
    "        - Prevention of duplicate operations\n",
    "        - Consistent responses for retries\n",
    "        - Pluggable storage backends\n",
    "        - Configurable key resolution\n",
    "\n",
    "        âœ… **Policy Composition**\n",
    "        - Stacking multiple policies effectively\n",
    "        - Correct policy ordering for optimal behavior\n",
    "        - Scenario-specific policy combinations\n",
    "        - Integration with Graph workflows\n",
    "\n",
    "        ### Key Patterns to Remember:\n",
    "\n",
    "        ```python\n",
    "        # Basic resilient node\n",
    "        basic_config = NodeConfig(\n",
    "            timeout=TimeoutPolicy(seconds=10.0),\n",
    "            retry=RetryPolicy(max_attempts=3, delay=1.0),\n",
    "        )\n",
    "\n",
    "        class MyNode(Node):\n",
    "            async def process(self, context):\n",
    "                # Business logic\n",
    "                return result\n",
    "\n",
    "        my_node = MyNode(config=basic_config)\n",
    "\n",
    "        # Production-grade node\n",
    "        prod_config = NodeConfig(\n",
    "            idempotency=IdempotencyPolicy(...),\n",
    "            rate_limiter=RateLimiterPolicy(...),\n",
    "            circuit_breaker=CircuitBreakerPolicy(...),\n",
    "            retry=RetryPolicy(max_attempts=5, delay=2.0, backoff_multiplier=2.0),\n",
    "            timeout=TimeoutPolicy(seconds=30.0),\n",
    "        )\n",
    "\n",
    "        class ProductionNode(Node):\n",
    "            async def process(self, context):\n",
    "                # Critical business logic\n",
    "                return result\n",
    "\n",
    "        prod_node = ProductionNode(config=prod_config)\n",
    "        ```\n",
    "\n",
    "        ### ðŸ“š Related Resources:\n",
    "\n",
    "        - Source: `spark/nodes/policies.py` - Complete policy implementations\n",
    "        - Examples: `examples/e011_agent_enhancements.py` - Agent resilience features\n",
    "        - Tutorial 7: Tools - Integration with agent tool calling\n",
    "        - Tutorial 4: Your First AI Agent - Basic node concepts\n",
    "\n",
    "        ### ðŸš€ Next Tutorial: Advanced Graph Patterns\n",
    "\n",
    "        In **Tutorial 9**, you'll learn how to:\n",
    "        - Implement conditional routing and decision trees\n",
    "        - Use subgraphs for modular workflow design\n",
    "        - Create dynamic workflows with runtime configuration\n",
    "        - Handle complex data flows and transformations\n",
    "        - Optimize graph performance and parallelism\n",
    "\n",
    "        ### ðŸ”§ Before You Move On:\n",
    "\n",
    "        Make sure you can:\n",
    "        1. âœ… Apply individual policies (Retry, Timeout, Rate Limit, Circuit Breaker, Idempotency)\n",
    "        2. âœ… Combine multiple policies in the correct order\n",
    "        3. âœ… Choose appropriate policy configurations for different scenarios\n",
    "        4. âœ… Handle policy-specific errors gracefully\n",
    "        5. âœ… Use policies within Graph workflows\n",
    "        6. âœ… Monitor and debug policy behavior\n",
    "        7. âœ… Design resilient architectures for production systems\n",
    "        8. âœ… Balance resilience with performance considerations\n",
    "\n",
    "        ### ðŸŽ“ Tutorial Series Progress:\n",
    "\n",
    "        - âœ… **Tutorial 1: Hello Spark** - Basic nodes\n",
    "        - âœ… **Tutorial 2: Batch Processing** - Parallel execution\n",
    "        - âœ… **Tutorial 3: Simple Flows** - Graph basics\n",
    "        - âœ… **Tutorial 4: Your First AI Agent** - Agent fundamentals\n",
    "        - âœ… **Tutorial 5: Conditional Routing** - Decision making\n",
    "        - âœ… **Tutorial 6: Agent Config & Memory** - Configuration\n",
    "        - âœ… **Tutorial 7: Tools** - Agent capabilities\n",
    "        - âœ… **Tutorial 8: Node Policies** - *You are here!* ðŸŽ¯\n",
    "        - âž¡ï¸ **Tutorial 9: Advanced Graph Patterns**\n",
    "\n",
    "        ### ðŸŒŸ Pro Tips:\n",
    "\n",
    "        - **Start simple**: Add policies incrementally based on observed failures\n",
    "        - **Monitor first**: Understand your failure patterns before adding complexity\n",
    "        - **Test failures**: Simulate failures to verify policy behavior\n",
    "        - **Configure appropriately**: Tune policy parameters based on SLA requirements\n",
    "        - **Order matters**: Place policies in the correct sequence for optimal behavior\n",
    "        - **Use in Graphs**: Policies work seamlessly within Graph workflows\n",
    "        - **Monitor policy metrics**: Track policy effectiveness and adjust as needed\n",
    "        - **Document behavior**: Explain why each policy is chosen and configured\n",
    "\n",
    "        ### ðŸŽ¯ Challenge Before Next Tutorial:\n",
    "\n",
    "        Build a \"Resilient Data Pipeline\" that:\n",
    "1. Fetches data from multiple sources with appropriate rate limiting\n",
    "2. Processes data with timeout protection\n",
    "3. Stores results with idempotency guarantees\n",
    "4. Handles external service failures with circuit breakers\n",
    "5. Retries transient failures appropriately\n",
    "6. Provides comprehensive error handling and fallbacks\n",
    "7. Includes monitoring and observability features\n",
    "\n",
    "This will prepare you for advanced graph patterns in Tutorial 9!\n",
    "\n",
    "---\n",
    "\n",
    "**You're now ready to build production-ready, resilient workflows with Spark!** ðŸš€\n",
    "\n",
    "### ðŸ“ Production Features Summary:\n",
    "\n",
    "The following resilience features are now available in Spark:\n",
    "\n",
    "âœ… **Retry Policies** - Automatic recovery from transient failures\n",
    "âœ… **Rate Limiting** - Resource protection and traffic control\n",
    "âœ… **Circuit Breakers** - Fast failure and automatic recovery\n",
    "âœ… **Timeout Protection** - Prevention of hanging operations\n",
    "âœ… **Idempotency** - Safe retry behavior and duplicate prevention\n",
    "âœ… **Policy Composition** - Flexible combination of resilience patterns\n",
    "âœ… **Graph Integration** - Seamless use within workflow graphs\n",
    "âœ… **Comprehensive Error Handling** - Detailed error context and recovery strategies\n",
    "\n",
    "These features enable enterprise-grade reliability and resilience for mission-critical workflows!\n",
    "\n",
    "Have questions or feedback? Check the Spark documentation or open an issue on GitHub.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
