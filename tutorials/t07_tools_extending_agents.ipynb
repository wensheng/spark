{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 7: Tools - Extending Agent Capabilities\n",
    "\n",
    "**Difficulty:** Intermediate-Advanced | **Time:** 40 minutes\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Create custom tools for agents\n",
    "- Understand tool calling mechanics and flow\n",
    "- Master tool function definition with docstrings and type hints\n",
    "- Configure tool choice strategies\n",
    "- Debug tool execution with traces\n",
    "- Build multi-step tool-based workflows\n",
    "- Handle tool errors gracefully\n",
    "\n",
    "## Real-World Use Cases\n",
    "\n",
    "Tools transform agents from passive responders into active problem solvers:\n",
    "\n",
    "- **Research Assistant**: Uses web search, database queries, and document retrieval tools\n",
    "- **Code Analysis Agent**: Executes code, reads files, runs tests, and generates documentation\n",
    "- **Customer Support Bot**: Checks order status, processes refunds, updates tickets\n",
    "- **Data Analyst**: Queries databases, runs calculations, generates visualizations\n",
    "- **Personal Assistant**: Manages calendar, sends emails, sets reminders\n",
    "- **DevOps Agent**: Monitors systems, deploys code, manages infrastructure\n",
    "\n",
    "In this tutorial, you'll learn how to give your agents superpowers by integrating custom tools!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Concepts\n",
    "\n",
    "### What Are Tools?\n",
    "\n",
    "**Tools** are functions that agents can call to perform actions or retrieve information. They extend agents beyond text generation to interact with external systems, execute code, access databases, and more.\n",
    "\n",
    "**Key characteristics:**\n",
    "- Defined as Python functions with clear signatures\n",
    "- Automatically discovered via the `@tool` decorator\n",
    "- Have descriptive docstrings that guide the LLM\n",
    "- Use type hints for parameter validation\n",
    "- Return structured results\n",
    "\n",
    "### Tool Calling Flow\n",
    "\n",
    "```\n",
    "User Query â†’ Agent â†’ LLM decides to use tool\n",
    "                â†“\n",
    "           Tool executed with parameters\n",
    "                â†“\n",
    "           Result returned to LLM\n",
    "                â†“\n",
    "           LLM formulates final answer\n",
    "```\n",
    "\n",
    "### The @tool Decorator\n",
    "\n",
    "The `@tool` decorator transforms regular Python functions into agent-callable tools:\n",
    "\n",
    "```python\n",
    "from spark.tools.decorator import tool\n",
    "\n",
    "@tool\n",
    "def get_weather(city: str, units: str = \"celsius\") -> str:\n",
    "    \"\"\"Get the current weather for a given city.\n",
    "    \n",
    "    Args:\n",
    "        city: The name of the city\n",
    "        units: Temperature units (celsius or fahrenheit)\n",
    "        \n",
    "    Returns:\n",
    "        Weather information as a string\n",
    "    \"\"\"\n",
    "    # Implementation here\n",
    "    return f\"Weather in {city}: 22Â°{units[0].upper()}\"\n",
    "```\n",
    "\n",
    "**What the decorator does:**\n",
    "1. Extracts function metadata (name, parameters, return type)\n",
    "2. Parses the docstring for descriptions\n",
    "3. Creates a JSON schema from type hints\n",
    "4. Validates inputs before execution\n",
    "5. Formats outputs for the LLM\n",
    "\n",
    "### Tool Choice Strategies\n",
    "\n",
    "Control how agents decide which tools to use via `AgentConfig.tool_choice`:\n",
    "\n",
    "**1. `auto` (default)**: LLM decides whether to use tools\n",
    "- Most flexible and common\n",
    "- Agent uses tools when needed\n",
    "- Can also answer directly without tools\n",
    "\n",
    "**2. `any`**: Force the agent to use at least one tool\n",
    "- Ensures tool usage\n",
    "- Useful when you always want an action performed\n",
    "- Agent cannot respond without calling a tool\n",
    "\n",
    "**3. Specific tool**: Force a specific tool by name\n",
    "- Agent must use the specified tool\n",
    "- Useful for deterministic workflows\n",
    "- Format: `{'type': 'tool', 'name': 'tool_name'}`\n",
    "\n",
    "**4. `none`**: Disable all tools\n",
    "- Agent cannot use any tools\n",
    "- Useful for final answer generation\n",
    "- Only generates text responses\n",
    "\n",
    "Example configuration:\n",
    "```python\n",
    "# Auto mode (default)\n",
    "config = AgentConfig(\n",
    "    model=model,\n",
    "    tools=[search, calculate],\n",
    "    tool_choice='auto'\n",
    ")\n",
    "\n",
    "# Force tool usage\n",
    "config = AgentConfig(\n",
    "    model=model,\n",
    "    tools=[search],\n",
    "    tool_choice='any'\n",
    ")\n",
    "\n",
    "# Force specific tool\n",
    "config = AgentConfig(\n",
    "    model=model,\n",
    "    tools=[search, calculate],\n",
    "    tool_choice={'type': 'tool', 'name': 'search'}\n",
    ")\n",
    "```\n",
    "\n",
    "### Multi-Step Tool Calling\n",
    "\n",
    "Agents can call multiple tools in sequence, controlled by `max_steps`:\n",
    "\n",
    "```\n",
    "1. User: \"Find and summarize recent AI research papers\"\n",
    "2. Agent â†’ search_papers(\"AI research\") â†’ returns paper list\n",
    "3. Agent â†’ get_paper_content(paper_id) â†’ returns full text\n",
    "4. Agent â†’ summarize_text(text) â†’ returns summary\n",
    "5. Agent â†’ Final answer with summarized papers\n",
    "```\n",
    "\n",
    "**max_steps Configuration**:\n",
    "- Limits the number of reasoning iterations\n",
    "- Prevents infinite loops in complex workflows\n",
    "- Default: 10 iterations\n",
    "- Each tool call + response counts as one step\n",
    "\n",
    "### Tool Traces\n",
    "\n",
    "Track tool execution for debugging and monitoring:\n",
    "- Which tools were called\n",
    "- What parameters were passed\n",
    "- What results were returned\n",
    "- Timing information\n",
    "- Errors encountered\n",
    "\n",
    "Tool traces are automatically tracked in `AgentState.tool_trace` and can be accessed after execution for analysis and debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's import the necessary classes for building tool-enabled agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import core Spark classes\n",
    "from spark.agents.agent import Agent\n",
    "from spark.agents.config import AgentConfig\n",
    "from spark.tools.decorator import tool, ToolContext\n",
    "from spark.models.openai import OpenAIModel\n",
    "from spark.models.echo import EchoModel\n",
    "from spark.utils import arun\n",
    "from typing import Any, Optional, Literal\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Your First Tool - Simple Calculator\n",
    "\n",
    "Let's start by creating a simple calculator tool and giving it to an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Example 1: Simple Calculator Tool ===\")\n",
    "print()\n",
    "\n",
    "# Define a simple calculator tool\n",
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Evaluate a mathematical expression and return the result.\n",
    "    \n",
    "    Args:\n",
    "        expression: A mathematical expression as a string (e.g., \"2 + 2\", \"10 * 5\")\n",
    "        \n",
    "    Returns:\n",
    "        The result of the calculation as a string\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Safe evaluation of mathematical expressions\n",
    "        # Note: In production, use a safer alternative to eval()\n",
    "        result = eval(expression, {\"__builtins__\": {}}, {})\n",
    "        print(f\"  ðŸ”§ Tool called: calculate('{expression}') = {result}\")\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Create an agent with the calculator tool\n",
    "calc_config = AgentConfig(\n",
    "    model=OpenAIModel(model_id='gpt-5-nano'),\n",
    "    name='calculator_agent',\n",
    "    system_prompt='You are a helpful math assistant. Use the calculate tool to perform calculations.',\n",
    "    tools=[calculate],  # Add the tool to the agent\n",
    ")\n",
    "\n",
    "calc_agent = Agent(calc_config)\n",
    "\n",
    "print(\"ðŸ¤– Calculator Agent\")\n",
    "print(f\"Available tools: {[tool.tool_name for tool in calc_agent.tool_registry.registry.values()]}\")\n",
    "print()\n",
    "\n",
    "# Test the agent\n",
    "question = \"What is 127 * 45?\"\n",
    "print(f\"User: {question}\")\n",
    "print()\n",
    "\n",
    "result = await calc_agent.do({'messages': [{'role': 'user', 'content': question}]})\n",
    "print(f\"\\nAssistant: {result.content}\")\n",
    "print('Tool traces:', calc_agent.get_tool_traces())\n",
    "print()\n",
    "\n",
    "print(\"ðŸ“Š Analysis:\")\n",
    "print(\"âœ“ Tool was automatically registered from the @tool decorator\")\n",
    "print(\"âœ“ Agent received tool specification with name, description, and parameters\")\n",
    "print(\"âœ“ LLM can now decide when to use the calculator\")\n",
    "print(\"âœ“ Tool execution is transparent to the user\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Tool Registration\n",
    "\n",
    "**How tools are registered:**\n",
    "\n",
    "1. **@tool decorator** extracts metadata:\n",
    "   - Function name â†’ tool name\n",
    "   - Docstring â†’ tool description (sent to LLM)\n",
    "   - Type hints â†’ parameter types and validation\n",
    "   - Parameter descriptions from docstring Args section\n",
    "\n",
    "2. **ToolRegistry** manages tools:\n",
    "   - Stores tool specifications\n",
    "   - Validates tool definitions\n",
    "   - Provides tools to the model\n",
    "\n",
    "3. **Agent** coordinates:\n",
    "   - Passes tool specs to the model\n",
    "   - Receives tool call requests from LLM\n",
    "   - Executes tools with provided parameters\n",
    "   - Returns results back to LLM\n",
    "\n",
    "**Best practices:**\n",
    "- Write clear, descriptive docstrings (LLM reads these!)\n",
    "- Use type hints for all parameters\n",
    "- Handle errors gracefully\n",
    "- Keep tool functions focused and simple\n",
    "- Return string results for text-based LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Multiple Tools - Research Assistant\n",
    "\n",
    "Let's build a research assistant with multiple tools for web search and content retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Example 2: Multi-Tool Research Assistant ===\")\n",
    "print()\n",
    "\n",
    "# Define multiple research tools\n",
    "@tool\n",
    "def search_web(query: str) -> str:\n",
    "    \"\"\"Search the web for information about a given query.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query string\n",
    "        \n",
    "    Returns:\n",
    "        Search results as a formatted string\n",
    "    \"\"\"\n",
    "    print(f\"  ðŸ” Searching web for: '{query}'\")\n",
    "    # Simulated search results\n",
    "    results = f\"\"\"Search results for '{query}':\n",
    "1. Article: Introduction to {query}\n",
    "2. Research paper: Recent advances in {query}\n",
    "3. Tutorial: Getting started with {query}\"\"\"\n",
    "    return results\n",
    "\n",
    "@tool\n",
    "def get_current_date() -> str:\n",
    "    \"\"\"Get the current date and time.\n",
    "    \n",
    "    Returns:\n",
    "        Current date and time as a formatted string\n",
    "    \"\"\"\n",
    "    print(\"  ðŸ“… Getting current date\")\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "@tool\n",
    "def count_words(text: str) -> str:\n",
    "    \"\"\"Count the number of words in a given text.\n",
    "    \n",
    "    Args:\n",
    "        text: The text to count words in\n",
    "        \n",
    "    Returns:\n",
    "        Number of words as a string\n",
    "    \"\"\"\n",
    "    word_count = len(text.split())\n",
    "    print(f\"  ðŸ“ Counting words: {word_count} words\")\n",
    "    return str(word_count)\n",
    "\n",
    "# Create research assistant with all tools\n",
    "research_config = AgentConfig(\n",
    "    model=OpenAIModel(model_id='gpt-5-nano'),\n",
    "    name='research_assistant',\n",
    "    system_prompt=\"\"\"You are a helpful research assistant with access to multiple tools.\n",
    "Use the appropriate tools to answer questions:\n",
    "- Use search_web to find information online\n",
    "- Use get_current_date for time-related queries\n",
    "- Use count_words to analyze text\n",
    "\n",
    "You can call multiple tools if needed to fully answer the question.\"\"\",\n",
    "    tools=[search_web, get_current_date, count_words],\n",
    ")\n",
    "\n",
    "research_agent = Agent(research_config)\n",
    "\n",
    "print(\"ðŸ¤– Research Assistant\")\n",
    "print(f\"Available tools: {[tool.tool_name for tool in research_agent.tool_registry.registry.values()]}\")\n",
    "print()\n",
    "\n",
    "# Test with a query requiring multiple tools\n",
    "questions = [\n",
    "    \"What's today's date?\",\n",
    "    \"Search for information about quantum computing\",\n",
    "    \"How many words are in this sentence: The quick brown fox jumps over the lazy dog\",\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"User: {question}\")\n",
    "    result = await research_agent.do({'messages': [{'role': 'user', 'content': question}]})\n",
    "    print(f\"Assistant: {result.content}\")\n",
    "    print()\n",
    "\n",
    "print(\"ðŸ“Š Analysis:\")\n",
    "print(\"âœ“ Agent has access to multiple specialized tools\")\n",
    "print(\"âœ“ LLM selects the appropriate tool based on the question\")\n",
    "print(\"âœ“ Each tool is focused on a specific task\")\n",
    "print(\"âœ“ Tools can be composed for complex queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool Selection Strategy\n",
    "\n",
    "**How the LLM chooses tools:**\n",
    "\n",
    "1. **Analyzes the user query** to understand intent\n",
    "2. **Reviews available tool descriptions** from docstrings\n",
    "3. **Matches query to tool capabilities**\n",
    "4. **Generates tool call** with appropriate parameters\n",
    "5. **Processes tool result** and formulates answer\n",
    "\n",
    "**Writing good tool descriptions:**\n",
    "\n",
    "âœ… **Good:**\n",
    "```python\n",
    "@tool\n",
    "def search_web(query: str) -> str:\n",
    "    \"\"\"Search the web for current information about a given topic.\n",
    "    Use this when you need up-to-date information or facts you don't know.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query (e.g., 'latest AI news', 'Python tutorial')\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "âŒ **Bad:**\n",
    "```python\n",
    "@tool\n",
    "def search_web(query: str) -> str:\n",
    "    \"\"\"Searches.\"\"\"\n",
    "```\n",
    "\n",
    "**Tips for tool descriptions:**\n",
    "- Be specific about what the tool does\n",
    "- Mention when the tool should be used\n",
    "- Provide example parameter values\n",
    "- Explain the format of the return value\n",
    "- Mention any limitations or constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Type Hints and Parameter Validation\n",
    "\n",
    "Type hints provide automatic parameter validation and clear API contracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Example 3: Type Hints and Validation ===\")\n",
    "print()\n",
    "\n",
    "from typing import Literal, Optional\n",
    "\n",
    "# Tool with rich type hints\n",
    "@tool\n",
    "def format_temperature(\n",
    "    value: float,\n",
    "    from_unit: Literal[\"celsius\", \"fahrenheit\", \"kelvin\"],\n",
    "    to_unit: Literal[\"celsius\", \"fahrenheit\", \"kelvin\"],\n",
    "    precision: int = 2\n",
    ") -> str:\n",
    "    \"\"\"Convert temperature between different units.\n",
    "    \n",
    "    Args:\n",
    "        value: The temperature value to convert\n",
    "        from_unit: Source temperature unit (celsius, fahrenheit, or kelvin)\n",
    "        to_unit: Target temperature unit (celsius, fahrenheit, or kelvin)\n",
    "        precision: Number of decimal places (default: 2)\n",
    "        \n",
    "    Returns:\n",
    "        Formatted temperature string with the converted value\n",
    "    \"\"\"\n",
    "    print(f\"  ðŸŒ¡ï¸  Converting {value}Â°{from_unit[0].upper()} to {to_unit}\")\n",
    "    \n",
    "    # Conversion logic (simplified)\n",
    "    # First convert to Celsius\n",
    "    if from_unit == \"fahrenheit\":\n",
    "        celsius = (value - 32) * 5/9\n",
    "    elif from_unit == \"kelvin\":\n",
    "        celsius = value - 273.15\n",
    "    else:\n",
    "        celsius = value\n",
    "    \n",
    "    # Then convert to target unit\n",
    "    if to_unit == \"fahrenheit\":\n",
    "        result = celsius * 9/5 + 32\n",
    "    elif to_unit == \"kelvin\":\n",
    "        result = celsius + 273.15\n",
    "    else:\n",
    "        result = celsius\n",
    "    \n",
    "    return f\"{result:.{precision}f}Â°{to_unit[0].upper()}\"\n",
    "\n",
    "# Tool with optional parameters\n",
    "@tool\n",
    "def send_notification(\n",
    "    message: str,\n",
    "    priority: Literal[\"low\", \"medium\", \"high\"] = \"medium\",\n",
    "    channel: Optional[str] = None\n",
    ") -> str:\n",
    "    \"\"\"Send a notification with a message.\n",
    "    \n",
    "    Args:\n",
    "        message: The notification message to send\n",
    "        priority: Notification priority level (default: medium)\n",
    "        channel: Optional channel to send to (e.g., 'email', 'slack')\n",
    "        \n",
    "    Returns:\n",
    "        Confirmation message\n",
    "    \"\"\"\n",
    "    channel_str = f\" via {channel}\" if channel else \"\"\n",
    "    print(f\"  ðŸ“¢ Sending {priority} priority notification{channel_str}\")\n",
    "    return f\"Notification sent: {message} [priority={priority}]\"\n",
    "\n",
    "# Create agent with typed tools\n",
    "typed_config = AgentConfig(\n",
    "    model=OpenAIModel(model_id='gpt-5-nano'),\n",
    "    name='typed_agent',\n",
    "    system_prompt='You are an assistant with precisely defined tools. Use them correctly.',\n",
    "    tools=[format_temperature, send_notification],\n",
    ")\n",
    "\n",
    "typed_agent = Agent(typed_config)\n",
    "\n",
    "print(\"ðŸ¤– Typed Tools Agent\")\n",
    "print()\n",
    "\n",
    "# Demonstrate tool usage\n",
    "print(\"ðŸ“‹ Tool Specifications:\")\n",
    "print()\n",
    "for tool_name, tool_obj in typed_agent.tool_registry.registry.items():\n",
    "    spec = tool_obj.tool_spec\n",
    "    print(f\"Tool: {spec['name']}\")\n",
    "    print(f\"Description: {spec['description'][:80]}...\")\n",
    "    print(f\"Parameters: {list(spec['parameters']['json'].get('properties', {}).keys())}\")\n",
    "    print()\n",
    "\n",
    "print(\"ðŸ“Š Analysis:\")\n",
    "print(\"âœ“ Literal types constrain values to specific options\")\n",
    "print(\"âœ“ Optional parameters have default values\")\n",
    "print(\"âœ“ Type hints generate JSON schema automatically\")\n",
    "print(\"âœ“ Invalid parameters are caught before execution\")\n",
    "print(\"âœ“ LLM understands parameter constraints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type Hints Best Practices\n",
    "\n",
    "**Supported type hints:**\n",
    "\n",
    "```python\n",
    "# Basic types\n",
    "param: str          # String\n",
    "param: int          # Integer\n",
    "param: float        # Float\n",
    "param: bool         # Boolean\n",
    "\n",
    "# Optional parameters\n",
    "param: Optional[str] = None    # Can be None\n",
    "param: str = \"default\"         # Has default value\n",
    "\n",
    "# Constrained values\n",
    "param: Literal[\"option1\", \"option2\"]  # Must be one of these\n",
    "\n",
    "# Collections\n",
    "param: list[str]     # List of strings\n",
    "param: dict[str, int]  # Dictionary\n",
    "```\n",
    "\n",
    "**Why type hints matter:**\n",
    "\n",
    "1. **Validation**: Catches errors before execution\n",
    "2. **Documentation**: Makes tool API clear\n",
    "3. **IDE support**: Better autocomplete and type checking\n",
    "4. **LLM guidance**: Helps LLM use tools correctly\n",
    "5. **Schema generation**: Automatic JSON schema creation\n",
    "\n",
    "**Common patterns:**\n",
    "\n",
    "```python\n",
    "# Enum-like choices with Literal\n",
    "@tool\n",
    "def set_mode(mode: Literal[\"easy\", \"medium\", \"hard\"]) -> str:\n",
    "    \"\"\"Set difficulty mode.\"\"\"\n",
    "    pass\n",
    "\n",
    "# Optional with sensible default\n",
    "@tool\n",
    "def fetch_data(url: str, timeout: int = 30) -> str:\n",
    "    \"\"\"Fetch data from URL with optional timeout.\"\"\"\n",
    "    pass\n",
    "\n",
    "# Multiple related parameters\n",
    "@tool\n",
    "def create_user(name: str, email: str, age: Optional[int] = None) -> str:\n",
    "    \"\"\"Create a new user with optional age.\"\"\"\n",
    "    pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Error Handling in Tools\n",
    "\n",
    "Proper error handling ensures tools fail gracefully and provide useful feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Example 4: Error Handling ===\")\n",
    "print()\n",
    "\n",
    "# Tool with robust error handling\n",
    "@tool\n",
    "def divide_numbers(numerator: float, denominator: float) -> str:\n",
    "    \"\"\"Divide two numbers and return the result.\n",
    "    \n",
    "    Args:\n",
    "        numerator: The number to divide\n",
    "        denominator: The number to divide by\n",
    "        \n",
    "    Returns:\n",
    "        The division result or an error message\n",
    "    \"\"\"\n",
    "    print(f\"  âž— Dividing {numerator} by {denominator}\")\n",
    "    \n",
    "    try:\n",
    "        if denominator == 0:\n",
    "            return \"Error: Cannot divide by zero. Please provide a non-zero denominator.\"\n",
    "        \n",
    "        result = numerator / denominator\n",
    "        return f\"Result: {result}\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error: Unexpected error occurred: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def read_file(filepath: str) -> str:\n",
    "    \"\"\"Read and return the contents of a file.\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path to the file to read\n",
    "        \n",
    "    Returns:\n",
    "        File contents or an error message\n",
    "    \"\"\"\n",
    "    print(f\"  ðŸ“„ Reading file: {filepath}\")\n",
    "    \n",
    "    try:\n",
    "        # Simulated file reading with validation\n",
    "        if not filepath:\n",
    "            return \"Error: Filepath cannot be empty\"\n",
    "        \n",
    "        if not filepath.endswith('.txt'):\n",
    "            return \"Error: Only .txt files are supported\"\n",
    "        \n",
    "        # Simulated file content\n",
    "        return f\"File contents of {filepath}: Hello, World!\"\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: File not found: {filepath}\"\n",
    "    except PermissionError:\n",
    "        return f\"Error: Permission denied to read {filepath}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: Failed to read file: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def parse_json(json_string: str) -> str:\n",
    "    \"\"\"Parse a JSON string and return a formatted representation.\n",
    "    \n",
    "    Args:\n",
    "        json_string: Valid JSON string to parse\n",
    "        \n",
    "    Returns:\n",
    "        Parsed JSON or an error message\n",
    "    \"\"\"\n",
    "    print(f\"  ðŸ“¦ Parsing JSON\")\n",
    "    \n",
    "    try:\n",
    "        parsed = json.loads(json_string)\n",
    "        return f\"Parsed successfully: {json.dumps(parsed, indent=2)}\"\n",
    "    \n",
    "    except json.JSONDecodeError as e:\n",
    "        return f\"Error: Invalid JSON format: {str(e)}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: Failed to parse JSON: {str(e)}\"\n",
    "\n",
    "# Create agent with error-handling tools\n",
    "error_config = AgentConfig(\n",
    "    model=OpenAIModel(model_id='gpt-5-nano'),\n",
    "    name='robust_agent',\n",
    "    system_prompt=\"\"\"You are a helpful assistant with robust tools.\n",
    "When tools return errors, explain the error to the user and suggest corrections.\n",
    "Be helpful and guide users to successful tool usage.\"\"\",\n",
    "    tools=[divide_numbers, read_file, parse_json],\n",
    ")\n",
    "\n",
    "robust_agent = Agent(error_config)\n",
    "\n",
    "print(\"ðŸ¤– Robust Agent with Error Handling\")\n",
    "print()\n",
    "\n",
    "# Test error scenarios\n",
    "test_cases = [\n",
    "    (\"Divide 10 by 0\", \"Tests division by zero\"),\n",
    "    (\"Read the file test.pdf\", \"Tests unsupported file type\"),\n",
    "    (\"Parse this JSON: {invalid json}\", \"Tests invalid JSON\"),\n",
    "]\n",
    "\n",
    "for query, description in test_cases:\n",
    "    print(f\"Test: {description}\")\n",
    "    print(f\"User: {query}\")\n",
    "    # In a real scenario, these would trigger tool calls\n",
    "    print(\"  [Tool would execute and handle error]\")\n",
    "    print()\n",
    "\n",
    "print(\"ðŸ“Š Error Handling Best Practices:\")\n",
    "print(\"âœ“ Check input parameters before processing\")\n",
    "print(\"âœ“ Catch specific exceptions (FileNotFoundError, etc.)\")\n",
    "print(\"âœ“ Provide clear, actionable error messages\")\n",
    "print(\"âœ“ Return errors as strings, not raise exceptions\")\n",
    "print(\"âœ“ Include context in error messages\")\n",
    "print(\"âœ“ Always have a catch-all except clause\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Handling Patterns\n",
    "\n",
    "**âœ… Good error handling:**\n",
    "\n",
    "```python\n",
    "@tool\n",
    "def my_tool(param: str) -> str:\n",
    "    \"\"\"Tool with good error handling.\"\"\"\n",
    "    try:\n",
    "        # Validate inputs\n",
    "        if not param:\n",
    "            return \"Error: param cannot be empty\"\n",
    "        \n",
    "        # Perform operation\n",
    "        result = do_something(param)\n",
    "        return f\"Success: {result}\"\n",
    "    \n",
    "    except SpecificError as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: Unexpected error: {str(e)}\"\n",
    "```\n",
    "\n",
    "**âŒ Bad error handling:**\n",
    "\n",
    "```python\n",
    "@tool\n",
    "def my_tool(param: str) -> str:\n",
    "    \"\"\"Tool with bad error handling.\"\"\"\n",
    "    result = do_something(param)  # Might crash!\n",
    "    return result\n",
    "```\n",
    "\n",
    "**Why return errors instead of raising?**\n",
    "\n",
    "- Tools run in the agent's execution loop\n",
    "- Raised exceptions break the agent flow\n",
    "- Returned error strings are sent back to the LLM\n",
    "- LLM can explain errors to users or retry with corrections\n",
    "- Enables graceful recovery and error correction\n",
    "\n",
    "**Error message format:**\n",
    "\n",
    "```python\n",
    "# âœ… Clear, actionable\n",
    "return \"Error: File 'data.txt' not found. Please check the filename and try again.\"\n",
    "\n",
    "# âŒ Vague, unhelpful\n",
    "return \"Error\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Multi-Step Tool Workflows\n",
    "\n",
    "Agents can chain multiple tool calls to accomplish complex tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Example 5: Multi-Step Workflows ===\")\n",
    "print()\n",
    "\n",
    "# Simulated database for demo\n",
    "fake_database = {\n",
    "    \"users\": [\n",
    "        {\"id\": 1, \"name\": \"Alice\", \"email\": \"alice@example.com\"},\n",
    "        {\"id\": 2, \"name\": \"Bob\", \"email\": \"bob@example.com\"},\n",
    "    ],\n",
    "    \"orders\": [\n",
    "        {\"order_id\": 101, \"user_id\": 1, \"product\": \"Laptop\", \"status\": \"shipped\"},\n",
    "        {\"order_id\": 102, \"user_id\": 2, \"product\": \"Mouse\", \"status\": \"pending\"},\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Tool 1: Search user\n",
    "@tool\n",
    "def find_user(email: str) -> str:\n",
    "    \"\"\"Find a user by their email address.\n",
    "    \n",
    "    Args:\n",
    "        email: User's email address\n",
    "        \n",
    "    Returns:\n",
    "        User information or error message\n",
    "    \"\"\"\n",
    "    print(f\"  ðŸ” Looking up user: {email}\")\n",
    "    \n",
    "    for user in fake_database[\"users\"]:\n",
    "        if user[\"email\"] == email:\n",
    "            return json.dumps(user)\n",
    "    \n",
    "    return f\"Error: User with email {email} not found\"\n",
    "\n",
    "# Tool 2: Get user's orders\n",
    "@tool\n",
    "def get_user_orders(user_id: int) -> str:\n",
    "    \"\"\"Get all orders for a specific user.\n",
    "    \n",
    "    Args:\n",
    "        user_id: The user's ID number\n",
    "        \n",
    "    Returns:\n",
    "        List of orders or error message\n",
    "    \"\"\"\n",
    "    print(f\"  ðŸ“¦ Fetching orders for user {user_id}\")\n",
    "    \n",
    "    orders = [o for o in fake_database[\"orders\"] if o[\"user_id\"] == user_id]\n",
    "    \n",
    "    if not orders:\n",
    "        return f\"No orders found for user {user_id}\"\n",
    "    \n",
    "    return json.dumps(orders)\n",
    "\n",
    "# Tool 3: Update order status\n",
    "@tool\n",
    "def update_order_status(\n",
    "    order_id: int,\n",
    "    new_status: Literal[\"pending\", \"processing\", \"shipped\", \"delivered\", \"cancelled\"]\n",
    ") -> str:\n",
    "    \"\"\"Update the status of an order.\n",
    "    \n",
    "    Args:\n",
    "        order_id: The order ID to update\n",
    "        new_status: New status for the order\n",
    "        \n",
    "    Returns:\n",
    "        Confirmation message or error\n",
    "    \"\"\"\n",
    "    print(f\"  âœï¸  Updating order {order_id} to status: {new_status}\")\n",
    "    \n",
    "    for order in fake_database[\"orders\"]:\n",
    "        if order[\"order_id\"] == order_id:\n",
    "            old_status = order[\"status\"]\n",
    "            order[\"status\"] = new_status\n",
    "            return f\"Order {order_id} status updated from '{old_status}' to '{new_status}'\"\n",
    "    \n",
    "    return f\"Error: Order {order_id} not found\"\n",
    "\n",
    "# Create agent with workflow tools and max_steps\n",
    "workflow_config = AgentConfig(\n",
    "    model=OpenAIModel(model_id='gpt-5-nano'),\n",
    "    name='workflow_agent',\n",
    "    system_prompt=\"\"\"You are a customer service agent with database access.\n",
    "    \n",
    "To help customers, you may need to:\n",
    "1. First find the user by email using find_user\n",
    "2. Then get their orders using get_user_orders with the user_id\n",
    "3. Finally update order status if needed using update_order_status\n",
    "\n",
    "Always chain tools in the correct order to complete the task.\"\"\",\n",
    "    tools=[find_user, get_user_orders, update_order_status],\n",
    "    max_steps=6,  # Limit to 6 reasoning iterations\n",
    ")\n",
    "\n",
    "workflow_agent = Agent(workflow_config)\n",
    "\n",
    "print(\"ðŸ¤– Workflow Agent (Multi-Step)\")\n",
    "print(f\"Max steps configured: {workflow_config.max_steps}\")\n",
    "print()\n",
    "\n",
    "print(\"ðŸ’¬ Complex Query Test:\")\n",
    "query = \"Can you find alice@example.com's orders and mark order 101 as delivered?\"\n",
    "print(f\"User: {query}\")\n",
    "print()\n",
    "\n",
    "result = await workflow_agent.do({'messages': query})\n",
    "\n",
    "print(f\"\\nAssistant: {result.content}\")\n",
    "print()\n",
    "\n",
    "print(\"ðŸ“Š Multi-Step Workflow Patterns:\")\n",
    "print(\"âœ“ Tool calls can be chained sequentially\")\n",
    "print(\"âœ“ Output of one tool becomes input to the next\")\n",
    "print(\"âœ“ LLM orchestrates the sequence automatically\")\n",
    "print(\"âœ“ Complex tasks decompose into simple tool calls\")\n",
    "print(\"âœ“ Each tool remains focused and reusable\")\n",
    "print(\"âœ“ max_steps prevents infinite loops\")\n",
    "print()\n",
    "\n",
    "print(\"ðŸ” Tool Trace Analysis:\")\n",
    "print(f\"Total tool calls made: {len(workflow_agent.get_tool_traces())}\")\n",
    "print(\"Tool sequence:\")\n",
    "for i, trace in enumerate(workflow_agent.get_tool_traces()):\n",
    "    print(f\"  {i}. {trace.get('tool_name')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Step Tool Patterns\n",
    "\n",
    "**Common workflow patterns:**\n",
    "\n",
    "**1. Sequential Pipeline**\n",
    "```\n",
    "Tool A â†’ Tool B â†’ Tool C â†’ Final Answer\n",
    "```\n",
    "Example: `search_user â†’ get_orders â†’ format_response`\n",
    "\n",
    "**2. Conditional Branching**\n",
    "```\n",
    "Tool A â†’ If result X: Tool B\n",
    "       â†’ If result Y: Tool C\n",
    "```\n",
    "Example: `check_inventory â†’ If available: process_order, If not: notify_out_of_stock`\n",
    "\n",
    "**3. Iterative Refinement**\n",
    "```\n",
    "Tool A â†’ Analyze â†’ Tool A again with refinements â†’ Final Answer\n",
    "```\n",
    "Example: `search â†’ analyze_results â†’ search_with_refined_query`\n",
    "\n",
    "**4. Parallel + Aggregate**\n",
    "```\n",
    "Tool A â”\n",
    "Tool B â”œâ†’ Combine Results â†’ Final Answer\n",
    "Tool C â”˜\n",
    "```\n",
    "Example: `get_weather, get_traffic, get_events â†’ summarize_for_day`\n",
    "\n",
    "**Max Steps Configuration:**\n",
    "\n",
    "Control the number of tool calling iterations to prevent infinite loops and manage costs:\n",
    "\n",
    "```python\n",
    "config = AgentConfig(\n",
    "    model=model,\n",
    "    tools=[tool1, tool2, tool3],\n",
    "    max_steps=10,  # Limit to 10 reasoning iterations (default: 10)\n",
    ")\n",
    "\n",
    "# For simple workflows\n",
    "config = AgentConfig(\n",
    "    model=model,\n",
    "    tools=[single_tool],\n",
    "    max_steps=3,  # Only allow up to 3 iterations\n",
    ")\n",
    "\n",
    "# For complex multi-step workflows\n",
    "config = AgentConfig(\n",
    "    model=model,\n",
    "    tools=[search, analyze, summarize, validate],\n",
    "    max_steps=15,  # Allow more iterations for complex tasks\n",
    ")\n",
    "```\n",
    "\n",
    "**Why max_steps matters:**\n",
    "- **Prevents infinite loops**: Stops runaway tool calling\n",
    "- **Controls costs**: Limits the number of LLM calls\n",
    "- **Sets timeout expectations**: Predictable execution time\n",
    "- **Forces efficiency**: Encourages agents to complete tasks within limits\n",
    "\n",
    "**What happens when max_steps is reached:**\n",
    "- Agent stops tool calling and returns current state\n",
    "- Any partial results are returned\n",
    "- Tool trace shows all steps taken\n",
    "- Error/warning may be included indicating step limit reached"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6: Tool Context and Agent Access\n",
    "\n",
    "Advanced: Tools can access the agent context for sophisticated behaviors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Example 6: Tools with Context ===\")\n",
    "print()\n",
    "\n",
    "from spark.tools.decorator import ToolContext\n",
    "\n",
    "# Tool with context access\n",
    "@tool(context=True)\n",
    "def get_conversation_stats(tool_context: ToolContext) -> str:\n",
    "    \"\"\"Get statistics about the current conversation.\n",
    "    \n",
    "    Returns:\n",
    "        Statistics about message count and conversation\n",
    "    \"\"\"\n",
    "    print(\"  ðŸ“Š Analyzing conversation stats\")\n",
    "    \n",
    "    # Access agent from context\n",
    "    agent = tool_context.invocation_state['agent']\n",
    "    \n",
    "    # Get conversation history (if available)\n",
    "    # Note: This is a demonstration of the concept\n",
    "    stats = {\n",
    "        \"agent_name\": agent.config.name,\n",
    "        \"tools_available\": len(agent.tool_registry.registry),\n",
    "        \"tool_use_id\": tool_context.tool_use.get('toolUseId', 'unknown'),\n",
    "    }\n",
    "    \n",
    "    return json.dumps(stats, indent=2)\n",
    "\n",
    "@tool(context=True)\n",
    "def log_tool_usage(message: str, tool_context: ToolContext) -> str:\n",
    "    \"\"\"Log a message with tool execution context.\n",
    "    \n",
    "    Args:\n",
    "        message: The message to log\n",
    "        \n",
    "    Returns:\n",
    "        Confirmation of logged message\n",
    "    \"\"\"\n",
    "    print(f\"  ðŸ“ Logging: {message}\")\n",
    "    \n",
    "    # Access invocation state\n",
    "    invocation_state = tool_context.invocation_state\n",
    "    \n",
    "    log_entry = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"message\": message,\n",
    "        \"agent\": invocation_state['agent'].config.name,\n",
    "    }\n",
    "    \n",
    "    return f\"Logged: {json.dumps(log_entry)}\"\n",
    "\n",
    "def before_hook(msgs, context):\n",
    "    print('msgs', msgs)\n",
    "    \n",
    "# Create agent with context-aware tools\n",
    "context_config = AgentConfig(\n",
    "    model=OpenAIModel(model_id='gpt-5-nano'),\n",
    "    name='context_aware_agent',\n",
    "    system_prompt='You are an agent with self-aware tools.',\n",
    "    tools=[get_conversation_stats, log_tool_usage],\n",
    "    before_llm_hooks=[before_hook]\n",
    ")\n",
    "\n",
    "context_agent = Agent(context_config)\n",
    "\n",
    "await context_agent.do({'messages': ['Hello']})\n",
    "await context_agent.do({'messages': ['hello, what tools do you have?']})\n",
    "await context_agent.do({'messages': ['can you give a your statistics so far?']})\n",
    "\n",
    "print(\"ðŸ¤– Context-Aware Agent\")\n",
    "print()\n",
    "\n",
    "print(\"ðŸ“‹ Context-Aware Tool Benefits:\")\n",
    "print(\"âœ“ Access to agent configuration and state\")\n",
    "print(\"âœ“ Can inspect conversation history\")\n",
    "print(\"âœ“ Tool use metadata available (toolUseId, etc.)\")\n",
    "print(\"âœ“ Enables meta-operations (stats, logging, monitoring)\")\n",
    "print(\"âœ“ Advanced debugging and instrumentation\")\n",
    "print()\n",
    "\n",
    "print(\"âš™ï¸  Context parameter:\")\n",
    "print(\"  @tool(context=True)  # Injects ToolContext as 'tool_context'\")\n",
    "print(\"  @tool(context='ctx')  # Injects ToolContext as 'ctx'\")\n",
    "print()\n",
    "\n",
    "print(\"ðŸ“¦ ToolContext contents:\")\n",
    "print(\"  - tool_use: Complete ToolUse object\")\n",
    "print(\"  - agent: The Agent instance\")\n",
    "print(\"  - invocation_state: Caller-provided kwargs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to Use Tool Context\n",
    "\n",
    "**Use ToolContext for:**\n",
    "\n",
    "âœ… **Meta-operations**\n",
    "```python\n",
    "@tool(context=True)\n",
    "def get_tool_stats(tool_context: ToolContext) -> str:\n",
    "    \"\"\"Report on available tools and usage.\"\"\"\n",
    "    tools = tool_context.agent.tool_registry.registry\n",
    "    return f\"Available tools: {list(tools.keys())}\"\n",
    "```\n",
    "\n",
    "âœ… **Logging and monitoring**\n",
    "```python\n",
    "@tool(context=True)\n",
    "def audit_log(action: str, tool_context: ToolContext) -> str:\n",
    "    \"\"\"Log actions with agent context.\"\"\"\n",
    "    agent_name = tool_context.agent.config.name\n",
    "    return f\"[{agent_name}] Logged: {action}\"\n",
    "```\n",
    "\n",
    "âœ… **Conditional behavior based on agent state**\n",
    "```python\n",
    "@tool(context=True)\n",
    "def smart_search(query: str, tool_context: ToolContext) -> str:\n",
    "    \"\"\"Search with behavior based on agent configuration.\"\"\"\n",
    "    # Adapt search based on agent's system prompt or state\n",
    "    pass\n",
    "```\n",
    "\n",
    "**Don't use ToolContext for:**\n",
    "\n",
    "âŒ **Regular data processing** (use normal parameters)\n",
    "âŒ **Modifying agent state** (tools should be side-effect free when possible)\n",
    "âŒ **Simple calculations** (keep tools simple)\n",
    "\n",
    "**Best practices:**\n",
    "- Use context sparingly for advanced use cases\n",
    "- Document why context is needed in the docstring\n",
    "- Prefer simple parameter-based tools when possible\n",
    "- Use context for instrumentation and debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Example 6b: Tool Choice Strategies ===\")\n",
    "print()\n",
    "\n",
    "# Define simple tools for demonstration\n",
    "@tool\n",
    "def get_time() -> str:\n",
    "    \"\"\"Get the current time.\n",
    "    \n",
    "    Returns:\n",
    "        Current time as a string\n",
    "    \"\"\"\n",
    "    print(\"  ðŸ• Getting current time\")\n",
    "    return datetime.now().strftime(\"%H:%M:%S\")\n",
    "\n",
    "@tool\n",
    "def get_date() -> str:\n",
    "    \"\"\"Get the current date.\n",
    "    \n",
    "    Returns:\n",
    "        Current date as a string\n",
    "    \"\"\"\n",
    "    print(\"  ðŸ“… Getting current date\")\n",
    "    return datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Test 1: Auto mode (default) - LLM decides\n",
    "print(\"Test 1: tool_choice='auto' (LLM decides)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "auto_agent = Agent(\n",
    "    config=AgentConfig(\n",
    "        model=OpenAIModel(model_id='gpt-5-nano'),\n",
    "        name='auto_agent',\n",
    "        system_prompt='You are a helpful assistant.',\n",
    "        tools=[get_time, get_date],\n",
    "        tool_choice='auto',  # Default - LLM decides\n",
    "    )\n",
    ")\n",
    "\n",
    "# Query that may or may not need tools\n",
    "result = await auto_agent.do({'messages': 'Hello! How are you?'})\n",
    "print(f\"Query: 'Hello! How are you?'\")\n",
    "print(f\"Response: {result.content[:100]}...\")\n",
    "print(f\"Tools used: {len(auto_agent.get_tool_traces())}\")\n",
    "print()\n",
    "\n",
    "# Query that likely needs tools\n",
    "result = await auto_agent.do({'messages': 'What time is it?'})\n",
    "print(f\"Query: 'What time is it?'\")\n",
    "print(f\"Response: {result.content[:100]}...\")\n",
    "print(f\"Tools used: {len(auto_agent.get_tool_traces())}\")\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Test 2: Any mode - Force tool usage\n",
    "print(\"Test 2: tool_choice='any' (Force tool usage)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "any_agent = Agent(\n",
    "    config=AgentConfig(\n",
    "        model=OpenAIModel(model_id='gpt-5-nano'),\n",
    "        name='any_agent',\n",
    "        system_prompt='You are a helpful assistant. Always use a tool to answer.',\n",
    "        tools=[get_time, get_date],\n",
    "        tool_choice='any',  # Must use at least one tool\n",
    "    )\n",
    ")\n",
    "\n",
    "result = await any_agent.do({'messages': 'Give me some information'})\n",
    "print(f\"Query: 'Give me some information'\")\n",
    "print(f\"Response: {result.content[:100]}...\")\n",
    "print(f\"Tools used: {len(any_agent.get_tool_traces())}\")\n",
    "print(\"âœ“ Agent was forced to use a tool even for a vague query\")\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Test 3: Specific tool - Force specific tool\n",
    "print(\"Test 3: tool_choice with specific tool\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "specific_agent = Agent(\n",
    "    config=AgentConfig(\n",
    "        model=OpenAIModel(model_id='gpt-5-nano'),\n",
    "        name='specific_agent',\n",
    "        system_prompt='You are a helpful assistant.',\n",
    "        tools=[get_time, get_date],\n",
    "        tool_choice='get_date',  # Force get_date\n",
    "    )\n",
    ")\n",
    "\n",
    "result = await specific_agent.do({'messages': 'What is the current information?'})\n",
    "print(f\"Query: 'What is the current information?'\")\n",
    "print(f\"Response: {result.content[:100]}...\")\n",
    "if hasattr(result.state, 'tool_trace') and result.state.tool_trace:\n",
    "    print(f\"Tool used: {specific_agent.get_tool_traces()[0].get('name', 'unknown')}\")\n",
    "    print(\"âœ“ Agent was forced to use get_date specifically\")\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Test 4: None mode - Disable tools\n",
    "print(\"Test 4: tool_choice='none' (No tools)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "none_agent = Agent(\n",
    "    config=AgentConfig(\n",
    "        model=OpenAIModel(model_id='gpt-5-nano'),\n",
    "        name='none_agent',\n",
    "        system_prompt='You are a helpful assistant.',\n",
    "        tools=[get_time, get_date],\n",
    "        tool_choice='none',  # Cannot use tools\n",
    "    )\n",
    ")\n",
    "\n",
    "result = await none_agent.do({'messages': 'What time is it?'})\n",
    "print(f\"Query: 'What time is it?'\")\n",
    "print(f\"Response: {result.content[:150]}...\")\n",
    "print(f\"Tools used: {len(none_agent.get_tool_traces())}\")\n",
    "print(\"âœ“ Agent cannot use tools even when they would be helpful\")\n",
    "print()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ðŸ“Š Tool Choice Strategy Summary:\")\n",
    "print()\n",
    "print(\"'auto':  Most flexible - LLM decides when to use tools\")\n",
    "print(\"'any':   Always forces tool usage - good for action-oriented tasks\")\n",
    "print(\"specific: Forces a particular tool - deterministic workflows\")\n",
    "print(\"'none':  Disables tools - pure text generation\")\n",
    "print()\n",
    "print(\"ðŸ’¡ Use Cases:\")\n",
    "print(\"  â€¢ 'auto' â†’ General purpose agents (default)\")\n",
    "print(\"  â€¢ 'any' â†’ Ensure action is taken (e.g., logging, data collection)\")\n",
    "print(\"  â€¢ specific â†’ Deterministic pipelines (e.g., always check inventory first)\")\n",
    "print(\"  â€¢ 'none' â†’ Final answer generation, no external calls needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6b: Tool Choice Strategies\n",
    "\n",
    "Learn how to control tool usage with different tool_choice settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging Checklist\n",
    "\n",
    "**When a tool isn't working:**\n",
    "\n",
    "**1. Check Tool Registration**\n",
    "```python\n",
    "# List all registered tools\n",
    "print(list(agent.tool_registry.registry.keys()))\n",
    "\n",
    "# Verify your tool is in the list\n",
    "assert 'my_tool' in agent.tool_registry.registry\n",
    "```\n",
    "\n",
    "**2. Inspect Tool Specification**\n",
    "```python\n",
    "# Check what the LLM sees\n",
    "tool_spec = agent.tool_specs[0]\n",
    "print(json.dumps(tool_spec, indent=2))\n",
    "\n",
    "# Verify description is clear and accurate\n",
    "assert 'description' in tool_spec\n",
    "```\n",
    "\n",
    "**3. Test Tool Directly**\n",
    "```python\n",
    "# Call tool without agent\n",
    "from my_tools import my_tool\n",
    "result = my_tool(param=\"test\")\n",
    "print(f\"Direct test: {result}\")\n",
    "```\n",
    "\n",
    "**4. Check Type Hints**\n",
    "```python\n",
    "# Verify parameter types match your docstring\n",
    "import inspect\n",
    "sig = inspect.signature(my_tool)\n",
    "print(sig.parameters)\n",
    "```\n",
    "\n",
    "**5. Add Debug Logging**\n",
    "```python\n",
    "@tool\n",
    "def my_tool(param: str) -> str:\n",
    "    print(f\"DEBUG: my_tool called with param={param}\")\n",
    "    result = process(param)\n",
    "    print(f\"DEBUG: my_tool returning {result}\")\n",
    "    return result\n",
    "```\n",
    "\n",
    "**6. Inspect Tool Traces**\n",
    "```python\n",
    "# After execution, check what actually happened\n",
    "result = await agent.do({'messages': query})\n",
    "if hasattr(result.state, 'tool_trace'):\n",
    "    for trace in result.state.tool_trace:\n",
    "        print(f\"Called: {trace['name']}\")\n",
    "        print(f\"Input: {trace['input']}\")\n",
    "        print(f\"Output: {trace['content']}\")\n",
    "```\n",
    "\n",
    "**7. Verify Model Compatibility**\n",
    "- Not all models support tool calling\n",
    "- Check your model's documentation\n",
    "- Test with a known working model (e.g., GPT-4)\n",
    "\n",
    "**8. Check max_steps Configuration**\n",
    "```python\n",
    "# Verify you haven't hit the iteration limit\n",
    "print(f\"Max steps: {agent.config.max_steps}\")\n",
    "print(f\"Actual steps taken: {len(result.state.tool_trace)}\")\n",
    "```\n",
    "\n",
    "**Common Solutions:**\n",
    "\n",
    "| Problem | Solution |\n",
    "|---------|----------|\n",
    "| Tool never called | Improve docstring clarity |\n",
    "| Wrong parameters | Fix type hints |\n",
    "| Tool errors | Add error handling |\n",
    "| Unexpected behavior | Test tool directly first |\n",
    "| Hit iteration limit | Increase max_steps or optimize tool chain |\n",
    "| Tool not selected | Check tool_choice setting |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Example 7: Tool Debugging and Traces ===\" )\n",
    "print()\n",
    "\n",
    "# Create tools for debugging demonstration\n",
    "@tool\n",
    "def fetch_data(source: str) -> str:\n",
    "    \"\"\"Fetch data from a source.\n",
    "    \n",
    "    Args:\n",
    "        source: Data source name\n",
    "    \"\"\"\n",
    "    print(f\"  ðŸ“¥ Fetching from: {source}\")\n",
    "    time.sleep(0.1)  # Simulate work\n",
    "    return f\"Data from {source}: [sample data]\"\n",
    "\n",
    "@tool\n",
    "def process_data(data: str) -> str:\n",
    "    \"\"\"Process the fetched data.\n",
    "    \n",
    "    Args:\n",
    "        data: Data to process\n",
    "    \"\"\"\n",
    "    print(f\"  âš™ï¸  Processing data\")\n",
    "    time.sleep(0.1)  # Simulate work\n",
    "    return f\"Processed: {data[:50]}...\"\n",
    "\n",
    "@tool\n",
    "def validate_result(result: str) -> str:\n",
    "    \"\"\"Validate the processed result.\n",
    "    \n",
    "    Args:\n",
    "        result: Result to validate\n",
    "    \"\"\"\n",
    "    print(f\"  âœ… Validating result\")\n",
    "    return \"Validation passed\"\n",
    "\n",
    "# Create agent with trace-enabled tools\n",
    "trace_config = AgentConfig(\n",
    "    model=OpenAIModel(model_id='gpt-5-nano'),\n",
    "    name='trace_agent',\n",
    "    system_prompt='You are a data processing agent. Use tools to fetch, process, and validate data.  The data is already in the database, there is no need for clarification.',\n",
    "    tools=[fetch_data, process_data, validate_result],\n",
    "    max_steps=8,\n",
    ")\n",
    "\n",
    "trace_agent = Agent(trace_config)\n",
    "\n",
    "print(\"ðŸ” Tool Debugging and Trace Analysis\")\n",
    "print()\n",
    "\n",
    "# Execute a multi-step workflow\n",
    "query = \"Fetch data from 'database', process it, and validate the result\"\n",
    "print(f\"User: {query}\")\n",
    "print()\n",
    "\n",
    "result = await trace_agent.do({'messages': query})\n",
    "\n",
    "print(f\"\\nAssistant: {result.content}\")\n",
    "print()\n",
    "\n",
    "# Analyze tool trace\n",
    "print(\"=\" * 60)\n",
    "print(\"ðŸ”§ Tool Trace Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "traces = trace_agent.get_tool_traces()\n",
    "print(f\"\\nTotal tool calls: {len(traces)}\")\n",
    "print()\n",
    "    \n",
    "for i, trace in enumerate(traces, 1):\n",
    "    print(f\"Tool Call #{i}:\")\n",
    "    print(f\"  Name: {trace.get('tool_name', 'unknown')}\")\n",
    "    print(f\"  Tool Use ID: {trace.get('toolUseId', 'N/A')[:20]}...\")\n",
    "        \n",
    "    # Show parameters\n",
    "    params = trace.get('input', {})\n",
    "    if params:\n",
    "        print(f\"  Parameters:\")\n",
    "        for key, value in params.items():\n",
    "            value_str = str(value)[:50]\n",
    "            print(f\"    {key}: {value_str}\")\n",
    "        \n",
    "    # Show result preview\n",
    "    result_content = trace.get('content', [])\n",
    "    if result_content:\n",
    "        for content in result_content:\n",
    "            if isinstance(content, dict) and 'text' in content:\n",
    "                result_text = content['text'][:60]\n",
    "                print(f\"  Result: {result_text}...\")\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "print(\"ðŸ“Š Debugging Best Practices:\")\n",
    "print()\n",
    "print(\"âœ… During Development:\")\n",
    "print(\"  â€¢ Add print statements in tools to track execution\")\n",
    "print(\"  â€¢ Test tools directly before giving them to agents\")\n",
    "print(\"  â€¢ Verify tool specs match your expectations\")\n",
    "print(\"  â€¢ Use descriptive tool names and docstrings\")\n",
    "print()\n",
    "print(\"âœ… Using Tool Traces:\")\n",
    "print(\"  â€¢ Access via result.state.tool_trace after execution\")\n",
    "print(\"  â€¢ Each trace entry contains: name, toolUseId, input, content\")\n",
    "print(\"  â€¢ Analyze call sequence to understand agent reasoning\")\n",
    "print(\"  â€¢ Debug parameter passing and result handling\")\n",
    "print(\"  â€¢ Track execution order for multi-tool workflows\")\n",
    "print()\n",
    "print(\"âœ… In Production:\")\n",
    "print(\"  â€¢ Log tool traces for debugging failed executions\")\n",
    "print(\"  â€¢ Monitor tool usage patterns and frequencies\")\n",
    "print(\"  â€¢ Track tool execution for audit trails\")\n",
    "print(\"  â€¢ Identify bottlenecks in multi-step workflows\")\n",
    "print()\n",
    "print(\"âœ… Common Issues:\")\n",
    "print(\"  â€¢ Tool not being called: Check description clarity\")\n",
    "print(\"  â€¢ Wrong parameters: Verify type hints and docstring\")\n",
    "print(\"  â€¢ Tool errors: Add better error handling\")\n",
    "print(\"  â€¢ Too many iterations: Adjust max_steps limit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging Checklist\n",
    "\n",
    "**When a tool isn't working:**\n",
    "\n",
    "**1. Check Tool Registration**\n",
    "```python\n",
    "# List all registered tools\n",
    "print(list(agent.tool_registry.registry.keys()))\n",
    "\n",
    "# Verify your tool is in the list\n",
    "assert 'my_tool' in agent.tool_registry.registry\n",
    "```\n",
    "\n",
    "**2. Inspect Tool Specification**\n",
    "```python\n",
    "# Check what the LLM sees\n",
    "tool_spec = agent.tool_specs[0]\n",
    "print(json.dumps(tool_spec, indent=2))\n",
    "\n",
    "# Verify description is clear and accurate\n",
    "assert 'description' in tool_spec\n",
    "```\n",
    "\n",
    "**3. Test Tool Directly**\n",
    "```python\n",
    "# Call tool without agent\n",
    "from my_tools import my_tool\n",
    "result = my_tool(param=\"test\")\n",
    "print(f\"Direct test: {result}\")\n",
    "```\n",
    "\n",
    "**4. Check Type Hints**\n",
    "```python\n",
    "# Verify parameter types match your docstring\n",
    "import inspect\n",
    "sig = inspect.signature(my_tool)\n",
    "print(sig.parameters)\n",
    "```\n",
    "\n",
    "**5. Add Debug Logging**\n",
    "```python\n",
    "@tool\n",
    "def my_tool(param: str) -> str:\n",
    "    print(f\"DEBUG: my_tool called with param={param}\")\n",
    "    result = process(param)\n",
    "    print(f\"DEBUG: my_tool returning {result}\")\n",
    "    return result\n",
    "```\n",
    "\n",
    "**6. Verify Model Compatibility**\n",
    "- Not all models support tool calling\n",
    "- Check your model's documentation\n",
    "- Test with a known working model (e.g., GPT-4)\n",
    "\n",
    "**Common Solutions:**\n",
    "\n",
    "| Problem | Solution |\n",
    "|---------|----------|\n",
    "| Tool never called | Improve docstring clarity |\n",
    "| Wrong parameters | Fix type hints |\n",
    "| Tool errors | Add error handling |\n",
    "| Unexpected behavior | Test tool directly first |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Concepts Recap\n",
    "\n",
    "### Tool Creation Checklist\n",
    "\n",
    "```python\n",
    "@tool\n",
    "def my_tool(\n",
    "    param1: str,                              # âœ“ Type hints\n",
    "    param2: int = 0,                          # âœ“ Default values\n",
    "    option: Literal[\"a\", \"b\"] = \"a\"          # âœ“ Constrained values\n",
    ") -> str:                                     # âœ“ Return type\n",
    "    \"\"\"Clear description of what the tool does.  # âœ“ Description\n",
    "    \n",
    "    Args:\n",
    "        param1: Description of param1         # âœ“ Parameter docs\n",
    "        param2: Description of param2\n",
    "        option: Which option to use\n",
    "        \n",
    "    Returns:\n",
    "        Description of return value           # âœ“ Return docs\n",
    "    \"\"\"\n",
    "    try:                                       # âœ“ Error handling\n",
    "        result = do_work(param1, param2)\n",
    "        return f\"Success: {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"            # âœ“ Error as string\n",
    "```\n",
    "\n",
    "### Tool Patterns Summary\n",
    "\n",
    "| Pattern | Use Case | Example |\n",
    "|---------|----------|------------|\n",
    "| **Single Tool** | Simple tasks | Calculator, date/time |\n",
    "| **Multiple Tools** | Varied capabilities | Research assistant |\n",
    "| **Tool Chains** | Complex workflows | User lookup â†’ Orders â†’ Update |\n",
    "| **Context-Aware** | Meta-operations | Statistics, logging |\n",
    "| **Error-Resistant** | Production reliability | All tools |\n",
    "\n",
    "### AgentConfig with Tools\n",
    "\n",
    "```python\n",
    "config = AgentConfig(\n",
    "    model=model,\n",
    "    name='my_agent',\n",
    "    system_prompt='...',\n",
    "    tools=[tool1, tool2, tool3],        # List of @tool decorated functions\n",
    "    tool_choice='auto',                 # 'auto', 'any', 'none', or {'type': 'tool', 'name': '...'}\n",
    "    max_steps=10,                       # Limit tool calling iterations (default: 10)\n",
    ")\n",
    "```\n",
    "\n",
    "### Tool Choice Strategies\n",
    "\n",
    "| Strategy | Behavior | Use Case |\n",
    "|----------|----------|----------|\n",
    "| **'auto'** | LLM decides | Most flexible, default |\n",
    "| **'any'** | Must use a tool | Force action |\n",
    "| **{'type': 'tool', 'name': 'X'}** | Must use specific tool | Deterministic workflows |\n",
    "| **'none'** | No tools allowed | Final answer only |\n",
    "\n",
    "### Tool Trace Access\n",
    "\n",
    "After agent execution, access tool traces for debugging:\n",
    "\n",
    "```python\n",
    "result = await agent.do({'messages': query})\n",
    "\n",
    "# Access tool trace\n",
    "if hasattr(result.state, 'tool_trace'):\n",
    "    for trace in result.state.tool_trace:\n",
    "        print(f\"Tool: {trace['name']}\")\n",
    "        print(f\"Input: {trace['input']}\")\n",
    "        print(f\"Result: {trace['content']}\")\n",
    "```\n",
    "\n",
    "### When to Create Tools\n",
    "\n",
    "**âœ… Create a tool when you need to:**\n",
    "- Access external systems (APIs, databases)\n",
    "- Execute code or commands\n",
    "- Perform calculations\n",
    "- Retrieve real-time data\n",
    "- Modify system state\n",
    "- Access private information\n",
    "\n",
    "**âŒ Don't create a tool for:**\n",
    "- Things the LLM can do with knowledge\n",
    "- Simple text transformations\n",
    "- Information in the system prompt\n",
    "- Tasks requiring human judgment\n",
    "\n",
    "### Tool Design Principles\n",
    "\n",
    "**1. Single Responsibility**: Each tool does one thing well\n",
    "**2. Clear Names**: `search_web` not `do_something`\n",
    "**3. Good Docs**: Docstrings guide the LLM\n",
    "**4. Type Safety**: Type hints prevent errors\n",
    "**5. Error Handling**: Return errors, don't raise\n",
    "**6. Focused Scope**: Keep tools small and composable\n",
    "**7. Idempotency**: Same input â†’ same output (when possible)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’ª Hands-On Exercises\n",
    "\n",
    "Test your understanding with these practical exercises!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Create a File System Tool\n",
    "\n",
    "Build a simple file system tool that can:\n",
    "- List files in a directory\n",
    "- Create a new file\n",
    "- Read file contents\n",
    "\n",
    "Requirements:\n",
    "- Use proper type hints\n",
    "- Include error handling\n",
    "- Write clear docstrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Your code here\n",
    "\n",
    "# TODO: Create list_directory tool\n",
    "# TODO: Create create_file tool\n",
    "# TODO: Create read_file tool\n",
    "# TODO: Create agent with these tools\n",
    "# TODO: Test with queries like \"List files\" and \"Create a file named test.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Build a Data Analysis Agent\n",
    "\n",
    "Create an agent with tools for data analysis:\n",
    "- Calculate mean/median/mode\n",
    "- Find min/max values\n",
    "- Generate summary statistics\n",
    "\n",
    "Requirements:\n",
    "- Accept list of numbers as input\n",
    "- Handle edge cases (empty list, etc.)\n",
    "- Return formatted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Your code here\n",
    "\n",
    "# TODO: Create statistics tools\n",
    "# TODO: Handle edge cases\n",
    "# TODO: Create agent with tools\n",
    "# TODO: Test with \"Calculate the mean of [1, 2, 3, 4, 5]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Multi-Step Workflow Agent\n",
    "\n",
    "Build an agent that chains tools to:\n",
    "1. Search for a topic\n",
    "2. Extract key information\n",
    "3. Summarize findings\n",
    "\n",
    "Create 3 tools that work together and test the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Your code here\n",
    "\n",
    "# TODO: Create search_topic tool\n",
    "# TODO: Create extract_info tool\n",
    "# TODO: Create summarize tool\n",
    "# TODO: Create agent that chains these tools\n",
    "# TODO: Test with \"Research and summarize quantum computing\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Context-Aware Logging Tool\n",
    "\n",
    "Create a tool that uses ToolContext to:\n",
    "- Log tool invocations with metadata\n",
    "- Track which agent called the tool\n",
    "- Include timestamps and tool use IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4: Your code here\n",
    "\n",
    "# TODO: Create context-aware logging tool\n",
    "# TODO: Extract agent name and tool_use_id from context\n",
    "# TODO: Format log entries nicely\n",
    "# TODO: Test the tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Solutions\n",
    "\n",
    "Try the exercises yourself first! Solutions are provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1: File System Tools\n",
    "\n",
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "@tool\n",
    "def list_directory(path: str = \".\") -> str:\n",
    "    \"\"\"List all files and directories in the given path.\n",
    "    \n",
    "    Args:\n",
    "        path: Directory path to list (default: current directory)\n",
    "        \n",
    "    Returns:\n",
    "        List of files and directories\n",
    "    \"\"\"\n",
    "    try:\n",
    "        items = os.listdir(path)\n",
    "        return f\"Files in {path}:\\n\" + \"\\n\".join(f\"  - {item}\" for item in items)\n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: Directory not found: {path}\"\n",
    "    except PermissionError:\n",
    "        return f\"Error: Permission denied: {path}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def create_file(filename: str, content: str = \"\") -> str:\n",
    "    \"\"\"Create a new file with optional content.\n",
    "    \n",
    "    Args:\n",
    "        filename: Name of the file to create\n",
    "        content: Optional content to write to the file\n",
    "        \n",
    "    Returns:\n",
    "        Confirmation message\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not filename:\n",
    "            return \"Error: Filename cannot be empty\"\n",
    "        \n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(content)\n",
    "        \n",
    "        return f\"File '{filename}' created successfully\"\n",
    "    except Exception as e:\n",
    "        return f\"Error creating file: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def read_file(filename: str) -> str:\n",
    "    \"\"\"Read and return the contents of a file.\n",
    "    \n",
    "    Args:\n",
    "        filename: Name of the file to read\n",
    "        \n",
    "    Returns:\n",
    "        File contents or error message\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        return f\"Contents of '{filename}':\\n{content}\"\n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: File not found: {filename}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error reading file: {str(e)}\"\n",
    "\n",
    "# Create file system agent\n",
    "fs_agent = Agent(AgentConfig(\n",
    "    model=OpenAIModel(model_id='gpt-5-nano'),\n",
    "    name='file_system_agent',\n",
    "    system_prompt='You are a file system assistant. Help users manage files.',\n",
    "    tools=[list_directory, create_file, read_file],\n",
    "))\n",
    "\n",
    "result = await fs_agent.do({'messages': ['what files are in the current working directory?']})\n",
    "\n",
    "print(\"=== Solution 1: File System Agent ===\")\n",
    "print(\"âœ… Created tools: list_directory, create_file, read_file\")\n",
    "print(\"âœ… All tools have error handling\")\n",
    "print(\"âœ… Clear docstrings and type hints\")\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 2: Data Analysis Agent\n",
    "\n",
    "from typing import List\n",
    "import statistics\n",
    "\n",
    "@tool\n",
    "def calculate_mean(numbers: List[float]) -> str:\n",
    "    \"\"\"Calculate the arithmetic mean (average) of a list of numbers.\n",
    "    \n",
    "    Args:\n",
    "        numbers: List of numbers\n",
    "        \n",
    "    Returns:\n",
    "        Mean value or error message\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not numbers:\n",
    "            return \"Error: Cannot calculate mean of empty list\"\n",
    "        \n",
    "        mean = statistics.mean(numbers)\n",
    "        return f\"Mean: {mean:.2f}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def calculate_median(numbers: List[float]) -> str:\n",
    "    \"\"\"Calculate the median (middle value) of a list of numbers.\n",
    "    \n",
    "    Args:\n",
    "        numbers: List of numbers\n",
    "        \n",
    "    Returns:\n",
    "        Median value or error message\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not numbers:\n",
    "            return \"Error: Cannot calculate median of empty list\"\n",
    "        \n",
    "        median = statistics.median(numbers)\n",
    "        return f\"Median: {median:.2f}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def find_min_max(numbers: List[float]) -> str:\n",
    "    \"\"\"Find the minimum and maximum values in a list of numbers.\n",
    "    \n",
    "    Args:\n",
    "        numbers: List of numbers\n",
    "        \n",
    "    Returns:\n",
    "        Min and max values or error message\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not numbers:\n",
    "            return \"Error: Cannot find min/max of empty list\"\n",
    "        \n",
    "        return f\"Min: {min(numbers)}, Max: {max(numbers)}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def summary_statistics(numbers: List[float]) -> str:\n",
    "    \"\"\"Generate comprehensive summary statistics for a list of numbers.\n",
    "    \n",
    "    Args:\n",
    "        numbers: List of numbers\n",
    "        \n",
    "    Returns:\n",
    "        Summary statistics or error message\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not numbers:\n",
    "            return \"Error: Cannot generate statistics for empty list\"\n",
    "        \n",
    "        stats = f\"\"\"Summary Statistics:\n",
    "  Count: {len(numbers)}\n",
    "  Mean: {statistics.mean(numbers):.2f}\n",
    "  Median: {statistics.median(numbers):.2f}\n",
    "  Std Dev: {statistics.stdev(numbers) if len(numbers) > 1 else 'N/A'}\n",
    "  Min: {min(numbers)}\n",
    "  Max: {max(numbers)}\"\"\"\n",
    "        return stats\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Create data analysis agent\n",
    "stats_agent = Agent(AgentConfig(\n",
    "    model=OpenAIModel(model_id='gpt-5-nano'),\n",
    "    name='statistics_agent',\n",
    "    system_prompt='You are a data analysis assistant. Help users analyze numerical data.',\n",
    "    tools=[calculate_mean, calculate_median, find_min_max, summary_statistics],\n",
    "))\n",
    "\n",
    "print(\"=== Solution 2: Data Analysis Agent ===\")\n",
    "print(\"âœ… Created statistical analysis tools\")\n",
    "print(\"âœ… Handles empty lists and edge cases\")\n",
    "print(\"âœ… Uses Python's statistics module\")\n",
    "\n",
    "result = await stats_agent.do({'messages':['1 2 3 4 5 6 7 8 9 20 30 40 50 60 70']})\n",
    "print(result.content)\n",
    "print('# of tool calls', len(stats_agent.get_tool_traces()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 3: Multi-Step Workflow Agent\n",
    "\n",
    "@tool\n",
    "def search_topic(topic: str) -> str:\n",
    "    \"\"\"Search for information about a topic.\n",
    "    \n",
    "    Args:\n",
    "        topic: The topic to search for\n",
    "        \n",
    "    Returns:\n",
    "        Search results with relevant information\n",
    "    \"\"\"\n",
    "    print(f\"  ðŸ” Searching for: {topic}\")\n",
    "    \n",
    "    # Simulated search results\n",
    "    results = f\"\"\"Search Results for '{topic}':\n",
    "    \n",
    "1. Overview: {topic} is an important field of study...\n",
    "2. Recent Developments: Latest advances in {topic} include...\n",
    "3. Applications: {topic} is used in various industries...\n",
    "4. Challenges: Current challenges in {topic} research...\n",
    "5. Future Directions: Expected developments in {topic}...\"\"\"\n",
    "    \n",
    "    return results\n",
    "\n",
    "@tool\n",
    "def extract_key_points(text: str) -> str:\n",
    "    \"\"\"Extract key points from text.\n",
    "    \n",
    "    Args:\n",
    "        text: Text to analyze\n",
    "        \n",
    "    Returns:\n",
    "        Extracted key points\n",
    "    \"\"\"\n",
    "    print(\"  ðŸ“Œ Extracting key points\")\n",
    "    \n",
    "    # Simulated extraction\n",
    "    lines = text.split('\\n')\n",
    "    key_lines = [line for line in lines if line.strip() and any(char.isdigit() for char in line[:3])]\n",
    "    \n",
    "    return \"Key Points:\\n\" + \"\\n\".join(f\"  â€¢ {line.strip()}\" for line in key_lines)\n",
    "\n",
    "@tool\n",
    "def create_summary(key_points: str) -> str:\n",
    "    \"\"\"Create a concise summary from key points.\n",
    "    \n",
    "    Args:\n",
    "        key_points: Key points to summarize\n",
    "        \n",
    "    Returns:\n",
    "        Concise summary\n",
    "    \"\"\"\n",
    "    print(\"  ðŸ“ Creating summary\")\n",
    "    \n",
    "    # Simulated summarization\n",
    "    summary = f\"\"\"Summary:\n",
    "    \n",
    "Based on the analysis, the topic encompasses several important aspects:\n",
    "{key_points}\n",
    "\n",
    "This represents a comprehensive overview of the subject matter.\"\"\"\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Create workflow agent\n",
    "workflow_agent = Agent(AgentConfig(\n",
    "    model=OpenAIModel(model_id='gpt-5-nano'),\n",
    "    name='research_workflow_agent',\n",
    "    system_prompt=\"\"\"You are a research assistant that follows a structured workflow:\n",
    "1. First, search for the topic using search_topic\n",
    "2. Then, extract key points using extract_key_points\n",
    "3. Finally, create a summary using create_summary\n",
    "Always follow this sequence for comprehensive research.\"\"\",\n",
    "    tools=[search_topic, extract_key_points, create_summary],\n",
    "))\n",
    "\n",
    "print(\"=== Solution 3: Multi-Step Workflow Agent ===\")\n",
    "print(\"âœ… Created 3 chained tools\")\n",
    "print(\"âœ… Each tool builds on the previous one\")\n",
    "print(\"âœ… System prompt guides the workflow\")\n",
    "print()\n",
    "print(\"Expected workflow:\")\n",
    "print(\"  1. search_topic â†’ Get raw information\")\n",
    "print(\"  2. extract_key_points â†’ Identify important parts\")\n",
    "print(\"  3. create_summary â†’ Generate final output\")\n",
    "\n",
    "result = await workflow_agent.do({'messages':['research app store optimization']})\n",
    "print(result.content)\n",
    "print('# of tool calls', len(workflow_agent.get_tool_traces()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 4: Context-Aware Logging Tool\n",
    "\n",
    "@tool(context=True)\n",
    "def log_invocation(message: str, tool_context: ToolContext) -> str:\n",
    "    \"\"\"Log a tool invocation with full context metadata.\n",
    "    \n",
    "    Args:\n",
    "        message: Message to log\n",
    "        \n",
    "    Returns:\n",
    "        Formatted log entry\n",
    "    \"\"\"\n",
    "    # Extract metadata from context\n",
    "    agent_name = tool_context.invocation_state['agent'].config.name\n",
    "    tool_use_id = tool_context.tool_use.get('toolUseId', 'unknown')\n",
    "    timestamp = datetime.now().isoformat()\n",
    "    \n",
    "    # Create structured log entry\n",
    "    log_entry = {\n",
    "        'timestamp': timestamp,\n",
    "        'agent': agent_name,\n",
    "        'tool_use_id': tool_use_id,\n",
    "        'message': message,\n",
    "    }\n",
    "    \n",
    "    # Format for display\n",
    "    formatted = f\"\"\"[LOG ENTRY]\n",
    "Timestamp: {timestamp}\n",
    "Agent: {agent_name}\n",
    "Tool Use ID: {tool_use_id}\n",
    "Message: {message}\"\"\"\n",
    "    \n",
    "    print(f\"  ðŸ“‹ {formatted}\")\n",
    "    return f\"Logged: {json.dumps(log_entry)}\"\n",
    "\n",
    "@tool(context=True)\n",
    "def get_agent_info(tool_context: ToolContext) -> str:\n",
    "    \"\"\"Get information about the current agent.\n",
    "    \n",
    "    Returns:\n",
    "        Agent information including name, tools, and configuration\n",
    "    \"\"\"\n",
    "    agent = tool_context.invocation_state['agent']\n",
    "    \n",
    "    info = {\n",
    "        'name': agent.config.name,\n",
    "        'model': str(type(agent.config.model).__name__),\n",
    "        'tools': list(agent.tool_registry.registry.keys()),\n",
    "        'tool_count': len(agent.tool_registry.registry),\n",
    "    }\n",
    "    \n",
    "    return json.dumps(info, indent=2)\n",
    "\n",
    "# Create context-aware agent\n",
    "context_agent = Agent(AgentConfig(\n",
    "    model=OpenAIModel(model_id='gpt-5-nano'),\n",
    "    name='context_aware_agent',\n",
    "    system_prompt='You are AI agent, you have access to logging and introspection tools.',\n",
    "    tools=[log_invocation, get_agent_info],\n",
    "))\n",
    "\n",
    "print(\"=== Solution 4: Context-Aware Tools ===\")\n",
    "print(\"âœ… Created tools with ToolContext access\")\n",
    "print(\"âœ… Extract agent metadata automatically\")\n",
    "print(\"âœ… Structured logging with timestamps\")\n",
    "print(\"âœ… Introspection capabilities\")\n",
    "\n",
    "result = await context_agent.do({'messages': ['tell me about the agent-yourself, then log the tool invocation']})\n",
    "print(result.content)\n",
    "print('# of tool calls', len(context_agent.get_tool_traces()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ðŸŽ¯ Summary & Next Steps\n",
    "\n",
    "### Congratulations! ðŸŽ‰\n",
    "\n",
    "You've mastered tool creation and integration in Spark! You can now build agents that interact with external systems, execute code, and solve complex problems through tool use.\n",
    "\n",
    "### What You Learned:\n",
    "\n",
    "âœ… **Tool Fundamentals**\n",
    "- How the @tool decorator works\n",
    "- Tool calling flow and mechanics\n",
    "- Tool registration and specification\n",
    "\n",
    "âœ… **Tool Development**\n",
    "- Writing clear docstrings for LLM guidance\n",
    "- Using type hints for validation\n",
    "- Handling errors gracefully\n",
    "- Creating multi-tool agents\n",
    "\n",
    "âœ… **Advanced Patterns**\n",
    "- Multi-step tool workflows with max_steps\n",
    "- Tool choice strategies (auto, any, specific, none)\n",
    "- Context-aware tools\n",
    "- Tool debugging techniques\n",
    "- Tool trace analysis\n",
    "\n",
    "âœ… **Production Practices**\n",
    "- Tool specification inspection\n",
    "- Direct tool testing\n",
    "- Debugging strategies with tool traces\n",
    "- Common pitfalls and solutions\n",
    "- Iteration control with max_steps\n",
    "\n",
    "### Key Patterns to Remember:\n",
    "\n",
    "```python\n",
    "# Simple tool\n",
    "@tool\n",
    "def my_tool(param: str) -> str:\n",
    "    \"\"\"Clear description for the LLM.\n",
    "    \n",
    "    Args:\n",
    "        param: Parameter description\n",
    "    \"\"\"\n",
    "    return f\"Result: {param}\"\n",
    "\n",
    "# Agent with tools and configuration\n",
    "agent = Agent(\n",
    "    config=AgentConfig(\n",
    "        model=model,\n",
    "        tools=[my_tool],\n",
    "        tool_choice='auto',      # Control tool usage\n",
    "        max_steps=10,            # Limit iterations\n",
    "    )\n",
    ")\n",
    "\n",
    "# Execute and inspect traces\n",
    "result = await agent.do({'messages': query})\n",
    "for trace in result.state.tool_trace:\n",
    "    print(f\"Called: {trace['name']}\")\n",
    "```\n",
    "\n",
    "### ðŸ“š Related Resources:\n",
    "\n",
    "- Example files: `e007_agent_with_tools.py`, `e009_tool_agent.py`\n",
    "- Source: `spark/tools/decorator.py`, `spark/agents/agent.py`\n",
    "- Tutorial 7: Agent Configuration and Memory (review if needed)\n",
    "- Tutorial 4: Your First AI Agent\n",
    "\n",
    "### ðŸš€ Next Tutorial: Structured Outputs and Type Safety\n",
    "\n",
    "In **Tutorial 9**, you'll learn how to:\n",
    "- Generate structured JSON outputs from agents\n",
    "- Use Pydantic schemas for validation\n",
    "- Handle structured output errors\n",
    "- Combine tools with structured outputs\n",
    "- Build type-safe agent workflows\n",
    "\n",
    "### ðŸ”§ Before You Move On:\n",
    "\n",
    "Make sure you can:\n",
    "1. âœ… Create tools with the @tool decorator\n",
    "2. âœ… Write clear docstrings and use type hints\n",
    "3. âœ… Handle errors gracefully in tools\n",
    "4. âœ… Build agents with multiple tools\n",
    "5. âœ… Configure tool_choice strategies\n",
    "6. âœ… Set max_steps to control iterations\n",
    "7. âœ… Debug tool execution with traces\n",
    "8. âœ… Create multi-step tool workflows\n",
    "9. âœ… Use ToolContext for advanced scenarios\n",
    "\n",
    "### ðŸŽ“ Tutorial Series Progress:\n",
    "\n",
    "- âœ… **Tutorial 1: Hello Spark** - Basic nodes\n",
    "- âœ… **Tutorial 2: Batch Processing** - Parallel execution\n",
    "- âœ… **Tutorial 3: Simple Flows** - Graph basics\n",
    "- âœ… **Tutorial 4: Your First AI Agent** - Agent fundamentals\n",
    "- âœ… **Tutorial 5: Conditional Routing** - Decision making\n",
    "- âœ… **Tutorial 6: Agent Config & Memory** - Configuration\n",
    "- âœ… **Tutorial 7: Tools** - *You are here!* ðŸŽ¯\n",
    "- âž¡ï¸ **Tutorial 8: TBD\n",
    "\n",
    "### ðŸŒŸ Pro Tips:\n",
    "\n",
    "- **Start simple**: Begin with single-purpose tools\n",
    "- **Test tools directly**: Don't wait for agent integration\n",
    "- **Write for the LLM**: Docstrings guide tool selection\n",
    "- **Handle errors**: Return errors as strings, don't raise\n",
    "- **Use type hints**: Catch errors early\n",
    "- **Keep tools focused**: Single responsibility principle\n",
    "- **Control iterations**: Use max_steps to prevent runaway execution\n",
    "- **Force tool usage**: Use tool_choice='any' when tools are required\n",
    "- **Debug with traces**: Access result.state.tool_trace for detailed analysis\n",
    "- **Add logging**: Track tool execution in production\n",
    "- **Monitor usage**: Understand which tools are called most\n",
    "\n",
    "### ðŸŽ¯ Challenge Before Next Tutorial:\n",
    "\n",
    "Build a \"Personal Assistant Agent\" that:\n",
    "1. Has at least 5 different tools\n",
    "2. Can chain tool calls for complex tasks\n",
    "3. Includes proper error handling\n",
    "4. Has one context-aware tool for logging\n",
    "5. Uses type hints and Literal types\n",
    "6. Configures max_steps appropriately\n",
    "7. Uses different tool_choice strategies for different scenarios\n",
    "8. Logs tool traces for debugging\n",
    "\n",
    "Example tools:\n",
    "- Get weather\n",
    "- Set reminder\n",
    "- Search information\n",
    "- Calculate expenses\n",
    "- Log activity\n",
    "\n",
    "This will prepare you for structured outputs in Tutorial 9!\n",
    "\n",
    "---\n",
    "\n",
    "**You're now ready to build production-ready agents with powerful tool integration!** ðŸš€\n",
    "\n",
    "### ðŸ“ Production Features Summary:\n",
    "\n",
    "The following features are now available in Spark:\n",
    "\n",
    "âœ… **tool_choice configuration** - Control tool usage with 'auto', 'any', 'none', or specific tool selection\n",
    "âœ… **max_steps configuration** - Limit reasoning iterations to prevent infinite loops and control costs\n",
    "âœ… **Tool trace logging** - Automatic tracking of all tool calls with parameters, results, and metadata\n",
    "\n",
    "These features enable robust, production-ready tool-based agent systems with full observability and control!\n",
    "\n",
    "Have questions or feedback? Check the Spark documentation or open an issue on GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
