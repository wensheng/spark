{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 5: Your First AI Agent\n",
    "\n",
    "**Difficulty:** Beginner | **Time:** 25 minutes\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Understand the difference between Nodes and Agents\n",
    "- Create and configure an Agent\n",
    "- Work with different LLM providers\n",
    "- Handle agent inputs and outputs\n",
    "\n",
    "## Real-World Use Case\n",
    "\n",
    "Imagine you want to build an AI assistant that can answer questions, help with customer service, or analyze documents. While you could build this using regular nodes with LLM calls, Spark provides a specialized **Agent** class that handles the complexity of AI interactions for you.\n",
    "\n",
    "In this tutorial, you'll learn how to create AI agents that can:\n",
    "- Answer questions using different language models\n",
    "- Maintain context and conversations\n",
    "- Use structured prompts and system instructions\n",
    "- Integrate with multiple AI providers (OpenAI, Bedrock, Ollama, etc.)\n",
    "\n",
    "We'll start by building a simple LLM node to understand the fundamentals, then move to the more powerful Agent class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Concepts\n",
    "\n",
    "### Node vs Agent\n",
    "\n",
    "**Node** (from Tutorial 1):\n",
    "- Generic processing unit\n",
    "- You define exactly what it does in `process()`\n",
    "- Manual handling of inputs/outputs\n",
    "- Good for data transformation, calculations, workflows\n",
    "\n",
    "**Agent** (new in this tutorial):\n",
    "- Specialized for AI/LLM interactions\n",
    "- Handles LLM calls, message formatting, and responses automatically\n",
    "- Built-in support for conversations, tools, and structured output\n",
    "- Ideal for AI assistants, chatbots, and reasoning tasks\n",
    "\n",
    "### When to Use Each\n",
    "\n",
    "Use **Nodes** for:\n",
    "- Data processing and transformations\n",
    "- API integrations (non-LLM)\n",
    "- Workflow orchestration\n",
    "- When you need full control over the logic\n",
    "\n",
    "Use **Agents** for:\n",
    "- Chatbots and conversational AI\n",
    "- Question answering and reasoning\n",
    "- Content generation and analysis\n",
    "- When working with language models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's import the necessary classes and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the classes we need\n",
    "from spark.nodes import Node\n",
    "from spark.agents.agent import Agent\n",
    "from spark.models import OpenAIModel\n",
    "from spark.agents.config import AgentConfig\n",
    "from spark.utils.common import ask_llm, arun\n",
    "\n",
    "# For testing without API keys\n",
    "from spark.models.echo import EchoModel\n",
    "\n",
    "import asyncio\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: LLM Node (The Foundation)\n",
    "\n",
    "Before we jump to Agents, let's build a simple node that calls an LLM. This will help you understand what's happening under the hood when we use Agents.\n",
    "\n",
    "### Key Points:\n",
    "- Use `ask_llm()` utility for simple LLM calls\n",
    "- You handle the input/output formatting manually\n",
    "- Good for understanding the basics but limited for complex interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLLMNode(Node):\n",
    "    \"\"\"A node that calls an LLM to answer questions.\"\"\"\n",
    "    \n",
    "    def process(self, context):\n",
    "        # Extract the question from inputs\n",
    "        question = context.inputs.content.get('question', '')\n",
    "        \n",
    "        if not question:\n",
    "            return {'error': 'No question provided'}\n",
    "        \n",
    "        print(f\"ü§î Question: {question}\")\n",
    "        \n",
    "        # Use the ask_llm utility to get an answer\n",
    "        answer = ask_llm(question)\n",
    "        \n",
    "        return {\n",
    "            'question': question,\n",
    "            'answer': answer,\n",
    "            'timestamp': time.time()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Simple LLM Node Demo ===\n",
      "ü§î Question: What is the capital of France?\n",
      "‚úÖ Result: Paris.\n",
      "\n",
      "ü§î Question: Explain photosynthesis in one sentence.\n",
      "‚úÖ Result: Photosynthesis is the process by which green plants, algae, and some bacteria use light energy to convert carbon dioxide and water into glucose and oxygen.\n",
      "\n",
      "ü§î Question: Why is the sky blue? Explain in under 150 words\n",
      "‚úÖ Result: Sunlight is white, made of many colors. When it hits Earth‚Äôs atmosphere, it collides with gas molecules and scatters. Shorter wavelengths (blue and violet) scatter much more than longer ones (red, yellow). This Rayleigh scattering makes blue light spread in all directions. Our eyes see blue from every part of the sky, so it looks blue.\n",
      "\n",
      "Violet light scatters even more, but the sky isn‚Äôt violet because the atmosphere absorbs much of it and our eyes are less sensitive to violet.\n",
      "\n",
      "At sunrise and sunset, sunlight travels through more air, scattering away the blue and green colors and leaving reds and oranges, which is why those times look reddish.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the Simple LLM Node\n",
    "llm_node = SimpleLLMNode()\n",
    "\n",
    "# Ask some questions\n",
    "questions = [\n",
    "    \"What is the capital of France?\",\n",
    "    \"Explain photosynthesis in one sentence.\",\n",
    "    \"Why is the sky blue? Explain in under 150 words\"\n",
    "]\n",
    "\n",
    "print(\"=== Simple LLM Node Demo ===\")\n",
    "for question in questions:\n",
    "    result = await llm_node.run({'question': question})\n",
    "    print(f\"‚úÖ Answer: {result.content['answer']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the ask_llm() Utility\n",
    "\n",
    "The `ask_llm()` utility is a simple wrapper that:\n",
    "1. Takes a text prompt\n",
    "2. Sends it to a configured LLM (defaults to OpenAi gpt-5-mini for testing)\n",
    "3. Returns the text response\n",
    "\n",
    "**Other Models**: To use real LLMs, set environment variables:\n",
    "- `OPENAI_API_KEY` for OpenAI models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Enter the Agent\n",
    "\n",
    "Now let's use Spark's Agent class, which provides much more powerful and flexible AI interactions.\n",
    "\n",
    "### Key Advantages of Agents:\n",
    "- **Message-based interaction**: Proper conversation handling\n",
    "- **Multiple models**: Easy switching between OpenAI, Bedrock, Ollama, etc.\n",
    "- **Configuration**: System prompts, templates, and behavior control\n",
    "- **Extensibility**: Built-in support for tools, memory, and structured output\n",
    "- **Error handling**: Robust error management and retry logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Simple Agent Demo ===\n",
      "Question: What is the matthew effect in under 150 words?\n",
      "Answer: The Matthew effect is the sociological phenomenon where advantages accumulate to those who already have them‚Äî‚Äúthe rich get richer.‚Äù Coined by Robert K. Merton (1968) after the Gospel of Matthew, it describes how small initial differences in status, recognition, resources, or success lead to growing disparities because benefits (funding, attention, opportunities) concentrate with the already successful. It shows up in science (well-known researchers get more credit), education (early achievers get more support), economics, and online networks (popular content gains more visibility).\n"
     ]
    }
   ],
   "source": [
    "# Create a simple Agent with EchoModel (for testing - no API key needed)\n",
    "agent = Agent(model_id='openai/gpt-5-mini')\n",
    "\n",
    "print(\"=== Simple Agent Demo ===\")\n",
    "question = \"What is the matthew effect in under 150 words?\"\n",
    "print(f\"Question: {question}\")\n",
    "\n",
    "# Execute the agent\n",
    "await agent.run({'messages': [{\"role\": \"user\", \"content\": question}]})\n",
    "\n",
    "print(f\"Answer: {agent.outputs and agent.outputs.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Agent Messages\n",
    "\n",
    "Agents expect messages in a specific format:\n",
    "\n",
    "```python\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Your question here\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Previous response\"},\n",
    "    {\"role\": \"user\", \"content\": \"Follow-up question\"}\n",
    "]\n",
    "```\n",
    "\n",
    "This format allows agents to maintain conversation context and handle multi-turn dialogues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Agent with Configuration\n",
    "\n",
    "Let's create a more sophisticated agent using AgentConfig. This gives us control over the agent's behavior, personality, and capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Configured Agent Demo ===\n",
      "\n",
      "üôã‚Äç‚ôÄÔ∏è Question: What is machine learning?\n",
      "ü§ñ Answer: Machine learning is a branch of artificial intelligence where computers learn patterns from data to make predictions or decisions without being explicitly programmed for each task. A model is trained on labeled or unlabeled data (supervised, unsupervised, or reinforcement learning), then evaluated and used to predict new cases. Common uses include spam filters, recommendations, image recognition, and fraud detection. Want a simple example or a deeper dive into one type?\n",
      "\n",
      "üôã‚Äç‚ôÄÔ∏è Question: How do I bake a chocolate cake?\n",
      "ü§ñ Answer: Simple chocolate cake\n",
      "\n",
      "Ingredients:\n",
      "- 1 3/4 cups (220 g) all‚Äëpurpose flour\n",
      "- 3/4 cup (75 g) unsweetened cocoa powder\n",
      "- 2 cups (400 g) sugar\n",
      "- 1 1/2 tsp baking powder, 1 1/2 tsp baking soda, 1 tsp salt\n",
      "- 2 large eggs\n",
      "- 1 cup (240 ml) milk\n",
      "- 1/2 cup (120 ml) vegetable oil\n",
      "- 2 tsp vanilla\n",
      "- 1 cup (240 ml) boiling water (or hot coffee)\n",
      "\n",
      "Instructions:\n",
      "1. Preheat oven to 350¬∞F (175¬∞C). Grease two 9\" round pans.\n",
      "2. Whisk dry ingredients. Add eggs, milk, oil, vanilla; beat 1‚Äì2 min.\n",
      "3. Stir in boiling water (batter will be thin).\n",
      "4. Divide batter, bake 30‚Äì35 min until a toothpick comes out clean.\n",
      "5. Cool 10 min, remove from pans, cool completely; frost as desired.\n",
      "\n",
      "Want a quick chocolate frosting recipe?\n",
      "\n",
      "üôã‚Äç‚ôÄÔ∏è Question: Explain the concept of recursion in programming.\n",
      "ü§ñ Answer: Recursion is when a function calls itself to solve a problem by breaking it into smaller instances. Every recursive solution needs:\n",
      "- a base case (stops recursion), and\n",
      "- a recursive case (reduces the problem toward the base).\n",
      "\n",
      "Example (factorial):\n",
      "function fact(n):\n",
      "  if n == 0: return 1\n",
      "  else: return n * fact(n-1)\n",
      "\n",
      "Each call is pushed on the call stack until the base case, then results unwind. Recursion makes code for divide-and-conquer, tree traversal, and backtracking clearer, but can use more memory and risk stack overflow; some languages optimize tail recursion. Want a language-specific example?\n"
     ]
    }
   ],
   "source": [
    "# Create an agent with configuration\n",
    "qa_agent = Agent(\n",
    "    config=AgentConfig(\n",
    "        model=OpenAIModel(model_id='gpt-5-mini'),\n",
    "        system_prompt=\"\"\"You are a helpful AI assistant. You are knowledgeable, friendly, and provide clear, concise answers.\n",
    "        \n",
    "        Guidelines:\n",
    "        - Answer questions directly and accurately\n",
    "        - If you don't know something, admit it\n",
    "        - Keep responses under 100 words when possible\n",
    "        - Be encouraging and positive\"\"\",\n",
    "        prompt_template=\"User Question: {{question}}\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"=== Configured Agent Demo ===\")\n",
    "\n",
    "# Test with different types of questions\n",
    "test_questions = [\n",
    "    \"What is machine learning?\",\n",
    "    \"How do I bake a chocolate cake?\",\n",
    "    \"Explain the concept of recursion in programming.\"\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    print(f\"\\nüôã‚Äç‚ôÄÔ∏è Question: {question}\")\n",
    "    \n",
    "    # Execute with the question\n",
    "    await qa_agent.do({\n",
    "        'messages': [{\"role\": \"user\", \"content\": question}]\n",
    "    })\n",
    "    \n",
    "    answer = qa_agent.outputs and qa_agent.outputs.content\n",
    "    print(f\"ü§ñ Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding AgentConfig Options\n",
    "\n",
    "The `AgentConfig` we used includes:\n",
    "\n",
    "- **`model_id`**: Which LLM to use ('echo' for testing, 'openai/gpt-4o-mini', etc.)\n",
    "- **`system_prompt`**: Instructions that define the agent's behavior and personality\n",
    "- **`prompt_template`**: Jinja2 template for formatting user inputs\n",
    "\n",
    "We'll explore more configuration options in future tutorials (tools, memory, structured output, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Different Model Providers\n",
    "\n",
    "One of the powerful features of Spark Agents is the ability to switch between different LLM providers. Let's explore how to work with various models.\n",
    "\n",
    "### Available Providers:\n",
    "- **EchoModel**: Testing (no API key)\n",
    "- **OpenAI**: GPT models (requires OPENAI_API_KEY, if you use OpenAI compatible models, provide a base_url)\n",
    "- **Bedrock**: AWS models (requires AWS credentials)\n",
    "- **Gemini**: Google models (requires GEMINI_API_KEY)\n",
    "- **Others**: More will be added in the future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use real models (not just the echo model), you need to configure API keys:\n",
    "\n",
    "```bash\n",
    "# For OpenAI\n",
    "export OPENAI_API_KEY=\"your-openai-api-key\"\n",
    "\n",
    "# For AWS Bedrock\n",
    "export AWS_ACCESS_KEY_ID=\"your-access-key\"\n",
    "export AWS_SECRET_ACCESS_KEY=\"your-secret-key\"\n",
    "export AWS_REGION=\"us-east-1\"\n",
    "\n",
    "# For Google Gemini\n",
    "export GEMINI_API_KEY=\"your-gemini-api-key\"\n",
    "\n",
    "agent = Agent(model_id='openai/gpt-4o-mini')\n",
    "or\n",
    "agent = Agent(model_id='bedrock/us.anthropic.claude-sonnet-4-5-20250929-v1:0')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Building a Practical Q&A Agent\n",
    "\n",
    "Let's build a practical Q&A agent that demonstrates the key concepts we've learned. This agent will be designed to answer educational questions in a specific style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Educational Q&A Agent Demo ===\n",
      "\n",
      "üìö Subject: Biology\n",
      "üôã‚Äç‚ôÄÔ∏è Question: What is photosynthesis?\n",
      "üéì Tutor: Simple answer: Photosynthesis is the process plants, algae, and some bacteria use to turn sunlight, carbon dioxide (CO2), and water (H2O) into sugar (glucose) and oxygen (O2) ‚Äî it‚Äôs how they make food and store energy. üåø‚ú®\n",
      "\n",
      "How it works in one line: chlorophyll captures light energy, uses it to split water (releasing O2) and make energy carriers (ATP, NADPH), then those power the Calvin cycle to fix CO2 into glucose.\n",
      "\n",
      "Analogy: Think of a leaf as a solar-powered factory ‚Äî sunlight is the electricity, chlorophyll are the solar panels, and the factory builds sugar ‚Äúbatteries‚Äù for the plant. ‚ö°‚û°Ô∏èüç¨\n",
      "\n",
      "Want a short diagram or a quick walk-through of the light and dark (Calvin cycle) steps? üéì\n",
      "\n",
      "üìö Subject: Mathematics\n",
      "üôã‚Äç‚ôÄÔ∏è Question: Why do we need to learn math?\n",
      "üéì Tutor: Simple answer: We learn math because it teaches clear thinking and problem-solving we use every day ‚Äî from managing money and understanding data to building technology and making fair decisions. üéì‚ú®\n",
      "\n",
      "Example/analogy: Think of math as a toolbox (or recipe book) ‚Äî learning fractions and percentages helps you split a bill, scale a recipe, or figure discounts while algebra and logic help you plan projects or debug code. üß∞üçΩÔ∏èüî¢\n",
      "\n",
      "Want to try a quick real-life problem (like splitting a bill or calculating a sale price) to see math in action? üòä\n",
      "\n",
      "üìö Subject: History\n",
      "üôã‚Äç‚ôÄÔ∏è Question: What caused World War I?\n",
      "üéì Tutor: Simple answer: The immediate spark was the assassination of Archduke Franz Ferdinand in 1914, but the war happened because long-term causes ‚Äî militarism, a system of rigid alliances, imperial rivalries, nationalism, and an arms race ‚Äî turned that spark into a global conflict. üéì‚ú®\n",
      "\n",
      "Concrete example: Austria-Hungary‚Äôs harsh ultimatum to Serbia activated alliances (Germany backed Austria; Russia backed Serbia), so local fighting cascaded into full-scale war.\n",
      "\n",
      "Analogy: Think of Europe as a powder keg with tangled dominoes ‚Äî one shove (assassination) toppled many connected pieces. üí•üß©\n",
      "\n",
      "Want a short timeline or a map showing how each country got pulled in? üòä\n",
      "\n",
      "üìö Subject: Computer Science\n",
      "üôã‚Äç‚ôÄÔ∏è Question: How do computers work?\n",
      "üéì Tutor: Simple answer: A computer turns input into binary data (0s and 1s), the CPU follows program instructions to process that data, RAM holds working data, storage keeps files long-term, and the operating system coordinates everything so programs and devices can work together. üíª‚ú®\n",
      "\n",
      "Analogy: Think of a computer like a kitchen ‚Äî the CPU is the chef who follows recipes (programs); RAM is the counter space for ingredients; storage is the pantry; the OS is the head chef organizing tasks; keyboard/mouse are the hands and eyes. üç≥‚öôÔ∏è\n",
      "\n",
      "Want a short demo of how binary represents letters or a quick look at the CPU‚Äôs fetch‚Äëdecode‚Äëexecute cycle? üéì\n"
     ]
    }
   ],
   "source": [
    "tutor = Agent(\n",
    "    config=AgentConfig(\n",
    "        model=OpenAIModel(model_id='gpt-5-mini'),\n",
    "        system_prompt=\"\"\"You are an enthusiastic and patient educational tutor. Your goal is to help students learn concepts clearly.\n",
    "                \n",
    "            Your teaching style:\n",
    "            - Start with a simple, direct answer\n",
    "            - Provide one concrete example or analogy\n",
    "            - End with an encouraging follow-up question\n",
    "            - Keep explanations under 150 words\n",
    "            - Use emojis to make learning fun üéì‚ú®\n",
    "        \"\"\",\n",
    "        prompt_template=\"Student Question: {{question}}\\n\\nSubject: {{subject}}\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"=== Educational Q&A Agent Demo ===\")\n",
    "\n",
    "educational_questions = [\n",
    "    {\"question\": \"What is photosynthesis?\", \"subject\": \"Biology\"},\n",
    "    {\"question\": \"Why do we need to learn math?\", \"subject\": \"Mathematics\"},\n",
    "    {\"question\": \"What caused World War I?\", \"subject\": \"History\"},\n",
    "    {\"question\": \"How do computers work?\", \"subject\": \"Computer Science\"}\n",
    "]\n",
    "\n",
    "for item in educational_questions:    \n",
    "    print(f\"\\nüìö Subject: {item['subject']}\")\n",
    "    print(f\"üôã‚Äç‚ôÄÔ∏è Question: {item['question']}\")\n",
    "    \n",
    "    answer = await tutor.run(item)\n",
    "    print(f\"üéì Tutor: {answer.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6: Comparison - Node vs Agent\n",
    "\n",
    "Let's compare our SimpleLLMNode with our Agent to understand the differences in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Node vs Agent Comparison ===\n",
      "Question: Explain the difference between weather and climate.\n",
      "\n",
      "1Ô∏è‚É£ Simple LLM Node:\n",
      "ü§î Question: Explain the difference between weather and climate.\n",
      "   Answer: - Weather: The current state of the atmosphere at a specific place and time. It includes temperature, humidity, precipitation, wind, clouds, etc. Example: ‚ÄúIt‚Äôs 28¬∞C with light rain in Tokyo at 3 PM,‚Äù or a forecast for the next 24‚Äì72 hours.\n",
      "\n",
      "- Climate: The long-term patterns of weather in a region, described by averages and ranges over many years (usually about 30 years). It includes typical temperatures, precipitation, seasons, and how often extreme events occur. Example: ‚ÄúSeattle has a wet climate with mild winters and light summers,‚Äù or ‚Äúthe 30-year normal rainfall for this area is about 100 cm per year.‚Äù\n",
      "\n",
      "Key differences:\n",
      "- Timescale: Weather is short-term (minutes to days); climate is long-term (years to decades).\n",
      "- What‚Äôs described: Weather describes current conditions; climate describes average conditions and variability over time.\n",
      "- What it tells you: Weather tells you what to wear or what to expect today; climate tells you what‚Äôs typical for a region and how that pattern might be changing.\n",
      "\n",
      "How they relate:\n",
      "- Climate sets the background pattern you expect; weather is the day-to-day variation around that pattern.\n",
      "- Climate change can shift the baseline (e.g., warmer average temperatures) and also affect the frequency and intensity of extreme weather events (heatwaves, heavy rains), even though any single forecast day is still weather.\n",
      "   Raw output: {'question': 'Explain the difference between weather and climate.', 'answer': '- Weather: The current state of the atmosphere at a specific place and time. It includes temperature, humidity, precipitation, wind, clouds, etc. Example: ‚ÄúIt‚Äôs 28¬∞C with light rain in Tokyo at 3 PM,‚Äù or a forecast for the next 24‚Äì72 hours.\\n\\n- Climate: The long-term patterns of weather in a region, described by averages and ranges over many years (usually about 30 years). It includes typical temperatures, precipitation, seasons, and how often extreme events occur. Example: ‚ÄúSeattle has a wet climate with mild winters and light summers,‚Äù or ‚Äúthe 30-year normal rainfall for this area is about 100 cm per year.‚Äù\\n\\nKey differences:\\n- Timescale: Weather is short-term (minutes to days); climate is long-term (years to decades).\\n- What‚Äôs described: Weather describes current conditions; climate describes average conditions and variability over time.\\n- What it tells you: Weather tells you what to wear or what to expect today; climate tells you what‚Äôs typical for a region and how that pattern might be changing.\\n\\nHow they relate:\\n- Climate sets the background pattern you expect; weather is the day-to-day variation around that pattern.\\n- Climate change can shift the baseline (e.g., warmer average temperatures) and also affect the frequency and intensity of extreme weather events (heatwaves, heavy rains), even though any single forecast day is still weather.', 'timestamp': 1763575234.6650088}\n",
      "\n",
      "==================================================\n",
      "\n",
      "2Ô∏è‚É£ Agent:\n",
      "   Answer: Weather and climate are related but describe different things.\n",
      "\n",
      "- Weather: the current state of the atmosphere at a place and time. It includes temperature, humidity, precipitation, wind, visibility, etc. Weather can change from hours to days. Examples: It‚Äôs raining now in London; today‚Äôs high is 75¬∞F; a cold front is moving in.\n",
      "\n",
      "- Climate: the long-term pattern of weather in a region, averaged over many years (commonly about 30 years). It describes what is typical and how much variation there is, not what will happen on a single day. Examples: Tokyo has a warm, wet summers and cool winters; the region tends to get a certain amount of rainfall each year.\n",
      "\n",
      "Key differences\n",
      "- Timescale: weather is short-term (hours to days); climate is long-term (decades-or-more).\n",
      "- Scope: weather is the state at a location and moment; climate is the statistical properties of weather over a region and a long period.\n",
      "- Predictability: weather forecasts aim to predict the next days; climate science projects long-term trends and variability under different conditions (like different greenhouse gas scenarios).\n",
      "- Use: weather helps with immediate decisions (dress, travel, storms); climate helps with planning and understanding trends (agriculture, infrastructure, risk of extreme events).\n",
      "\n",
      "How they relate to climate change\n",
      "- Climate change shifts the distribution of weather events. For example, heat waves may become more frequent and intense, heavy rainfall may become more likely, even if a specific storm‚Äôs path is a weather event.\n",
      "- Weather will still vary day to day; climate change changes the long-term expectations for that variability.\n",
      "\n",
      "If you want, I can give a simple example with numbers or explain how normals (30-year climate averages) are calculated.\n",
      "   Agent outputs: id=None type='text' content='Weather and climate are related but describe different things.\\n\\n- Weather: the current state of the atmosphere at a place and time. It includes temperature, humidity, precipitation, wind, visibility, etc. Weather can change from hours to days. Examples: It‚Äôs raining now in London; today‚Äôs high is 75¬∞F; a cold front is moving in.\\n\\n- Climate: the long-term pattern of weather in a region, averaged over many years (commonly about 30 years). It describes what is typical and how much variation there is, not what will happen on a single day. Examples: Tokyo has a warm, wet summers and cool winters; the region tends to get a certain amount of rainfall each year.\\n\\nKey differences\\n- Timescale: weather is short-term (hours to days); climate is long-term (decades-or-more).\\n- Scope: weather is the state at a location and moment; climate is the statistical properties of weather over a region and a long period.\\n- Predictability: weather forecasts aim to predict the next days; climate science projects long-term trends and variability under different conditions (like different greenhouse gas scenarios).\\n- Use: weather helps with immediate decisions (dress, travel, storms); climate helps with planning and understanding trends (agriculture, infrastructure, risk of extreme events).\\n\\nHow they relate to climate change\\n- Climate change shifts the distribution of weather events. For example, heat waves may become more frequent and intense, heavy rainfall may become more likely, even if a specific storm‚Äôs path is a weather event.\\n- Weather will still vary day to day; climate change changes the long-term expectations for that variability.\\n\\nIf you want, I can give a simple example with numbers or explain how normals (30-year climate averages) are calculated.' raw=[] metadata={} extras={} state=None\n"
     ]
    }
   ],
   "source": [
    "# Create both implementations\n",
    "simple_node = SimpleLLMNode()\n",
    "simple_agent = Agent(model_id='openai/gpt-5-nano')\n",
    "\n",
    "comparison_question = \"Explain the difference between weather and climate.\"\n",
    "\n",
    "print(\"=== Node vs Agent Comparison ===\")\n",
    "print(f\"Question: {comparison_question}\\n\")\n",
    "\n",
    "# Test the Node approach\n",
    "print(\"1Ô∏è‚É£ Simple LLM Node:\")\n",
    "node_result = await simple_node.run({'question': comparison_question})\n",
    "node_answer = node_result.content['answer']\n",
    "print(f\"   Answer: {node_answer}\")\n",
    "print(f\"   Raw output: {node_result.content}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Test the Agent approach\n",
    "print(\"2Ô∏è‚É£ Agent:\")\n",
    "agent_outputs = await simple_agent.run(comparison_question)\n",
    "agent_answer = agent_outputs.content\n",
    "print(f\"   Answer: {agent_answer}\")\n",
    "print(f\"   Agent outputs: {simple_agent.outputs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Differences Observed\n",
    "\n",
    "1. **Input Format**: \n",
    "   - Node: `{'question': 'text'}`\n",
    "   - Agent: `{'messages': [{'role': 'user', 'content': 'text'}]}`\n",
    "     When the argument is a string, it will be automatically converted to Messages.\n",
    "\n",
    "2. **Output Format**:\n",
    "   - Node: Standardized NodeMessage with content\n",
    "   - Agent: same\n",
    "\n",
    "3. **Extensibility**:\n",
    "   - Node: Limited to what we implement in `process()`\n",
    "   - Agent: Built-in support for conversations, tools, memory, etc.\n",
    "\n",
    "4. **Configuration**:\n",
    "   - Node: Hardcoded behavior\n",
    "   - Agent: Configurable via AgentConfig (system prompts, templates, tools, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### ‚úÖ What You Learned:\n",
    "\n",
    "1. **Nodes vs Agents**:\n",
    "   - Nodes: Generic processing units with full control\n",
    "   - Agents: Specialized for AI/LLM interactions with built-in features\n",
    "\n",
    "2. **Simple LLM Calls**:\n",
    "   - Use `ask_llm()` utility for basic LLM interactions\n",
    "   - Good for understanding fundamentals but limited functionality\n",
    "\n",
    "3. **Agent Fundamentals**:\n",
    "   - Create agents with `Agent(model_id='...')`\n",
    "   - Use message format for conversations\n",
    "   - Access results via `agent.outputs.content`\n",
    "\n",
    "4. **Agent Configuration**:\n",
    "   - Use `AgentConfig` to customize behavior\n",
    "   - Set system prompts for personality and instructions\n",
    "   - Use prompt templates for input formatting\n",
    "\n",
    "5. **Model Providers**:\n",
    "   - Easy switching between OpenAI, Bedrock, Ollama, etc.\n",
    "   - Just change `model_id` parameter\n",
    "   - EchoModel available for testing without API keys\n",
    "\n",
    "6. **Practical Applications**:\n",
    "   - Q&A systems\n",
    "   - Educational tutors\n",
    "   - Customer service assistants\n",
    "   - Content generation and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí™ Practice Exercises\n",
    "\n",
    "Test your understanding with these hands-on exercises!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Create a Specialized Agent\n",
    "\n",
    "Create a `CodeReviewAgent` that provides feedback on Python code. The agent should:\n",
    "- Be encouraging and constructive\n",
    "- Focus on one improvement area at a time\n",
    "- Suggest specific code changes\n",
    "- Keep feedback under 100 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Create a Code Review Agent\n",
    "class CodeReviewAgent:\n",
    "    \"\"\"Your code here!\"\"\"\n",
    "    \n",
    "    def __init__(self, model_id='echo'):\n",
    "        # TODO: Create an Agent with appropriate configuration\n",
    "        pass\n",
    "    \n",
    "    async def review_code(self, code):\n",
    "        # TODO: Implement code review functionality\n",
    "        pass\n",
    "\n",
    "# Test your agent\n",
    "# reviewer = CodeReviewAgent()\n",
    "# test_code = \"\"\"\n",
    "# def calculate_total(items):\n",
    "#     total = 0\n",
    "#     for item in items:\n",
    "#         total += item\n",
    "#     return total\n",
    "# \"\"\"\n",
    "# feedback = await reviewer.review_code(test_code)\n",
    "# print(f\"Code Review Feedback: {feedback}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Build a Translation Agent\n",
    "\n",
    "Create an agent that translates text between languages. Include error handling for unsupported languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Create a Translation Agent\n",
    "class TranslationAgent:\n",
    "    \"\"\"Your code here!\"\"\"\n",
    "    \n",
    "    def __init__(self, model_id='echo'):\n",
    "        # TODO: Create an Agent for translation\n",
    "        pass\n",
    "    \n",
    "    async def translate(self, text, from_lang, to_lang):\n",
    "        # TODO: Implement translation with error handling\n",
    "        pass\n",
    "\n",
    "# Test your agent\n",
    "# translator = TranslationAgent()\n",
    "# result = await translator.translate(\"Hello world\", \"English\", \"Spanish\")\n",
    "# print(f\"Translation result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Multi-Turn Conversation\n",
    "\n",
    "Create a simple chatbot that maintains conversation context across multiple turns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Create a Conversational Agent\n",
    "class ConversationalAgent:\n",
    "    \"\"\"Your code here!\"\"\"\n",
    "    \n",
    "    def __init__(self, model_id='echo'):\n",
    "        # TODO: Create an Agent and maintain conversation history\n",
    "        pass\n",
    "    \n",
    "    async def chat(self, message):\n",
    "        # TODO: Handle multi-turn conversation\n",
    "        pass\n",
    "\n",
    "# Test your conversational agent\n",
    "# chatbot = ConversationalAgent()\n",
    "# await chatbot.chat(\"Hi, my name is Alice\")\n",
    "# await chatbot.chat(\"What did I just tell you?\")\n",
    "# await chatbot.chat(\"Can you recommend a good book?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Solutions\n",
    "\n",
    "Try the exercises yourself first! Solutions are provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíª Code Review Feedback: Great that you want feedback ‚Äî thanks for sharing your work! \n",
      "\n",
      "One key improvement: include the actual code and a minimal reproducible example (what it should do, what it does, and any errors). Actionable: paste the function/class plus sample inputs and expected vs actual outputs.\n",
      "\n",
      "Example:\n",
      "```python\n",
      "def my_func(x):\n",
      "    return x*2\n",
      "\n",
      "# input: 3\n",
      "# expected: 6\n",
      "# actual: 5  # paste observed behavior/errors here\n",
      "```\n",
      "Send that and I‚Äôll review the logic/style/security quickly. üöÄ\n"
     ]
    }
   ],
   "source": [
    "# Solution 1: Code Review Agent\n",
    "code_review_agent = Agent(\n",
    "    config=AgentConfig(\n",
    "        model=OpenAIModel(model_id='gpt-5-mini'),\n",
    "        system_prompt=\"\"\"You are a supportive code reviewer. Your goal is to help developers improve their skills.\n",
    "                \n",
    "            Review guidelines:\n",
    "            - Always start with something positive\n",
    "            - Focus on ONE improvement opportunity per review\n",
    "            - Provide specific, actionable suggestions\n",
    "            - Include a code example when helpful\n",
    "            - Keep feedback under 100 words\n",
    "            - End with encouragement üöÄ\n",
    "        \"\"\",\n",
    "        prompt_template=\"Please review this Python code:\\n\\n```python\\n{code}\\n```\"\n",
    "    )\n",
    ")\n",
    "\n",
    "test_code = \"\"\"\n",
    "def calculate_total(items):\n",
    "    total = 0\n",
    "    for item in items:\n",
    "        total += item\n",
    "    return total\n",
    "\"\"\"\n",
    "feedback = await code_review_agent.run({\"code\": test_code})\n",
    "print(f\"üíª Code Review Feedback: {feedback.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç Translation result: Hola, mundo\n",
      "‚ùå Error handling: Sorry, I don't support translating to klingon. Supported languages: arabic, chinese, dutch, english, french, german, hindi, italian, japanese, korean, norwegian, portuguese, russian, spanish, swedish\n"
     ]
    }
   ],
   "source": [
    "# Solution 2: Translation Agent\n",
    "class TranslationAgent:\n",
    "    \"\"\"An agent that translates text between languages.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.agent = Agent(\n",
    "            config=AgentConfig(\n",
    "                model=OpenAIModel(model_id='gpt-5-mini'),\n",
    "                system_prompt=\"\"\"You are a professional translator. You provide accurate translations while preserving meaning and tone.\n",
    "                \n",
    "                Translation rules:\n",
    "                - Translate accurately and naturally\n",
    "                - Preserve the original tone and intent\n",
    "                - If you don't know a language, say so politely\n",
    "                - For unsupported languages, suggest alternatives\n",
    "                - Keep the translation concise and clear\"\"\",\n",
    "                prompt_template=\"Translate the following text from {from_lang} to {to_lang}:\\n\\nText: {text}\"\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Common languages for validation\n",
    "        self.supported_languages = {\n",
    "            'english', 'spanish', 'french', 'german', 'italian', \n",
    "            'portuguese', 'chinese', 'japanese', 'korean', 'russian',\n",
    "            'arabic', 'hindi', 'dutch', 'swedish', 'norwegian'\n",
    "        }\n",
    "    \n",
    "    async def translate(self, text, from_lang, to_lang):\n",
    "        # Validate inputs\n",
    "        if not text or not text.strip():\n",
    "            return \"Please provide text to translate.\"\n",
    "        \n",
    "        from_lang = from_lang.lower()\n",
    "        to_lang = to_lang.lower()\n",
    "        \n",
    "        # Check language support\n",
    "        if from_lang not in self.supported_languages:\n",
    "            return f\"Sorry, I don't support translating from {from_lang}. Supported languages: {', '.join(sorted(self.supported_languages))}\"\n",
    "        \n",
    "        if to_lang not in self.supported_languages:\n",
    "            return f\"Sorry, I don't support translating to {to_lang}. Supported languages: {', '.join(sorted(self.supported_languages))}\"\n",
    "        \n",
    "        # Don't translate if same language\n",
    "        if from_lang == to_lang:\n",
    "            return \"The source and target languages are the same. No translation needed.\"\n",
    "        \n",
    "        formatted_prompt = f\"Translate the following text from {from_lang} to {to_lang}:\\n\\nText: {text}\"\n",
    "        \n",
    "        await self.agent.do({\n",
    "            'messages': [{\"role\": \"user\", \"content\": formatted_prompt}]\n",
    "        })\n",
    "        \n",
    "        return self.agent.outputs and self.agent.outputs.content\n",
    "\n",
    "# Test the solution\n",
    "translator = TranslationAgent()\n",
    "result = await translator.translate(\"Hello world\", \"english\", \"spanish\")\n",
    "print(f\"üåç Translation result: {result}\")\n",
    "\n",
    "# Test error handling\n",
    "error_result = await translator.translate(\"Hello\", \"english\", \"klingon\")\n",
    "print(f\"‚ùå Error handling: {error_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ Starting conversation...\n",
      "\n",
      "--- Turn 1 ---\n",
      "üôã‚Äç‚ôÄÔ∏è User: Hi, my name is Alice and I love hiking.\n",
      "ü§ñ Assistant: Hi Alice ‚Äî nice to meet you! I‚Äôm glad you love hiking ‚Äî me too. Do you have favorite trails or a region you usually hike in?\n",
      "\n",
      "If you want, I can:\n",
      "- Suggest trails near you\n",
      "- Make a packing checklist for day hikes or overnight trips\n",
      "- Build a training plan to get fitter for longer hikes\n",
      "- Give gear recommendations or safety tips\n",
      "\n",
      "Quick tips to get started: check the weather and trail conditions, wear layered clothing and sturdy footwear, carry enough water and a map/phone with offline maps, and follow Leave No Trace. Which of the options above would you like first?\n",
      "\n",
      "--- Turn 2 ---\n",
      "üôã‚Äç‚ôÄÔ∏è User: What did I just tell you about myself?\n",
      "ü§ñ Assistant: You told me your name is Alice and that you love hiking. Would you like trail suggestions, a packing checklist, or something else related to hiking?\n",
      "\n",
      "--- Turn 3 ---\n",
      "üôã‚Äç‚ôÄÔ∏è User: Can you recommend a good hiking trail near San Francisco?\n"
     ]
    }
   ],
   "source": [
    "# Solution 3: Conversational Agent\n",
    "class ConversationalAgent:\n",
    "    \"\"\"An agent that maintains conversation context across multiple turns.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.agent = Agent(\n",
    "            config=AgentConfig(\n",
    "                model=OpenAIModel(model_id='gpt-5-mini'),\n",
    "                system_prompt=\"\"\"You are a friendly and helpful AI assistant. You:\n",
    "                - Remember previous parts of the conversation\n",
    "                - Reference earlier messages when relevant\n",
    "                - Maintain a consistent, helpful personality\n",
    "                - Ask follow-up questions when appropriate\n",
    "                - Keep responses conversational but concise\"\"\"\n",
    "            )\n",
    "        )\n",
    "        self.conversation_history = []\n",
    "    \n",
    "    async def chat(self, message):\n",
    "        if not message or not message.strip():\n",
    "            return \"Please say something!\"\n",
    "        \n",
    "        # Add user message to history\n",
    "        self.conversation_history.append({\n",
    "            \"role\": \"user\", \n",
    "            \"content\": message\n",
    "        })\n",
    "        \n",
    "        # Send the entire conversation history\n",
    "        await self.agent.do({\n",
    "            'messages': self.conversation_history\n",
    "        })\n",
    "        \n",
    "        # Get agent response\n",
    "        response = self.agent.outputs and self.agent.outputs.content\n",
    "        \n",
    "        # Add agent response to history\n",
    "        if response:\n",
    "            self.conversation_history.append({\n",
    "                \"role\": \"assistant\", \n",
    "                \"content\": response\n",
    "            })\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def get_conversation_summary(self):\n",
    "        \"\"\"Return a summary of the conversation so far.\"\"\"\n",
    "        total_messages = len(self.conversation_history)\n",
    "        user_messages = len([m for m in self.conversation_history if m[\"role\"] == \"user\"])\n",
    "        assistant_messages = len([m for m in self.conversation_history if m[\"role\"] == \"assistant\"])\n",
    "        \n",
    "        return {\n",
    "            \"total_messages\": total_messages,\n",
    "            \"user_messages\": user_messages,\n",
    "            \"assistant_messages\": assistant_messages,\n",
    "            \"last_topic\": self.conversation_history[-1][\"content\"] if self.conversation_history else \"No conversation yet\"\n",
    "        }\n",
    "\n",
    "# Test the solution\n",
    "chatbot = ConversationalAgent()\n",
    "\n",
    "print(\"üí¨ Starting conversation...\")\n",
    "\n",
    "# Simulate a conversation\n",
    "messages = [\n",
    "    \"Hi, my name is Alice and I love hiking.\",\n",
    "    \"What did I just tell you about myself?\",\n",
    "    \"Can you recommend a good hiking trail near San Francisco?\",\n",
    "    \"That sounds great! Do you remember my name?\"\n",
    "]\n",
    "\n",
    "for i, message in enumerate(messages, 1):\n",
    "    print(f\"\\n--- Turn {i} ---\")\n",
    "    print(f\"üôã‚Äç‚ôÄÔ∏è User: {message}\")\n",
    "    \n",
    "    response = await chatbot.chat(message)\n",
    "    print(f\"ü§ñ Assistant: {response}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "summary = chatbot.get_conversation_summary()\n",
    "print(f\"üìä Conversation Summary: {summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Summary & Next Steps\n",
    "\n",
    "### Congratulations! üéâ\n",
    "\n",
    "You've successfully learned how to create and work with AI Agents in Spark ADK! You've built a solid foundation for creating intelligent, conversational AI systems.\n",
    "\n",
    "### What You Mastered:\n",
    "\n",
    "‚úÖ **Understanding Nodes vs Agents**: When to use each approach\n",
    "\n",
    "‚úÖ **Simple LLM Calls**: Using `ask_llm()` for basic AI interactions\n",
    "\n",
    "‚úÖ **Agent Creation**: Building agents with different model providers\n",
    "\n",
    "‚úÖ **Agent Configuration**: Using AgentConfig for customization\n",
    "\n",
    "‚úÖ **Message Format**: Proper conversation handling with role-based messages\n",
    "\n",
    "‚úÖ **Practical Applications**: Q&A systems, educational tutors, code reviewers\n",
    "\n",
    "‚úÖ **Error Handling**: Robust agent design with input validation\n",
    "\n",
    "‚úÖ **Multi-turn Conversations**: Maintaining context across interactions\n",
    "\n",
    "### üìö Related Documentation:\n",
    "- Example files: `e002_single_llm_call_node.py`, `e003_single_agent.py`\n",
    "- Source: `spark/agents/agent.py`, `spark/agents/config.py`\n",
    "- Models: `spark/models/` directory for different providers\n",
    "\n",
    "### üöÄ Next Tutorial: Conditional Routing and Decision Making\n",
    "\n",
    "In **Tutorial 5**, you'll learn how to:\n",
    "- Create conditional edges between nodes\n",
    "- Route based on agent outputs and decisions\n",
    "- Build decision trees and branching workflows\n",
    "- Implement loops and cycles in graphs\n",
    "- Use LLMs to make routing decisions\n",
    "\n",
    "### üîß Before You Move On:\n",
    "\n",
    "Make sure you can:\n",
    "1. ‚úÖ Create both simple LLM nodes and agents\n",
    "2. ‚úÖ Configure agents with system prompts and templates\n",
    "3. ‚úÖ Switch between different model providers\n",
    "4. ‚úÖ Handle errors and edge cases gracefully\n",
    "5. ‚úÖ Maintain conversation context across multiple turns\n",
    "\n",
    "### üéì Tutorial Series Progress:\n",
    "- ‚úÖ **Tutorial 1: Hello Spark** - Basic nodes\n",
    "- ‚úÖ **Tutorial 2: Batch Processing** - Parallel execution  \n",
    "- ‚úÖ **Tutorial 3: Simple Flows** - Graph basics (you'll see this next!)\n",
    "- ‚úÖ **Tutorial 4: Your First AI Agent** - *You are here!* üéØ\n",
    "- ‚û°Ô∏è **Tutorial 5: Conditional Routing** - Decision making\n",
    "\n",
    "### üåü Pro Tips:\n",
    "\n",
    "- **Start with EchoModel** for testing without API costs\n",
    "- **Use system prompts** to define clear agent behavior and constraints\n",
    "- **Test with different models** to find the best balance of cost and performance\n",
    "- **Handle errors gracefully** - agents should provide helpful feedback even when things go wrong\n",
    "- **Think in conversations** - design agents to handle multi-turn interactions naturally\n",
    "\n",
    "### üéØ Challenge Before Next Tutorial:\n",
    "\n",
    "Create a \"Story Generator\" agent that:\n",
    "1. Accepts a genre and a story prompt\n",
    "2. Generates a creative 3-sentence story\n",
    "3. Maintains a consistent tone for the genre\n",
    "4. Can continue the story if the user asks for \"more\"\n",
    "\n",
    "This will prepare you well for working with conditional logic in the next tutorial!\n",
    "\n",
    "---\n",
    "\n",
    "**Happy building with Spark!** üöÄ\n",
    "\n",
    "Have questions or feedback? Check the Spark documentation or open an issue on GitHub."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
