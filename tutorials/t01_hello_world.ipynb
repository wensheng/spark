{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-header",
   "metadata": {},
   "source": [
    "# Tutorial 1: Hello Spark - Your First Node\n",
    "\n",
    "## Welcome to Spark ADK! üöÄ\n",
    "\n",
    "Welcome to your first Spark tutorial! In this hands-on session, you'll learn the foundation of Spark ADK by creating and running your first nodes.\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "By the end of this tutorial, you'll be able to:\n",
    "- ‚úÖ Understand what a **Node** is in Spark\n",
    "- ‚úÖ Create and execute a simple node\n",
    "- ‚úÖ Understand the `process()` method and its role\n",
    "- ‚úÖ Work with inputs, outputs, and ExecutionContext\n",
    "- ‚úÖ Return data from nodes\n",
    "\n",
    "### Prerequisites\n",
    "- Basic Python knowledge\n",
    "- Python 3.12+ installed\n",
    "- Spark ADK installed (`pip install spark`)\n",
    "\n",
    "### Time Required\n",
    "‚è±Ô∏è Approximately 15-20 minutes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concept-explanation",
   "metadata": {},
   "source": [
    "## üß† What is a Node?\n",
    "\n",
    "In Spark ADK, a **Node** is the fundamental building block of your AI systems. Think of a node as a processing unit that:\n",
    "\n",
    "1. **Receives inputs** (optional)\n",
    "2. **Processes data** (performs some work)\n",
    "3. **Produces outputs** (optional)\n",
    "\n",
    "### Node Class Hierarchy\n",
    "\n",
    "```\n",
    "BaseNode (abstract base class)\n",
    "    ‚Üì\n",
    "Node (adds configuration, capabilities, queues)\n",
    "    ‚Üì\n",
    "Your Custom Nodes\n",
    "```\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "- **BaseNode**: The abstract foundation all nodes inherit from\n",
    "- **Node**: The concrete class you typically inherit from (adds features like config, state, queues)\n",
    "- **process() method**: Where you define what your node does\n",
    "- **ExecutionContext**: Container for inputs, outputs, state, and metadata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-1-intro",
   "metadata": {},
   "source": [
    "## Example 1: The Simplest Node\n",
    "\n",
    "Let's start with the absolute simplest node possible - one that just prints a message.\n",
    "\n",
    "### Key Points:\n",
    "- Inherit from `Node` class\n",
    "- Define a `process()` method\n",
    "- That's it! No other methods required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spark.nodes import Node\n",
    "from spark.utils.common import arun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-node-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNode(Node):\n",
    "    \"\"\"The simplest possible node - just prints a greeting.\"\"\"\n",
    "    \n",
    "    def process(self):\n",
    "        print(\"Hello from Spark Node!\")\n",
    "        print(\"This is your first node üéâ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "execution-explanation",
   "metadata": {},
   "source": [
    "### Running a Node\n",
    "\n",
    "There are multiple ways to execute a node:\n",
    "\n",
    "1. **node.do()** - Direct execution (returns NodeMessage)\n",
    "2. **node.go()** - Continously run node (take inputs from a queue, does not return anything.)\n",
    "3. **node.run()** - Wrapper for do() or go() \n",
    "\n",
    "All three are async methods and need to be 'await'ed.\n",
    "\n",
    "In Jupyter notebooks (which support async), we can use `await` directly.   In Actual application, we need to use asyncio.run.  Spark provide a convenient function `arun` that does `asyncio.run`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-node-execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of our node\n",
    "node = SimpleNode()\n",
    "\n",
    "# Execute it\n",
    "result = await node.do()\n",
    "\n",
    "print(f\"\\nReturn value: {result}\")\n",
    "print(f\"Return type: {type(result)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "return-values-explanation",
   "metadata": {},
   "source": [
    "### Understanding the Return Value\n",
    "\n",
    "Notice that even though our `process()` method doesn't explicitly return anything, the node execution returns a `NodeMessage` object. This is Spark's standardized message format.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-2-intro",
   "metadata": {},
   "source": [
    "## Example 2: Node with Return Value\n",
    "\n",
    "Most nodes will return data for other nodes to use. Let's create a node that performs a calculation and returns the result.\n",
    "\n",
    "### Key Point:\n",
    "- The `process()` method can return any Python value (str, int, dict, list, etc.)\n",
    "- Returned values are automatically wrapped in NodeMessage format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "calculator-node",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalculatorNode(Node):\n",
    "    \"\"\"A node that performs a calculation and returns the result.\"\"\"\n",
    "    \n",
    "    def process(self):\n",
    "        result = 42 * 2\n",
    "        print(f\"Calculating: 42 * 2 = {result}\")\n",
    "        return result  # Return a simple integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "calculator-execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_node = CalculatorNode()\n",
    "result = await calc_node.do()\n",
    "\n",
    "print(f\"\\nResult: {result}\")\n",
    "print(f\"Result content: {result.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-3-intro",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example 3: Node with Dictionary Return\n",
    "\n",
    "When you need to return multiple pieces of information, use a dictionary. This is the most common pattern in Spark.\n",
    "\n",
    "### Why Dictionaries?\n",
    "- Named keys make it clear what each value represents\n",
    "- Easy to pass multiple values to subsequent nodes\n",
    "- Standard pattern in Spark for structured data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-node",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessorNode(Node):\n",
    "    \"\"\"A node that returns structured data as a dictionary.\"\"\"\n",
    "    \n",
    "    def process(self):\n",
    "        # Process some data\n",
    "        data = {\n",
    "            'status': 'success',\n",
    "            'value': 100,\n",
    "            'message': 'Data processed successfully',\n",
    "            'items': ['item1', 'item2', 'item3']\n",
    "        }\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-node-execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_node = DataProcessorNode()\n",
    "result = await data_node.do()\n",
    "\n",
    "print(f\"Result: {result.content}\")\n",
    "print(f\"\\nStatus: {result.content['status']}\")\n",
    "print(f\"Value: {result.content['value']}\")\n",
    "print(f\"Items: {result.content['items']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-4-intro",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example 4: Node with Inputs (ExecutionContext)\n",
    "\n",
    "Real nodes need to receive data from somewhere! The `ExecutionContext` is how nodes receive inputs.\n",
    "\n",
    "### ExecutionContext Components:\n",
    "- **`context.inputs`** - Data passed to the node\n",
    "- **`context.state`** - Persistent state across executions\n",
    "- **`context.metadata`** - Additional information about execution\n",
    "- **`context.outputs`** - Accumulated outputs (read-only in process)\n",
    "\n",
    "### Important Note:\n",
    "While Spark tolerates `process()` methods without arguments for convenience, **always write** `process(self, context)` to access inputs properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greeting-node",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreetingNode(Node):\n",
    "    \"\"\"A node that uses input data to create a personalized greeting.\"\"\"\n",
    "    \n",
    "    def process(self, context):\n",
    "        # Access inputs from the context\n",
    "        name = context.inputs.content.get('name', 'Stranger')\n",
    "        language = context.inputs.content.get('language', 'English')\n",
    "        \n",
    "        # Create greeting based on language\n",
    "        greetings = {\n",
    "            'English': f'Hello, {name}!',\n",
    "            'Spanish': f'¬°Hola, {name}!',\n",
    "            'French': f'Bonjour, {name}!',\n",
    "            'German': f'Guten Tag, {name}!',\n",
    "        }\n",
    "        \n",
    "        greeting = greetings.get(language, f'Hello, {name}!')\n",
    "        print(greeting)\n",
    "        \n",
    "        return {\n",
    "            'greeting': greeting,\n",
    "            'name': name,\n",
    "            'language': language\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greeting-execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create node and pass inputs directly to do()\n",
    "greeting_node = GreetingNode()\n",
    "\n",
    "# Execute with inputs\n",
    "result1 = await greeting_node.do({'name': 'Alice', 'language': 'Spanish'})\n",
    "print(f\"Result: {result1.content}\\n\")\n",
    "\n",
    "result2 = await greeting_node.do({'name': 'Bob', 'language': 'French'})\n",
    "print(f\"Result: {result2.content}\\n\")\n",
    "\n",
    "result3 = await greeting_node.do({'name': 'Charlie'})  # Default language\n",
    "print(f\"Result: {result3.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-5-intro",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example 5: Node with State\n",
    "\n",
    "Nodes can maintain state across multiple executions. State is persistent within the node instance.\n",
    "\n",
    "### When to Use State:\n",
    "- Counting operations\n",
    "- Accumulating results\n",
    "- Tracking history\n",
    "- Maintaining context across calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "counter-node",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CounterNode(Node):\n",
    "    \"\"\"A node that counts how many times it has been executed.\"\"\"\n",
    "    \n",
    "    def process(self, context):\n",
    "        # Initialize counter in state if not exists\n",
    "        if 'count' not in context.state:\n",
    "            context.state['count'] = 0\n",
    "        \n",
    "        # Increment counter\n",
    "        context.state['count'] += 1\n",
    "        \n",
    "        current_count = context.state['count']\n",
    "        print(f\"Execution #{current_count}\")\n",
    "        \n",
    "        return {\n",
    "            'execution_number': current_count,\n",
    "            'message': f'This node has been called {current_count} time(s)'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "counter-execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_node = CounterNode()\n",
    "\n",
    "# Call it multiple times\n",
    "for i in range(5):\n",
    "    result = await counter_node.do()\n",
    "    print(f\"  ‚Üí {result.content['message']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-6-intro",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example 6: Practical Node - Text Processor\n",
    "\n",
    "Let's create a more practical example: a text processing node that performs various transformations.\n",
    "\n",
    "This demonstrates:\n",
    "- Multiple input parameters\n",
    "- Conditional logic\n",
    "- Different operations based on inputs\n",
    "- Comprehensive return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "text-processor-node",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextProcessorNode(Node):\n",
    "    \"\"\"A node that performs various text transformations.\"\"\"\n",
    "    \n",
    "    def process(self, context):\n",
    "        text = context.inputs.content.get('text', '')\n",
    "        operation = context.inputs.content.get('operation', 'none')\n",
    "        \n",
    "        if not text:\n",
    "            return {'error': 'No text provided'}\n",
    "        \n",
    "        # Perform the requested operation\n",
    "        operations = {\n",
    "            'uppercase': text.upper(),\n",
    "            'lowercase': text.lower(),\n",
    "            'reverse': text[::-1],\n",
    "            'word_count': len(text.split()),\n",
    "            'char_count': len(text),\n",
    "            'title': text.title(),\n",
    "            'none': text\n",
    "        }\n",
    "        \n",
    "        result = operations.get(operation, text)\n",
    "        \n",
    "        return {\n",
    "            'original': text,\n",
    "            'operation': operation,\n",
    "            'result': result,\n",
    "            'original_length': len(text)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "text-processor-execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = TextProcessorNode()\n",
    "\n",
    "# Test different operations\n",
    "test_text = \"Hello World from Spark ADK\"\n",
    "\n",
    "operations = ['uppercase', 'lowercase', 'reverse', 'word_count', 'title']\n",
    "\n",
    "for op in operations:\n",
    "    result = await processor.do({'text': test_text, 'operation': op})\n",
    "    print(f\"{op.upper():12} ‚Üí {result.content['result']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "async-explanation",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîç Async vs Sync in Spark\n",
    "\n",
    "### Important Notes:\n",
    "\n",
    "1. **You can write sync or async `process()` methods**\n",
    "   ```python\n",
    "   def process(self, context):        # Sync - OK!\n",
    "       return {'result': 42}\n",
    "   \n",
    "   async def process(self, context):  # Async - Preferred!\n",
    "       return {'result': 42}\n",
    "   ```\n",
    "\n",
    "2. **Spark auto-wraps sync methods to async**\n",
    "   - The framework handles this automatically\n",
    "   - But prefer writing async for consistency\n",
    "\n",
    "3. **Execution methods are always async**\n",
    "   - `await node.do()`\n",
    "   - `await node.run()`\n",
    "   - Use `arun()` utility if calling from sync context\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercises-intro",
   "metadata": {},
   "source": [
    "## üí™ Practice Exercises\n",
    "\n",
    "Now it's your turn! Try these exercises to solidify your understanding.\n",
    "\n",
    "### Exercise 1: Temperature Converter\n",
    "\n",
    "Create a node that converts temperatures between Celsius and Fahrenheit.\n",
    "\n",
    "**Requirements:**\n",
    "- Accept `temperature` and `from_unit` ('C' or 'F') as inputs\n",
    "- Convert to the other unit\n",
    "- Return both values and the conversion formula used\n",
    "\n",
    "**Formulas:**\n",
    "- C to F: `(C √ó 9/5) + 32`\n",
    "- F to C: `(F - 32) √ó 5/9`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exercise-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemperatureConverterNode(Node):\n",
    "    \"\"\"Your code here!\"\"\"\n",
    "    \n",
    "    def process(self, context):\n",
    "        # TODO: Implement temperature conversion\n",
    "        pass\n",
    "\n",
    "# Test your node\n",
    "# temp_node = TemperatureConverterNode()\n",
    "# result = await temp_node.do({'temperature': 100, 'from_unit': 'C'})\n",
    "# print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-2-intro",
   "metadata": {},
   "source": [
    "### Exercise 2: Statistics Node\n",
    "\n",
    "Create a node that calculates basic statistics for a list of numbers.\n",
    "\n",
    "**Requirements:**\n",
    "- Accept a list of numbers as input\n",
    "- Calculate: mean, median, min, max, sum\n",
    "- Return all statistics in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exercise-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatisticsNode(Node):\n",
    "    \"\"\"Your code here!\"\"\"\n",
    "    \n",
    "    def process(self, context):\n",
    "        # TODO: Implement statistics calculation\n",
    "        pass\n",
    "\n",
    "# Test your node\n",
    "# stats_node = StatisticsNode()\n",
    "# result = await stats_node.do({'numbers': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]})\n",
    "# print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-3-intro",
   "metadata": {},
   "source": [
    "### Exercise 3: Accumulator Node\n",
    "\n",
    "Create a node that accumulates values over multiple calls using state.\n",
    "\n",
    "**Requirements:**\n",
    "- Accept a number as input\n",
    "- Add it to a running total (stored in state)\n",
    "- Return the current total and count of additions\n",
    "- Include a 'reset' input option to clear the state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exercise-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccumulatorNode(Node):\n",
    "    \"\"\"Your code here!\"\"\"\n",
    "    \n",
    "    def process(self, context):\n",
    "        # TODO: Implement accumulator with state\n",
    "        pass\n",
    "\n",
    "# Test your node\n",
    "# acc_node = AccumulatorNode()\n",
    "# await acc_node.do({'value': 10})\n",
    "# await acc_node.do({'value': 20})\n",
    "# result = await acc_node.do({'value': 30})\n",
    "# print(result.content)  # Should show total: 60, count: 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solutions-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Solutions\n",
    "\n",
    "Try the exercises yourself first! Solutions are provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solution-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1: Temperature Converter\n",
    "class TemperatureConverterNode(Node):\n",
    "    def process(self, context):\n",
    "        temp = context.inputs.content.get('temperature')\n",
    "        from_unit = context.inputs.content.get('from_unit', 'C').upper()\n",
    "        \n",
    "        if temp is None:\n",
    "            return {'error': 'Temperature value required'}\n",
    "        \n",
    "        if from_unit == 'C':\n",
    "            converted = (temp * 9/5) + 32\n",
    "            to_unit = 'F'\n",
    "            formula = '(C √ó 9/5) + 32'\n",
    "        elif from_unit == 'F':\n",
    "            converted = (temp - 32) * 5/9\n",
    "            to_unit = 'C'\n",
    "            formula = '(F - 32) √ó 5/9'\n",
    "        else:\n",
    "            return {'error': 'Invalid unit. Use C or F'}\n",
    "        \n",
    "        return {\n",
    "            'original': f\"{temp}¬∞{from_unit}\",\n",
    "            'converted': f\"{converted:.2f}¬∞{to_unit}\",\n",
    "            'formula': formula\n",
    "        }\n",
    "\n",
    "# Test\n",
    "temp_node = TemperatureConverterNode()\n",
    "result = await temp_node.do({'temperature': 100, 'from_unit': 'C'})\n",
    "print(f\"Solution 1: {result.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solution-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 2: Statistics Node\n",
    "class StatisticsNode(Node):\n",
    "    def process(self, context):\n",
    "        numbers = context.inputs.content.get('numbers', [])\n",
    "        \n",
    "        if not numbers:\n",
    "            return {'error': 'No numbers provided'}\n",
    "        \n",
    "        sorted_nums = sorted(numbers)\n",
    "        n = len(sorted_nums)\n",
    "        \n",
    "        # Calculate median\n",
    "        if n % 2 == 0:\n",
    "            median = (sorted_nums[n//2 - 1] + sorted_nums[n//2]) / 2\n",
    "        else:\n",
    "            median = sorted_nums[n//2]\n",
    "        \n",
    "        return {\n",
    "            'count': n,\n",
    "            'sum': sum(numbers),\n",
    "            'mean': sum(numbers) / n,\n",
    "            'median': median,\n",
    "            'min': min(numbers),\n",
    "            'max': max(numbers),\n",
    "            'range': max(numbers) - min(numbers)\n",
    "        }\n",
    "\n",
    "# Test\n",
    "stats_node = StatisticsNode()\n",
    "result = await stats_node.do({'numbers': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]})\n",
    "print(f\"Solution 2: {result.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solution-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 3: Accumulator Node\n",
    "class AccumulatorNode(Node):\n",
    "    def process(self, context):\n",
    "        # Check for reset command\n",
    "        if context.inputs.content.get('reset'):\n",
    "            context.state.clear()\n",
    "            return {'message': 'Accumulator reset', 'total': 0, 'count': 0}\n",
    "        \n",
    "        # Initialize state\n",
    "        if 'total' not in context.state:\n",
    "            context.state['total'] = 0\n",
    "            context.state['count'] = 0\n",
    "        \n",
    "        # Add new value\n",
    "        value = context.inputs.content.get('value', 0)\n",
    "        context.state['total'] += value\n",
    "        context.state['count'] += 1\n",
    "        \n",
    "        return {\n",
    "            'total': context.state['total'],\n",
    "            'count': context.state['count'],\n",
    "            'average': context.state['total'] / context.state['count'],\n",
    "            'last_added': value\n",
    "        }\n",
    "\n",
    "# Test\n",
    "acc_node = AccumulatorNode()\n",
    "await acc_node.do({'value': 10})\n",
    "await acc_node.do({'value': 20})\n",
    "result = await acc_node.do({'value': 30})\n",
    "print(f\"Solution 3: {result.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Key Takeaways\n",
    "\n",
    "Congratulations! You've learned the fundamentals of Spark nodes. Let's recap:\n",
    "\n",
    "### ‚úÖ What You Learned:\n",
    "\n",
    "1. **Nodes are the building blocks** of Spark systems\n",
    "   - Inherit from `Node` class\n",
    "   - Define a `process()` method\n",
    "\n",
    "2. **The process() method** is where the magic happens\n",
    "   - Can be sync or async\n",
    "   - Optionally accepts ExecutionContext\n",
    "   - Can return any Python value\n",
    "\n",
    "3. **ExecutionContext provides**:\n",
    "   - `context.inputs` - Data passed to the node\n",
    "   - `context.state` - Persistent state across executions\n",
    "   - `context.metadata` - Execution metadata\n",
    "\n",
    "4. **Execution methods**:\n",
    "   - `await node.do(inputs)` - Direct execution\n",
    "   - `await node.run(inputs)` - Higher-level execution\n",
    "   - Pass inputs as dictionaries\n",
    "\n",
    "5. **Best practices**:\n",
    "   - Use dictionaries for structured returns\n",
    "   - Always write `process(self, context)` for clarity\n",
    "   - Prefer async methods\n",
    "   - Use state for persistent data\n",
    "\n",
    "### üìö Related Documentation:\n",
    "- Example file: `examples/e001_hello.py`\n",
    "- Source: `spark/nodes/base.py`, `spark/nodes/nodes.py`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next-steps",
   "metadata": {},
   "source": [
    "## üöÄ Next Steps\n",
    "\n",
    "Now that you understand individual nodes, you're ready to connect them together!\n",
    "\n",
    "### Coming Up in Tutorial 2:\n",
    "- **Connecting nodes** into workflows\n",
    "- **Creating graphs** with the `>>` operator\n",
    "- **Passing data** between nodes\n",
    "- **Building pipelines** that solve real problems\n",
    "\n",
    "### Challenge Before Next Tutorial:\n",
    "Try creating a node that:\n",
    "1. Accepts a URL as input\n",
    "2. Fetches content from that URL (use `requests` library)\n",
    "3. Returns word count and character count\n",
    "4. Uses state to track how many URLs have been processed\n",
    "\n",
    "This will prepare you well for the next tutorial!\n",
    "\n",
    "---\n",
    "\n",
    "### üéì Tutorial Series:\n",
    "- ‚úÖ **Tutorial 1: Hello Spark** (You are here)\n",
    "- ‚û°Ô∏è Tutorial 2: Simple Flows and Graph Basics\n",
    "- Tutorial 3: Your First AI Agent\n",
    "- Tutorial 4: Conditional Routing and Decision Making\n",
    "- ...and more!\n",
    "\n",
    "---\n",
    "\n",
    "**Questions or Issues?** Check the Spark documentation or open an issue on GitHub.\n",
    "\n",
    "Happy building with Spark! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
