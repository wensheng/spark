{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2: Batch Processing with Parallel Nodes\n",
    "\n",
    "**Difficulty:** Beginner | **Time:** 25 minutes\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Understand batch processing with multiple items\n",
    "- Choose the right parallel processing strategy\n",
    "- Implement SequentialNode for ordered processing\n",
    "- Use MultipleThreadNode for concurrent processing\n",
    "- Use MultipleProcessNode for CPU-intensive tasks\n",
    "\n",
    "## Real-World Use Case\n",
    "\n",
    "Imagine you need to translate a document into multiple languages, process a list of customer reviews, or analyze thousands of images. Doing these tasks one by one would be slow and inefficient. Spark's batch processing nodes allow you to handle multiple items efficiently using different parallelization strategies.\n",
    "\n",
    "In this tutorial, we'll build a translation service that processes multiple languages simultaneously, demonstrating different approaches to batch processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Concepts\n",
    "\n",
    "### The `process_item()` Method Pattern\n",
    "\n",
    "Unlike regular nodes that implement `process()`, batch processing nodes implement `process_item()`:\n",
    "\n",
    "```python\n",
    "class MyBatchNode(SequentialNode):\n",
    "    async def process_item(self, item):\n",
    "        # Process a single item from the batch\n",
    "        result = await self.process_single_item(item)\n",
    "        return result\n",
    "```\n",
    "\n",
    "### Three Batch Processing Strategies\n",
    "\n",
    "1. **SequentialNode**: Process items one after another (ordered)\n",
    "2. **MultipleThreadNode**: Process items concurrently using threads\n",
    "3. **MultipleProcessNode**: Process items in parallel using separate processes\n",
    "\n",
    "### When to Use Each Strategy\n",
    "\n",
    "- **SequentialNode**: When order matters or when dealing with limited resources\n",
    "- **MultipleThreadNode**: For I/O-bound tasks (API calls, file operations)\n",
    "- **MultipleProcessNode**: For CPU-intensive tasks (image processing, data analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's import the necessary classes and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the batch processing node types\n",
    "from spark.nodes.nodes import SequentialNode, MultipleThreadNode, MultipleProcessNode\n",
    "from spark.utils import arun\n",
    "import asyncio\n",
    "import time\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Sequential Processing\n",
    "\n",
    "Let's start with a simple text processing example using SequentialNode. This processes items one by one, maintaining order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTextProcessor(SequentialNode):\n",
    "    \"\"\"Process text items sequentially, maintaining order.\"\"\"\n",
    "    \n",
    "    async def process_item(self, item):\n",
    "        text = item['text']\n",
    "        delay = item.get('delay', 0.1)  # Simulate processing time\n",
    "        \n",
    "        # Simulate some text processing work\n",
    "        await asyncio.sleep(delay)\n",
    "        \n",
    "        # Process the text (convert to uppercase and add length)\n",
    "        processed_text = text.upper()\n",
    "        result = {\n",
    "            'original': text,\n",
    "            'processed': processed_text,\n",
    "            'length': len(text),\n",
    "            'processing_time': delay\n",
    "        }\n",
    "        \n",
    "        print(f\"Processed: '{text}' -> '{processed_text}'\")\n",
    "        return result\n",
    "\n",
    "# Test data\n",
    "text_data = [\n",
    "    {'text': 'hello world', 'delay': 0.1},\n",
    "    {'text': 'spark framework', 'delay': 0.1},\n",
    "    {'text': 'batch processing', 'delay': 0.1},\n",
    "    {'text': 'parallel execution', 'delay': 0.1}\n",
    "]\n",
    "\n",
    "# Create and run the sequential processor\n",
    "processor = SimpleTextProcessor()\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"=== Sequential Processing ===\")\n",
    "results = await processor.do(text_data)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\nTotal time: {end_time - start_time:.2f} seconds\")\n",
    "print(f\"Processed {len(results.content)} items\")\n",
    "print(f\"Results: {results.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Multi-Thread Processing\n",
    "\n",
    "Now let's use MultipleThreadNode to process items concurrently. This is ideal for I/O-bound tasks like API calls or file operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcurrentTextProcessor(MultipleThreadNode):\n",
    "    \"\"\"Process text items concurrently using multiple threads.\"\"\"\n",
    "    \n",
    "    async def process_item(self, item):\n",
    "        text = item['text']\n",
    "        delay = item.get('delay', 0.1)\n",
    "        \n",
    "        # Simulate I/O-bound work (like an API call)\n",
    "        await asyncio.sleep(delay)\n",
    "        \n",
    "        # Process the text\n",
    "        processed_text = text.title()  # Title case instead of uppercase\n",
    "        result = {\n",
    "            'original': text,\n",
    "            'processed': processed_text,\n",
    "            'length': len(text),\n",
    "            'thread_id': id(asyncio.current_task()),\n",
    "            'processing_time': delay\n",
    "        }\n",
    "        \n",
    "        print(f\"Thread processed: '{text}' -> '{processed_text}'\")\n",
    "        return result\n",
    "\n",
    "# Create and run the concurrent processor\n",
    "concurrent_processor = ConcurrentTextProcessor()\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"=== Multi-Thread Processing ===\")\n",
    "thread_results = await concurrent_processor.do(text_data)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\nTotal time: {end_time - start_time:.2f} seconds\")\n",
    "print(f\"Processed {len(thread_results.content)} items concurrently\")\n",
    "print(f\"Results: {thread_results.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Translation Service (Real-World Application)\n",
    "\n",
    "Let's build a practical translation service that processes multiple languages. We'll simulate translation since we don't want to make actual API calls in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock translation function (simulates API call)\n",
    "async def mock_translate(text, target_language):\n",
    "    \"\"\"Simulate translation by adding language prefix.\"\"\"\n",
    "    # Simulate API call delay\n",
    "    await asyncio.sleep(0.2)\n",
    "    \n",
    "    translations = {\n",
    "        'Spanish': f'[ES] {text}',\n",
    "        'French': f'[FR] {text}',\n",
    "        'German': f'[DE] {text}',\n",
    "        'Chinese': f'[ZH] {text}',\n",
    "        'Japanese': f'[JA] {text}',\n",
    "        'Korean': f'[KO] {text}'\n",
    "    }\n",
    "    \n",
    "    return translations.get(target_language, f'[{target_language[:2].upper()}] {text}')\n",
    "\n",
    "class TranslationProcessor(MultipleThreadNode):\n",
    "    \"\"\"Translate text to multiple languages concurrently.\"\"\"\n",
    "    \n",
    "    async def process_item(self, item):\n",
    "        text = item['text']\n",
    "        language = item['language']\n",
    "        \n",
    "        print(f\"Translating to {language}...\")\n",
    "        \n",
    "        # Translate the text\n",
    "        translated_text = await mock_translate(text, language)\n",
    "        \n",
    "        result = {\n",
    "            'original': text,\n",
    "            'language': language,\n",
    "            'translated': translated_text,\n",
    "            'timestamp': time.time()\n",
    "        }\n",
    "        \n",
    "        print(f\"Translation complete for {language}\")\n",
    "        return result\n",
    "\n",
    "# Translation data\n",
    "translation_data = [\n",
    "    {'text': 'Hello, how are you?', 'language': 'Spanish'},\n",
    "    {'text': 'Hello, how are you?', 'language': 'French'},\n",
    "    {'text': 'Hello, how are you?', 'language': 'German'},\n",
    "    {'text': 'Hello, how are you?', 'language': 'Chinese'},\n",
    "    {'text': 'Hello, how are you?', 'language': 'Japanese'},\n",
    "    {'text': 'Hello, how are you?', 'language': 'Korean'}\n",
    "]\n",
    "\n",
    "# Create and run the translation service\n",
    "translator = TranslationProcessor()\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"=== Translation Service (Multi-Thread) ===\")\n",
    "translation_results = await translator.do(translation_data)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\nTranslation complete!\")\n",
    "print(f\"Total time: {end_time - start_time:.2f} seconds\")\n",
    "print(f\"Translated to {len(translation_results.content)} languages\")\n",
    "\n",
    "# Display results nicely\n",
    "print(\"\\nTranslation Results:\")\n",
    "for result in translation_results.content:\n",
    "    print(f\"  {result['language']}: {result['translated']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Performance Comparison\n",
    "\n",
    "Let's compare the performance of Sequential vs Multi-Thread processing with different workloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BenchmarkProcessor:\n",
    "    \"\"\"Utility class to compare different processing strategies.\"\"\"\n",
    "    \n",
    "    class Sequential(SequentialNode):\n",
    "        async def process_item(self, item):\n",
    "            await asyncio.sleep(item['delay'])\n",
    "            return {'item': item['id'], 'processed': True}\n",
    "    \n",
    "    class Threaded(MultipleThreadNode):\n",
    "        async def process_item(self, item):\n",
    "            await asyncio.sleep(item['delay'])\n",
    "            return {'item': item['id'], 'processed': True}\n",
    "    \n",
    "    @staticmethod\n",
    "    async def run_benchmark(name, processor_class, data):\n",
    "        print(f\"\\n=== {name} ===\")\n",
    "        processor = processor_class()\n",
    "        start_time = time.time()\n",
    "        results = await processor.do(data)\n",
    "        end_time = time.time()\n",
    "        print(f\"Time: {end_time - start_time:.2f}s\")\n",
    "        print(f\"Results: {len(results.content)} items processed\")\n",
    "        return end_time - start_time\n",
    "\n",
    "# Create test data with different processing times\n",
    "test_data = [\n",
    "    {'id': i, 'delay': 0.1} for i in range(8)\n",
    "]\n",
    "\n",
    "print(\"Performance Comparison: Sequential vs Multi-Thread\")\n",
    "print(f\"Test data: {len(test_data)} items, each with 0.1s delay\")\n",
    "\n",
    "# Run benchmarks\n",
    "sequential_time = await BenchmarkProcessor.run_benchmark(\n",
    "    \"Sequential Processing\", \n",
    "    BenchmarkProcessor.Sequential, \n",
    "    test_data\n",
    ")\n",
    "\n",
    "threaded_time = await BenchmarkProcessor.run_benchmark(\n",
    "    \"Multi-Thread Processing\", \n",
    "    BenchmarkProcessor.Threaded, \n",
    "    test_data\n",
    ")\n",
    "\n",
    "print(f\"\\n=== Summary ===\")\n",
    "print(f\"Sequential time: {sequential_time:.2f}s\")\n",
    "print(f\"Multi-thread time: {threaded_time:.2f}s\")\n",
    "speedup = sequential_time / threaded_time if threaded_time > 0 else float('inf')\n",
    "print(f\"Speedup: {speedup:.1f}x faster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Error Handling and Failure Strategies\n",
    "\n",
    "Batch processing nodes support different failure strategies. Let's explore how to handle errors gracefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobustProcessor(MultipleThreadNode):\n",
    "    \"\"\"A processor that demonstrates error handling.\"\"\"\n",
    "\n",
    "    async def process_item(self, item):\n",
    "        try:\n",
    "            text = item['text']\n",
    "            \n",
    "            # Simulate an error for specific items\n",
    "            if 'error' in text.lower():\n",
    "                raise ValueError(f\"Simulated error processing: {text}\")\n",
    "            \n",
    "            # Normal processing\n",
    "            await asyncio.sleep(0.1)\n",
    "            return {\n",
    "                'original': text,\n",
    "                'processed': text.upper(),\n",
    "                'status': 'success'\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing '{text}': {str(e)}\")\n",
    "            return {\n",
    "                'original': text,\n",
    "                'error': str(e),\n",
    "                'status': 'failed'\n",
    "            }\n",
    "\n",
    "# Test data with some items that will fail\n",
    "test_data_with_errors = [\n",
    "    {'text': 'normal item 1'},\n",
    "    {'text': 'item with error'},  # This will fail\n",
    "    {'text': 'normal item 2'},\n",
    "    {'text': 'another ERROR'},     # This will fail\n",
    "    {'text': 'normal item 3'}\n",
    "]\n",
    "\n",
    "# Test with error handling\n",
    "robust_processor = RobustProcessor(failure_strategy='skip_failed')\n",
    "\n",
    "print(\"=== Error Handling in Batch Processing ===\")\n",
    "results_with_errors = await robust_processor.do(test_data_with_errors)\n",
    "\n",
    "print(f\"\\nResults summary:\")\n",
    "successful = [r for r in results_with_errors.content if r.get('status') == 'success']\n",
    "failed = [r for r in results_with_errors.content if r.get('status') == 'failed']\n",
    "\n",
    "print(f\"Successful: {len(successful)} items\")\n",
    "print(f\"Failed: {len(failed)} items\")\n",
    "print(f\"Total processed: {len(results_with_errors.content)} items\")\n",
    "\n",
    "print(\"\\nDetailed results:\")\n",
    "for i, result in enumerate(results_with_errors.content, 1):\n",
    "    status = result.get('status', 'unknown')\n",
    "    original = result.get('original', 'unknown')\n",
    "    if status == 'success':\n",
    "        print(f\"  {i}. {original} -> {result['processed']}\")\n",
    "    else:\n",
    "        print(f\"  {i}. {original} - Error: {result['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### When to Use Each Node Type\n",
    "\n",
    "**SequentialNode**\n",
    "- Use when order matters\n",
    "- Good for debugging and testing\n",
    "- Lower resource usage\n",
    "- Predictable execution time\n",
    "\n",
    "**MultipleThreadNode**\n",
    "- Best for I/O-bound tasks (API calls, database operations, file I/O)\n",
    "- Lower overhead than MultipleProcessNode\n",
    "- Share memory (but needs thread safety)\n",
    "- Great for network operations\n",
    "\n",
    "**MultipleProcessNode**\n",
    "- Best for CPU-intensive tasks (data processing, image processing, machine learning)\n",
    "- True parallelism (bypasses GIL)\n",
    "- Isolated memory (safer)\n",
    "- Higher overhead\n",
    "- Requires picklable objects\n",
    "\n",
    "### Performance Tips\n",
    "\n",
    "1. **Match the strategy to the workload**: I/O-bound → threads, CPU-bound → processes\n",
    "2. **Consider overhead**: Don't use parallel processing for very small tasks\n",
    "3. **Handle errors gracefully**: Use try-catch in `process_item()`\n",
    "4. **Monitor resource usage**: Don't create too many threads/processes\n",
    "\n",
    "### Common Patterns\n",
    "\n",
    "```python\n",
    "# Pattern 1: API processing\n",
    "class APIProcessor(MultipleThreadNode):\n",
    "    async def process_item(self, item):\n",
    "        result = await api_call(item)\n",
    "        return result\n",
    "\n",
    "# Pattern 2: File processing  \n",
    "class FileProcessor(MultipleProcessNode):\n",
    "    async def process_item(self, file_path):\n",
    "        data = load_and_process_file(file_path)  # CPU-intensive\n",
    "        return data\n",
    "\n",
    "# Pattern 3: Data transformation\n",
    "class DataTransformer(SequentialNode):\n",
    "    async def process_item(self, row):\n",
    "        transformed = transform_row(row)\n",
    "        return transformed\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-On Exercises\n",
    "\n",
    "### Exercise 1: Create a Simple Batch Processor\n",
    "\n",
    "Create a batch processor that calculates the square of numbers. Use SequentialNode first, then modify it to use MultipleThreadNode.\n",
    "\n",
    "```python\n",
    "# Your code here\n",
    "numbers = [{'value': i} for i in range(1, 11)]\n",
    "\n",
    "class SquareCalculator(SequentialNode):\n",
    "    async def process_item(self, item):\n",
    "        # Implement this\n",
    "        pass\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1 Solution\n",
    "class SquareCalculator(SequentialNode):\n",
    "    async def process_item(self, item):\n",
    "        value = item['value']\n",
    "        await asyncio.sleep(0.05)  # Simulate work\n",
    "        result = {\n",
    "            'original': value,\n",
    "            'square': value ** 2,\n",
    "            'cube': value ** 3\n",
    "        }\n",
    "        return result\n",
    "\n",
    "# Test it\n",
    "numbers = [{'value': i} for i in range(1, 6)]\n",
    "calculator = SquareCalculator()\n",
    "result = await calculator.do(numbers)\n",
    "print(\"Square Calculator Results:\")\n",
    "for r in result.content:\n",
    "    print(f\"  {r['original']}^2 = {r['square']}, {r['original']}^3 = {r['cube']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Convert to Multi-Thread Processing\n",
    "\n",
    "Modify the SquareCalculator to use MultipleThreadNode and compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2 Solution\n",
    "class ThreadedSquareCalculator(MultipleThreadNode):\n",
    "    async def process_item(self, item):\n",
    "        value = item['value']\n",
    "        await asyncio.sleep(0.05)  # Simulate work\n",
    "        result = {\n",
    "            'original': value,\n",
    "            'square': value ** 2,\n",
    "            'cube': value ** 3\n",
    "        }\n",
    "        return result\n",
    "\n",
    "# Performance comparison\n",
    "more_numbers = [{'value': i} for i in range(1, 11)]\n",
    "\n",
    "print(\"Performance Comparison:\")\n",
    "\n",
    "# Sequential\n",
    "seq_calc = SquareCalculator()\n",
    "start = time.time()\n",
    "seq_results = await seq_calc.do(more_numbers)\n",
    "seq_time = time.time() - start\n",
    "print(f\"Sequential: {seq_time:.2f}s\")\n",
    "\n",
    "# Threaded\n",
    "thread_calc = ThreadedSquareCalculator()\n",
    "start = time.time()\n",
    "thread_results = await thread_calc.do(more_numbers)\n",
    "thread_time = time.time() - start\n",
    "print(f\"Threaded: {thread_time:.2f}s\")\n",
    "\n",
    "print(f\"Speedup: {seq_time/thread_time:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Build a Sentiment Analyzer\n",
    "\n",
    "Create a batch processor that analyzes sentiment of text messages. Include error handling for malformed input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3 Solution\n",
    "class SentimentAnalyzer(MultipleThreadNode):\n",
    "    \"\"\"Analyze sentiment of text messages.\"\"\"\n",
    "    \n",
    "    async def process_item(self, item):\n",
    "        try:\n",
    "            text = item.get('text', '')\n",
    "            message_id = item.get('id', 'unknown')\n",
    "            \n",
    "            # Validate input\n",
    "            if not text or not isinstance(text, str):\n",
    "                raise ValueError(f\"Invalid text: {text}\")\n",
    "            \n",
    "            # Simulate sentiment analysis API call\n",
    "            await asyncio.sleep(0.1)\n",
    "            \n",
    "            # Simple sentiment analysis (mock)\n",
    "            positive_words = ['good', 'great', 'excellent', 'amazing', 'love', 'happy', 'wonderful']\n",
    "            negative_words = ['bad', 'terrible', 'awful', 'hate', 'sad', 'horrible', 'worst']\n",
    "            \n",
    "            text_lower = text.lower()\n",
    "            positive_count = sum(1 for word in positive_words if word in text_lower)\n",
    "            negative_count = sum(1 for word in negative_words if word in text_lower)\n",
    "            \n",
    "            if positive_count > negative_count:\n",
    "                sentiment = 'positive'\n",
    "                score = positive_count / max(positive_count + negative_count, 1)\n",
    "            elif negative_count > positive_count:\n",
    "                sentiment = 'negative'\n",
    "                score = negative_count / max(positive_count + negative_count, 1)\n",
    "            else:\n",
    "                sentiment = 'neutral'\n",
    "                score = 0.5\n",
    "            \n",
    "            return {\n",
    "                'id': message_id,\n",
    "                'text': text,\n",
    "                'sentiment': sentiment,\n",
    "                'confidence': round(score, 2),\n",
    "                'word_count': len(text.split())\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'id': item.get('id', 'unknown'),\n",
    "                'text': item.get('text', ''),\n",
    "                'error': str(e),\n",
    "                'status': 'failed'\n",
    "            }\n",
    "\n",
    "# Test the sentiment analyzer\n",
    "messages = [\n",
    "    {'id': 1, 'text': 'I love this amazing product!'},\n",
    "    {'id': 2, 'text': 'This is terrible and awful'},\n",
    "    {'id': 3, 'text': 'It is good but not great'},\n",
    "    {'id': 4, 'text': ''},  # This should fail\n",
    "    {'id': 5, 'text': 'Wonderful experience, happy with the result'},\n",
    "    {'id': 6, 'text': 'Bad bad bad'}\n",
    "]\n",
    "\n",
    "analyzer = SentimentAnalyzer()\n",
    "result = await analyzer.do(messages)\n",
    "\n",
    "print(\"Sentiment Analysis Results:\")\n",
    "for result in result.content:\n",
    "    if 'error' in result:\n",
    "        print(f\"  ID {result['id']}: ERROR - {result['error']}\")\n",
    "    else:\n",
    "        print(f\"  ID {result['id']}: {result['sentiment'].upper()} (confidence: {result['confidence']})\")\n",
    "        print(f\"    Text: {result['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Next Steps\n",
    "\n",
    "### What You Learned\n",
    "\n",
    "- **Batch Processing Fundamentals**: Understand how to process multiple items efficiently\n",
    "- **Three Processing Strategies**: SequentialNode, MultipleThreadNode, MultipleProcessNode\n",
    "- **Real-World Application**: Built a translation service using concurrent processing\n",
    "- **Performance Optimization**: Compared sequential vs concurrent processing\n",
    "- **Error Handling**: Implemented robust error handling in batch operations\n",
    "- **Practical Patterns**: Created sentiment analyzer and other useful processors\n",
    "\n",
    "### Key Concepts Mastered\n",
    "\n",
    "- `process_item()` method pattern for batch processing\n",
    "- Choosing the right strategy for your workload\n",
    "- Performance considerations and trade-offs\n",
    "- Error handling and failure strategies\n",
    "- Real-world applications (translation, sentiment analysis, data processing)\n",
    "\n",
    "### Next Tutorial\n",
    "\n",
    "In **Tutorial 3: Simple Flows and Graph Basics**, you'll learn how to:\n",
    "- Connect multiple nodes into workflows\n",
    "- Create edges between nodes\n",
    "- Build and execute graphs\n",
    "- Pass data between nodes using ExecutionContext\n",
    "\n",
    "### Continue Your Learning\n",
    "\n",
    "- Try building your own batch processors for tasks you encounter\n",
    "- Experiment with different failure strategies\n",
    "- Compare performance with your own datasets\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations!** You've mastered batch processing with Spark's parallel nodes. You can now efficiently process multiple items concurrently, choose the right processing strategy, and handle errors gracefully. This foundation will be crucial as we move on to building more complex workflows in the next tutorial!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
